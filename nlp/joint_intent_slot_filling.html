

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tutorial &mdash; nemo 0.10.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tutorial" href="question_answering.html" />
    <link rel="prev" title="Tutorial" href="punctuation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.10.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Fast Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/intro.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech_command/intro.html">Speech Commands</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="intro.html">Natural Language Processing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="intro.html#neural-machine-translation-nmt">Neural Machine Translation (NMT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#pretraining-bert">Pretraining BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#transformer-language-model">Transformer Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#dialogue-state-tracking">Dialogue State Tracking</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#named-entity-recognition">Named Entity Recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#punctuation-and-word-capitalization">Punctuation and Word Capitalization</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="intro.html#intent-and-slot-filling">Intent and Slot filling</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#preliminaries">Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="#code-structure">Code Structure</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-training">Model Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#question-answering">Question Answering</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#improving-speech-recognition-with-bertx2-post-processing-model">Improving Speech Recognition with BERTx2 Post-processing Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tts/intro.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">NeMo API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chinese/intro.html">中文支持</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="intro.html">Natural Language Processing</a> &raquo;</li>
        
      <li>Tutorial</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/nlp/joint_intent_slot_filling.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tutorial">
<h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we are going to show the structure of our example on training and evaluating an intent detection and slot filling model with pretrained BERT model. This model is based on a model proposed in <a class="reference external" href="https://arxiv.org/abs/1902.10909">BERT for Joint Intent Classification and Slot Filling</a> <a class="bibtex reference internal" href="#nlp-slot-chen2019bert" id="id1">[NLP-SLOT1]</a>.
All the code introduced in this tutorial is based on <code class="docutils literal notranslate"><span class="pre">examples/nlp/intent_detection_slot_tagging/joint_intent_slot_with_bert.py</span></code>.</p>
<p>There are a variety pre-trained BERT models that we can select as the base encoder for our model. We’re currently
using the script for loading pre-trained models from <cite>transformers</cite>. See the list of available pre-trained models by calling <cite>nemo.collections.nlp.nm.trainables.get_bert_models_list()</cite>. The type of the encoder can get defined by the argument <cite>–pretrained_model_name</cite>.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For pretraining BERT model in NeMo and also downloading pretrained model checkpoints go to <a class="reference external" href="https://nvidia.github.io/NeMo/nlp/bert_pretraining.html">BERT pretraining</a>.</p>
</div>
<div class="section" id="preliminaries">
<h2>Preliminaries<a class="headerlink" href="#preliminaries" title="Permalink to this headline">¶</a></h2>
<p><strong>Model details</strong>
This model jointly train the sentence-level classifier for intents and token-level classifier for slots by minimizing the combined loss of the two classifiers:</p>
<blockquote>
<div><p>intent_loss * intent_loss_weight + slot_loss * (1 - intent_loss_weight)</p>
</div></blockquote>
<p>When <cite>intent_loss_weight = 0.5</cite>, this loss jointly maximizes:</p>
<blockquote>
<div><p>p(y | x)P(s1, s2, …, sn | x)</p>
</div></blockquote>
<p>with x being the sequence of n tokens (x1, x2, …, xn), y being the predicted intent for x, and s1, s2, …, sn being the predicted slots corresponding to x1, x2, …, xn.</p>
<p><strong>Datasets.</strong></p>
<dl class="simple">
<dt>This model can work with any dataset that follows the NeMo’s format:</dt><dd><ul class="simple">
<li><p>input file: a <cite>tsv</cite> file with the first line as a header [sentence][tab][label]</p></li>
<li><p>slot file: slot labels for all tokens in the sentence, separated by space. The length of the slot labels should be the same as the length of all tokens in sentence in input file.</p></li>
</ul>
</dd>
</dl>
<p>Datasets which are not in this format should get processed and converted into NeMo’s format. Currently, the datasets that we provide pre-processing script for include ATIS which can be downloaded
from <a class="reference external" href="https://www.kaggle.com/siddhadev/atis-dataset-from-ms-cntk">Kaggle</a> and the SNIPS spoken language understanding research dataset which can be
requested from <a class="reference external" href="https://github.com/snipsco/spoken-language-understanding-research-datasets">here</a>. </p>
<p>You may use <code class="docutils literal notranslate"><span class="pre">/examples/nlp/intent_detection_slot_tagging/data/import_datasets.py</span></code> script to process these datasets:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">examples</span><span class="o">/</span><span class="n">nlp</span><span class="o">/</span><span class="n">intent_detection_slot_tagging</span><span class="o">/</span><span class="n">data</span><span class="o">/</span>
<span class="n">python</span> <span class="n">import_datasets</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">dataset_name</span> <span class="o">&lt;</span><span class="n">name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">dataset</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">source_data_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">data</span><span class="o">&gt;</span>\
    <span class="o">--</span><span class="n">target_data_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">save</span> <span class="n">the</span> <span class="n">processed</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">NeMo</span> <span class="nb">format</span><span class="o">&gt;</span>
</pre></div>
</div>
</div></blockquote>
<p>By setting the dataset_name parameter to one of [‘atis’, ‘snips’], you can process and convert these datasets into NeMo’s format. you can also write your own preprocessing scripts for any dataset.</p>
</div>
<div class="section" id="code-structure">
<h2>Code Structure<a class="headerlink" href="#code-structure" title="Permalink to this headline">¶</a></h2>
<p>First, we instantiate Neural Module Factory which defines 1) backend (PyTorch or TensorFlow), 2) mixed precision optimization level,
3) local rank of the GPU, and 4) an experiment manager that creates a timestamped folder to store checkpoints, relevant outputs, log files, and TensorBoard graphs.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nf</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">NeuralModuleFactory</span><span class="p">(</span>
    <span class="n">backend</span><span class="o">=</span><span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Backend</span><span class="o">.</span><span class="n">PyTorch</span><span class="p">,</span>
    <span class="n">local_rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
    <span class="n">optimization_level</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">amp_opt_level</span><span class="p">,</span>
    <span class="n">log_dir</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">work_dir</span><span class="p">,</span>
    <span class="n">checkpoint_dir</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">,</span>
    <span class="n">create_tb_writer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">files_to_copy</span><span class="o">=</span><span class="p">[</span><span class="vm">__file__</span><span class="p">],</span>
    <span class="n">add_time_to_log_dir</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>We define the tokenizer which transforms text into BERT tokens, using a built-in tokenizer by <cite>transformers</cite>. NemoBertTokenizer would select and return the appropriate tokenizer for each model.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">NemoBertTokenizer</span><span class="p">(</span><span class="n">pretrained_model</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model_name</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>Next, we define all Neural Modules participating in our joint intent slot filling classification pipeline.</p>
<blockquote>
<div><ul class="simple">
<li><p>Build data description: the <cite>JointIntentSlotDataDesc</cite> class in <cite>nemo/collections/nlp/data/datasets/joint_intent_slot_dataset/data_descriptor.py</cite> is supposed to do the read the dataset and build its schema.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nemo.collections.nlp.data.datasets.joint_intent_slot_dataset</span> <span class="kn">import</span> <span class="n">JointIntentSlotDataDesc</span>
<span class="n">data_desc</span> <span class="o">=</span> <span class="n">JointIntentSlotDataDesc</span><span class="p">(</span>
    <span class="n">data_dir</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">none_slot_label</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">none_slot_label</span><span class="p">,</span> <span class="n">pad_label</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">pad_label</span>
<span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Load the pre-trained BERT model to encode the corresponding inputs.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pretrained_bert_model</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">nm</span><span class="o">.</span><span class="n">trainables</span><span class="o">.</span><span class="n">get_huggingface_model</span><span class="p">(</span>
    <span class="n">bert_config</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">bert_config</span><span class="p">,</span> <span class="n">pretrained_model_name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model_name</span>
<span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create the classifier heads for our task.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nemo.collections.nlp.nm.trainables</span> <span class="kn">import</span> <span class="n">JointIntentSlotClassifier</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">JointIntentSlotClassifier</span><span class="p">(</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_intents</span><span class="o">=</span><span class="n">data_desc</span><span class="o">.</span><span class="n">num_intents</span><span class="p">,</span> <span class="n">num_slots</span><span class="o">=</span><span class="n">data_desc</span><span class="o">.</span><span class="n">num_slots</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">fc_dropout</span>
<span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create loss functions for intent detection and slot filling then and use loss aggregator module to merge them</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nemo.backends.pytorch.common.losses</span> <span class="kn">import</span> <span class="n">CrossEntropyLossNM</span><span class="p">,</span> <span class="n">LossAggregatorNM</span>
<span class="n">intent_loss_fn</span> <span class="o">=</span> <span class="n">CrossEntropyLossNM</span><span class="p">(</span><span class="n">logits_ndim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">slot_loss_fn</span> <span class="o">=</span> <span class="n">CrossEntropyLossNM</span><span class="p">(</span><span class="n">logits_ndim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">total_loss_fn</span> <span class="o">=</span> <span class="n">LossAggregatorNM</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">intent_loss_weight</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">args</span><span class="o">.</span><span class="n">intent_loss_weight</span><span class="p">])</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create the pipelines for the train and evaluation processes. Each pipeline creates its own data layer (BertJointIntentSlotDataLayer).</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nemo.collections.nlp.nm.data_layers</span> <span class="kn">import</span> <span class="n">BertJointIntentSlotDataLayer</span>
<span class="k">def</span> <span class="nf">create_pipeline</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">data_prefix</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading </span><span class="si">{data_prefix}</span><span class="s2"> data...&quot;</span><span class="p">)</span>
    <span class="n">data_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{data_desc.data_dir}</span><span class="s1">/</span><span class="si">{data_prefix}</span><span class="s1">.tsv&#39;</span>
    <span class="n">slot_file</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{data_desc.data_dir}</span><span class="s1">/</span><span class="si">{data_prefix}</span><span class="s1">_slots.tsv&#39;</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">shuffle_data</span> <span class="k">if</span> <span class="n">is_training</span> <span class="k">else</span> <span class="kc">False</span>

    <span class="n">data_layer</span> <span class="o">=</span> <span class="n">BertJointIntentSlotDataLayer</span><span class="p">(</span>
        <span class="n">input_file</span><span class="o">=</span><span class="n">data_file</span><span class="p">,</span>
        <span class="n">slot_file</span><span class="o">=</span><span class="n">slot_file</span><span class="p">,</span>
        <span class="n">pad_label</span><span class="o">=</span><span class="n">data_desc</span><span class="o">.</span><span class="n">pad_label</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">max_seq_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">ignore_extra_tokens</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ignore_extra_tokens</span><span class="p">,</span>
        <span class="n">ignore_start_end</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ignore_start_end</span><span class="p">,</span>
        <span class="n">do_lower_case</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">do_lower_case</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">data_layer</span><span class="p">()</span>
    <span class="n">data_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_layer</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The length of data layer is </span><span class="si">{data_size}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">data_size</span> <span class="o">&lt;</span> <span class="n">batch_size</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Batch_size is larger than the dataset size&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Reducing batch_size to dataset size&quot;</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">data_size</span>

    <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">data_size</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_gpus</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Steps_per_epoch = </span><span class="si">{steps_per_epoch}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">pretrained_bert_model</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">input_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">input_mask</span>
    <span class="p">)</span>

    <span class="n">intent_logits</span><span class="p">,</span> <span class="n">slot_logits</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">hidden_states</span><span class="o">=</span><span class="n">hidden_states</span><span class="p">)</span>

    <span class="n">intent_loss</span> <span class="o">=</span> <span class="n">intent_loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">intent_logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">intents</span><span class="p">)</span>
    <span class="n">slot_loss</span> <span class="o">=</span> <span class="n">slot_loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">slot_logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">slots</span><span class="p">,</span> <span class="n">loss_mask</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">loss_mask</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">total_loss_fn</span><span class="p">(</span><span class="n">loss_1</span><span class="o">=</span><span class="n">intent_loss</span><span class="p">,</span> <span class="n">loss_2</span><span class="o">=</span><span class="n">slot_loss</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_training</span><span class="p">:</span>
        <span class="n">tensors_to_evaluate</span> <span class="o">=</span> <span class="p">[</span><span class="n">total_loss</span><span class="p">,</span> <span class="n">intent_logits</span><span class="p">,</span> <span class="n">slot_logits</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tensors_to_evaluate</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">intent_logits</span><span class="p">,</span>
            <span class="n">slot_logits</span><span class="p">,</span>
            <span class="n">input_data</span><span class="o">.</span><span class="n">intents</span><span class="p">,</span>
            <span class="n">input_data</span><span class="o">.</span><span class="n">slots</span><span class="p">,</span>
            <span class="n">input_data</span><span class="o">.</span><span class="n">subtokens_mask</span><span class="p">,</span>
        <span class="p">]</span>

    <span class="k">return</span> <span class="n">tensors_to_evaluate</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="p">,</span> <span class="n">data_layer</span>


<span class="n">train_tensors</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_steps_per_epoch</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_pipeline</span><span class="p">(</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_train_samples</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">data_prefix</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train_file_prefix</span><span class="p">,</span>
    <span class="n">is_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_gpus</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_gpus</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">eval_tensors</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">eval_data_layer</span> <span class="o">=</span> <span class="n">create_pipeline</span><span class="p">(</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_eval_samples</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">data_prefix</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eval_file_prefix</span><span class="p">,</span>
    <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">num_gpus</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_gpus</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create relevant callbacks for saving checkpoints, printing training progresses and evaluating results.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nemo.collections.nlp.callbacks.joint_intent_slot_callback</span> <span class="kn">import</span> <span class="n">eval_epochs_done_callback</span><span class="p">,</span> <span class="n">eval_iter_callback</span>
<span class="kn">from</span> <span class="nn">nemo.core</span> <span class="kn">import</span> <span class="n">CheckpointCallback</span><span class="p">,</span> <span class="n">SimpleLossLoggerCallback</span>
<span class="n">train_callback</span> <span class="o">=</span> <span class="n">SimpleLossLoggerCallback</span><span class="p">(</span>
    <span class="n">tensors</span><span class="o">=</span><span class="n">train_tensors</span><span class="p">,</span>
    <span class="n">print_func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">3</span><span class="p">))),</span>
    <span class="n">tb_writer</span><span class="o">=</span><span class="n">nf</span><span class="o">.</span><span class="n">tb_writer</span><span class="p">,</span>
    <span class="n">get_tb_values</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[[</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]]],</span>
    <span class="n">step_freq</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">eval_callback</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">EvaluatorCallback</span><span class="p">(</span>
    <span class="n">eval_tensors</span><span class="o">=</span><span class="n">eval_tensors</span><span class="p">,</span>
    <span class="n">user_iter_callback</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">eval_iter_callback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
    <span class="n">user_epochs_done_callback</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">eval_epochs_done_callback</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">intents_label_ids</span><span class="o">=</span><span class="n">data_desc</span><span class="o">.</span><span class="n">intents_label_ids</span><span class="p">,</span>
        <span class="n">slots_label_ids</span><span class="o">=</span><span class="n">data_desc</span><span class="o">.</span><span class="n">slots_label_ids</span><span class="p">,</span>
        <span class="n">graph_fold</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{nf.work_dir}</span><span class="s1">/graphs&#39;</span><span class="p">,</span>
        <span class="n">normalize_cm</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">),</span>
    <span class="n">tb_writer</span><span class="o">=</span><span class="n">nf</span><span class="o">.</span><span class="n">tb_writer</span><span class="p">,</span>
    <span class="n">eval_step</span><span class="o">=</span><span class="n">train_steps_per_epoch</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">ckpt_callback</span> <span class="o">=</span> <span class="n">CheckpointCallback</span><span class="p">(</span>
    <span class="n">folder</span><span class="o">=</span><span class="n">nf</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="n">epoch_freq</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_epoch_freq</span><span class="p">,</span> <span class="n">step_freq</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_step_freq</span>
<span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Finally, we define the optimization parameters and run the whole pipeline.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nemo.utils.lr_policies</span> <span class="kn">import</span> <span class="n">get_lr_policy</span>
<span class="n">lr_policy_fn</span> <span class="o">=</span> <span class="n">get_lr_policy</span><span class="p">(</span>
    <span class="n">args</span><span class="o">.</span><span class="n">lr_policy</span><span class="p">,</span> <span class="n">total_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span> <span class="o">*</span> <span class="n">steps_per_epoch</span><span class="p">,</span> <span class="n">warmup_ratio</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr_warmup_proportion</span>
<span class="p">)</span>

<span class="n">nf</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">tensors_to_optimize</span><span class="o">=</span><span class="p">[</span><span class="n">train_loss</span><span class="p">],</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">train_callback</span><span class="p">,</span> <span class="n">eval_callback</span><span class="p">,</span> <span class="n">ckpt_callback</span><span class="p">],</span>
    <span class="n">lr_policy</span><span class="o">=</span><span class="n">lr_policy_fn</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">optimizer_kind</span><span class="p">,</span>
    <span class="n">optimization_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="model-training">
<h2>Model Training<a class="headerlink" href="#model-training" title="Permalink to this headline">¶</a></h2>
<p>To train an intent detection and slot filling model on a dataset, run <code class="docutils literal notranslate"><span class="pre">joint_intent_slot_with_bert.py</span></code> located at <code class="docutils literal notranslate"><span class="pre">examples/nlp/intent_detection_slot_tagging/joint_intent_slot_with_bert.py</span></code>:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">examples</span><span class="o">/</span><span class="n">nlp</span><span class="o">/</span><span class="n">intent_detection_slot_tagging</span><span class="o">/</span>
<span class="n">python</span> <span class="n">joint_intent_slot_with_bert</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">data_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">data</span><span class="o">&gt;</span>\
    <span class="o">--</span><span class="n">work_dir</span> <span class="o">&lt;</span><span class="n">where</span> <span class="n">you</span> <span class="n">want</span> <span class="n">to</span> <span class="n">log</span> <span class="n">your</span> <span class="n">experiment</span><span class="o">&gt;</span>\
</pre></div>
</div>
</div></blockquote>
<p>By default a folder named “checkpoints” would get created under the working folder specified by <cite>–work_dir</cite> and checkpoints are stored under it.
To do inference with a checkpoint on test set, you may run:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">examples</span><span class="o">/</span><span class="n">nlp</span><span class="o">/</span><span class="n">intent_detection_slot_tagging</span><span class="o">/</span>
<span class="n">python</span> <span class="n">joint_intent_slot_infer</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">data_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">data</span><span class="o">&gt;</span> \
    <span class="o">--</span><span class="n">checkpoint_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">checkpoint</span> <span class="n">folder</span><span class="o">&gt;</span>\
    <span class="o">--</span><span class="n">eval_file_prefix</span> <span class="n">test</span>
</pre></div>
</div>
</div></blockquote>
<p>To do inference on a single query, run:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">examples</span><span class="o">/</span><span class="n">nlp</span><span class="o">/</span><span class="n">intent_detection_slot_tagging</span><span class="o">/</span>
<span class="n">python</span> <span class="n">joint_intent_slot_infer</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">checkpoint_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">checkpoint</span> <span class="n">folder</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">query</span> <span class="o">&lt;</span><span class="n">query</span><span class="o">&gt;</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-nlp/joint_intent_slot_filling-0"><dl class="citation">
<dt class="bibtex label" id="nlp-slot-chen2019bert"><span class="brackets"><a class="fn-backref" href="#id1">NLP-SLOT1</a></span></dt>
<dd><p>Qian Chen, Zhu Zhuo, and Wen Wang. Bert for joint intent classification and slot filling. <em>arXiv preprint arXiv:1902.10909</em>, 2019.</p>
</dd>
</dl>
</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="question_answering.html" class="btn btn-neutral float-right" title="Tutorial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="punctuation.html" class="btn btn-neutral float-left" title="Tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2020, NVIDIA

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>