

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>教程 &mdash; nemo 0.9.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="语音合成" href="../tts/intro.html" />
    <link rel="prev" title="教程" href="joint_intent_slot_filling.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.9.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">如何安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro.html">从这里开始</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">快速训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/intro.html">语音识别</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="intro.html">自然语言处理</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="intro.html#nmt">神经网络机器翻译 (NMT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#bert">BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#transformer">Transformer语言模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#ner">命名实体识别 (NER)</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#intent-and-slot-filling">Intent and Slot filling</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="intro.html#bertx2">用 BERTx2 后处理模型来提升语音识别性能</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">教程</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">数据</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bert">从预训练 BERT 模型中加载参数</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id7">神经模块概览</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">模型训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10">参考</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tts/intro.html">语音合成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">NeMo API</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="intro.html">自然语言处理</a> &raquo;</li>
        
      <li>教程</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/nlp/asr-improvement.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>教程<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>在这个教程中，我们会训练一个后处理模型来纠正端到端语音识别模型的输出错误。这个模型类似于一个翻译模型，但和传统语音识别中的二次打分模型不太一样。
这个模型的架构是基于注意力机制的编码器解码器架构，其中编码器和解码器都是用BERT的预训练语言模型初始化的。为了训练这个模型，我们用预训练的 Jasper 语音识别模型 <a class="reference internal" href="#asr-imps-li2019jasper" id="id2">[ASR-IMPROVEMENTS3]</a> 产生的错误来收集数据集。</p>
<div class="section" id="id3">
<h2>数据<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p><strong>数据收集</strong> 我们用 Jasper <a class="reference internal" href="#asr-imps-li2019jasper" id="id4">[ASR-IMPROVEMENTS3]</a> 在 Librispeech 数据集 <a class="reference internal" href="#asr-imps-panayotov2015librispeech" id="id5">[ASR-IMPROVEMENTS4]</a>  上训练的模型为这个任务收集数据集。
下载 Librispeech 数据集, 参考 <a class="reference internal" href="../asr/datasets.html#librispeech-dataset"><span class="std std-ref">LibriSpeech</span></a> 。
获得 Jasper 预训练模型, 参考 <a class="reference internal" href="../asr/jasper.html#jasper-model"><span class="std std-ref">Jasper</span></a> 。
Librispeech 训练数据集包含三个部分: train-clean-100, train-clean-360, 和 train-clean-500 总共281000个训练样本。
我们用两个方法来扩增数据集：</p>
<ul class="simple">
<li><p>我们把所有的训练集分成10份，然后用交叉验证的方法训练10个 Jasper 模型: 一个模型在9份数据集上训练，然后在剩下的那份数据集上做语音识别。</p></li>
<li><p>我们用预训练的 Jasper 模型，在训练集上做推理的时候，开启 dropout。这个过程用不同的随机种子重复多次。</p></li>
</ul>
<p><strong>数据后处理</strong> 收集到的数据集需要去除重复以及错词率大于0.5的样本。
得到的数据集包含1,700,000对 “坏” 英文-“好” 英文样本对。</p>
<p><strong>开发和测试集准备</strong> Librispeech 包含两个开发集 (dev-clean 和 dev-other) 以及2个测试集 (test-clean 和 test-other)。
在我们的任务中，我们也这么分。我们把这些数据集放到预训练好的 Jasper 模型中，用贪婪算法 (greedy) 解码得到语音识别的输出结果。
这些结果在我们的教程中用来做评测。</p>
</div>
<div class="section" id="bert">
<h2>从预训练 BERT 模型中加载参数<a class="headerlink" href="#bert" title="Permalink to this headline">¶</a></h2>
<p>编码器和解码器用的都是预训练的 BERT 模型参数。 因为 BERT 的语言模型和 Transformer 的编码器结构相同，因此没有其他什么需要做的。从预训练的 BERT 模型中为解码器准备参数，我们写了一个脚本 <code class="docutils literal notranslate"><span class="pre">get_decoder_params_from_bert.py</span></code> 会从 <code class="docutils literal notranslate"><span class="pre">pytorch-transformers</span></code> <a class="reference internal" href="#asr-imps-huggingface2019transformers" id="id6">[ASR-IMPROVEMENTS1]</a> 下载参数，并把他们映射到解码器的参数上.
编码器和解码器的注意力是用 self-attention 参数做初始化的。
这个脚本位于 <code class="docutils literal notranslate"><span class="pre">scripts</span></code> 文件目录下，接受两个参数：</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">--model_name</span></code>: 模型名称，可选择 <code class="docutils literal notranslate"><span class="pre">bert-base-cased</span></code>, <code class="docutils literal notranslate"><span class="pre">bert-base-uncased</span></code> 等参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--save_to</span></code>: 指定保存目录</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python get_decoder_params_from_bert.py --model_name bert-base-uncased
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id7">
<h2>神经模块概览<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>首先，因为所有的模块都是由NeMo构建的，我们需要初始化 <code class="docutils literal notranslate"><span class="pre">NeuralModuleFactory</span></code> ，我们需要定义 1) backend (目前只支持PyTorch)，2) 混精度优化等级，3) GPU的loca rank以及，4) 一个实验管理器，创建一个时间戳的文件夹来存储 checkpoints 和相关的输出，日志文件以及 TensorBoard 的图。</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nf</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">NeuralModuleFactory</span><span class="p">(</span>
                <span class="n">backend</span><span class="o">=</span><span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Backend</span><span class="o">.</span><span class="n">PyTorch</span><span class="p">,</span>
                <span class="n">local_rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
                <span class="n">optimization_level</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">amp_opt_level</span><span class="p">,</span>
                <span class="n">log_dir</span><span class="o">=</span><span class="n">work_dir</span><span class="p">,</span>
                <span class="n">create_tb_writer</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                <span class="n">files_to_copy</span><span class="o">=</span><span class="p">[</span><span class="vm">__file__</span><span class="p">])</span>
</pre></div>
</div>
</div></blockquote>
<p>接着我们定义分词器(tokenizer)，把所有的词转到它们对应的序号上。我们会使用 <code class="docutils literal notranslate"><span class="pre">bert-base-uncased</span></code> 模型的词表，因为我们的数据集只包含不区分大小写的文本：</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">NemoBertTokenizer</span><span class="p">(</span><span class="n">pretrained_model</span><span class="o">=</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>编码器模块对应于 BERT 的语言模型，它来自于 <code class="docutils literal notranslate"><span class="pre">nemo_nlp.huggingface</span></code> 模块：</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">zeros_transform</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">ZerosLikeNM</span><span class="p">()</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">huggingface</span><span class="o">.</span><span class="n">BERT</span><span class="p">(</span>
    <span class="n">pretrained_model_name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model</span><span class="p">,</span>
    <span class="n">local_rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>让词嵌入的大小（包括其他的张量维度）能够整除8可以得到最好的GPU利用率和混精度训练加速。</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">8</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">/</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">tokens_to_add</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span>
<span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">tokens_to_add</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">encoder</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
    <span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">zeros</span><span class="p">))</span>
</pre></div>
</div>
</div></blockquote>
<p>接着, 我们构建 Transformer 解码器神经模块. 因为我们会用 BERT 预训练的参数来初始化我们的解码器, 我们设置隐藏层激活函数为 <code class="docutils literal notranslate"><span class="pre">&quot;hidden_act&quot;:</span> <span class="pre">&quot;gelu&quot;</span></code> 以及设置学习位置编码 <code class="docutils literal notranslate"><span class="pre">&quot;learn_positional_encodings&quot;:</span> <span class="pre">True</span></code> :</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">TransformerDecoderNM</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
    <span class="n">d_inner</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">d_inner</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
    <span class="n">num_attn_heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span>
    <span class="n">ffn_dropout</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ffn_dropout</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
    <span class="n">max_seq_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
    <span class="n">embedding_dropout</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">embedding_dropout</span><span class="p">,</span>
    <span class="n">learn_positional_encodings</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">dec_first_sublayer_params</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>为了把预训练参数加载到解码器参数中, 我们用解码器神经模块的属性函数 <code class="docutils literal notranslate"><span class="pre">restore_from</span></code> 来加载:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span><span class="o">.</span><span class="n">restore_from</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">restore_from</span><span class="p">,</span> <span class="n">local_rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="id8">
<h2>模型训练<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>训练模型，运行 <code class="docutils literal notranslate"><span class="pre">asr_postprocessor.py.py</span></code> ，它位于 <code class="docutils literal notranslate"><span class="pre">examples/nlp</span></code> 目录中。我们用 novograd 优化器来训练 <a class="reference internal" href="#asr-imps-ginsburg2019stochastic" id="id9">[ASR-IMPROVEMENTS2]</a>, 设置学习率 <code class="docutils literal notranslate"><span class="pre">lr=0.001</span></code> ，多项式学习率衰减策略, <code class="docutils literal notranslate"><span class="pre">1000</span></code> 步预热, 每个GPU的 batch size 为 <code class="docutils literal notranslate"><span class="pre">4096*8</span></code> 个符号, 以及 <code class="docutils literal notranslate"><span class="pre">0.25</span></code> dropout 概率。我们在8块GPU上做训练，可以用下面的方法开启多GPU训练模式:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python -m torch.distributed.launch --nproc_per_node<span class="o">=</span><span class="m">8</span>  asr_postprocessor.py --data_dir ../../tests/data/pred_real/ --restore_from ../../scripts/bert-base-uncased_decoder.pt
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="id10">
<h2>参考<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-nlp/asr-improvement-0"><dl class="citation">
<dt class="label" id="asr-imps-huggingface2019transformers"><span class="brackets"><a class="fn-backref" href="#id6">ASR-IMPROVEMENTS1</a></span></dt>
<dd><p>A library of state-of-the-art pretrained models for natural language processing (nlp). <span><a class="reference external" href="#"></a></span>https://github.com/huggingface/pytorch-transformers, Accessed August 23, 2019.</p>
</dd>
<dt class="label" id="asr-imps-ginsburg2019stochastic"><span class="brackets"><a class="fn-backref" href="#id9">ASR-IMPROVEMENTS2</a></span></dt>
<dd><p>Boris Ginsburg, Patrice Castonguay, Oleksii Hrinchuk, Oleksii Kuchaiev, Vitaly Lavrukhin, Ryan Leary, Jason Li, Huyen Nguyen, and Jonathan M Cohen. Stochastic gradient methods with layer-wise adaptive moments for training of deep networks. <em>arXiv preprint arXiv:1905.11286</em>, 2019.</p>
</dd>
<dt class="label" id="asr-imps-li2019jasper"><span class="brackets">ASR-IMPROVEMENTS3</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>Jason Li, Vitaly Lavrukhin, Boris Ginsburg, Ryan Leary, Oleksii Kuchaiev, Jonathan M Cohen, Huyen Nguyen, and Ravi Teja Gadde. Jasper: an end-to-end convolutional neural acoustic model. <em>arXiv preprint arXiv:1904.03288</em>, 2019.</p>
</dd>
<dt class="label" id="asr-imps-panayotov2015librispeech"><span class="brackets"><a class="fn-backref" href="#id5">ASR-IMPROVEMENTS4</a></span></dt>
<dd><p>Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech: an asr corpus based on public domain audio books. In <em>2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 5206–5210. IEEE, 2015.</p>
</dd>
</dl>
</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../tts/intro.html" class="btn btn-neutral float-right" title="语音合成" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="joint_intent_slot_filling.html" class="btn btn-neutral float-left" title="教程" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2019, NVIDIA

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>