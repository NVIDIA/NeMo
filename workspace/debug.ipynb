{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def random_masking(x, mask_ratio):\n",
    "    \"\"\"\n",
    "    Perform per-sample random masking by per-sample shuffling.\n",
    "    Per-sample shuffling is done by argsort random noise.\n",
    "    x: [N, L, D], sequence\n",
    "    \"\"\"\n",
    "    N, L, D = x.shape  # batch, length, dim\n",
    "    len_keep = int(L * (1 - mask_ratio))\n",
    "    \n",
    "    noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "    \n",
    "    # sort noise for each sample\n",
    "    ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "    ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "    # keep the first subset\n",
    "    ids_keep = ids_shuffle[:, :len_keep]\n",
    "    x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "    # generate the binary mask: 0 is keep, 1 is remove\n",
    "    mask = torch.ones([N, L], device=x.device)\n",
    "    mask[:, :len_keep] = 0\n",
    "    # unshuffle to get the binary mask\n",
    "    mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "\n",
    "    return x_masked, mask, ids_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 16])\n",
      "torch.Size([2, 10])\n",
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 10, 16)\n",
    "x_masked, mask, ids_restore = random_masking(x, 0.2)\n",
    "print(x_masked.shape)\n",
    "print(mask.shape)\n",
    "print(ids_restore.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 8, 3])\n",
      "tensor(0.) tensor(25.1454)\n",
      "torch.Size([2, 5, 8, 3])\n",
      "torch.Size([2, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "class RandomProjectionVectorQuantizer(nn.Module):\n",
    "    DIST_FN_LIST = [\"l2\", \"cosine\"]\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_classes: int,\n",
    "        num_books: int,\n",
    "        dist_fn: str = \"cosine\",\n",
    "        time_first: bool = False,\n",
    "        freeze: bool = True,\n",
    "    ):\n",
    "        \"\"\"Vector quantization using random projection\n",
    "\n",
    "         Args:\n",
    "            dim: input dimension (channels)\n",
    "            num_classes: number of quantized vectors per group\n",
    "            num_groups: number of codebooks to use\n",
    "            vq_dim: dimensionality of the resulting quantized vector\n",
    "            time_first: if true, expect input in BxTxC format, otherwise in BxCxT\n",
    "            activation: what activation to use (should be a module).\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if dist_fn not in self.DIST_FN_LIST:\n",
    "            raise ValueError(f\"Unknown distance function {dist_fn}, must be one of {self.DIST_FN_LIST}\")\n",
    "\n",
    "        self.feat_dim = feat_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.num_books = num_books\n",
    "        self.dist_fn = dist_fn\n",
    "        self.time_first = time_first\n",
    "\n",
    "        # (B, T, D) -> (B, T, num_books, hidden_dim)\n",
    "        self.proj = nn.Linear(self.feat_dim, self.num_books*self.hidden_dim, bias=False).requires_grad_(not freeze)\n",
    "        torch.nn.init.xavier_normal_(self.proj.weight)\n",
    "    \n",
    "        # (num_books, num_classes, hid_dim)\n",
    "        codebooks = nn.Parameter(torch.FloatTensor(self.num_books, self.num_classes, self.hidden_dim)).requires_grad_(not freeze)\n",
    "        torch.nn.init.normal_(codebooks, mean=0, std=1)\n",
    "        self.codebooks = F.normalize(codebooks, dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, T, D) or (B, D, T)\n",
    "        Returns:\n",
    "            xq: (B, N, T, D) or (B, N, D, T)\n",
    "            xid: (B, N, T)\n",
    "        \"\"\"\n",
    "        if not self.time_first:\n",
    "            # (B, D, T) -> (B, T, D)\n",
    "            x = x.transpose(1, 2)\n",
    "\n",
    "        B, T, _ = x.size()\n",
    "\n",
    "        # (B, T, D) -> (B, T, num_books*hidden_dim)\n",
    "        x = self.proj(x)\n",
    "\n",
    "        # (B, T, num_books*hidden_dim) -> (B, T, num_books, hidden_dim)\n",
    "        x = F.normalize(x.view(B, T, self.num_books, self.hidden_dim), dim=-1)\n",
    "\n",
    "        # get tokens (xid) of shape (B, T, num_books)\n",
    "        if self.dist_fn == \"cosine\":\n",
    "            # (B, T, num_books, hidden_dim) -> (B, T, num_books, num_classes)\n",
    "            xid = torch.einsum('btdh,dch->btdc', x, self.codebooks)\n",
    "            # (B, T, num_books, num_classes) -> (B, T, num_books)\n",
    "            xid = xid.max(dim=-1)[1]\n",
    "        elif self.dist_fn == \"l2\":\n",
    "            # (B, T, num_books, hidden_dim) -> (B, T, num_books, hidden_dim, num_classes)\n",
    "            xid = x.unsqueeze(-1) - self.codebooks.transpose(1,2).unsqueeze(0).unsqueeze(0)\n",
    "            xid = xid.norm(dim=-2).argmin(dim=-1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown distance function {self.dist_fn}, must be one of {self.DIST_FN_LIST}\")\n",
    "        \n",
    "        \n",
    "        # xid2: (B, T, num_books) -> (B, T, num_books)\n",
    "        xid2 = xid + self.num_classes*torch.arange(self.num_books, device=xid.device).unsqueeze(0).unsqueeze(0)\n",
    "        # xid2: (B, T, num_books) -> (B*num_books, T)\n",
    "        xid2 = xid2.transpose(1,2).contiguous().view(-1, T)\n",
    "        \n",
    "        # get quantized vector (xq) of shape (B, T, hidden_dim, num_books)\n",
    "        # codebook: (num_books, num_classes, hidden_dim) -> (num_books*num_classes, hidden_dim)\n",
    "        xq = F.embedding(xid2.view(-1), self.codebooks.view(-1, self.hidden_dim)).view(B, T, self.hidden_dim, self.num_books)\n",
    "    \n",
    "        if not self.time_first:\n",
    "            # (B, T, D) -> (B, D, T)\n",
    "            xq = xq.transpose(1, 2)\n",
    "        return xq, xid\n",
    "\n",
    "quantizer = RandomProjectionVectorQuantizer(16, 8, 6, 3, time_first=True)\n",
    "x = torch.rand(2, 5, 16)\n",
    "xid = quantizer(x)\n",
    "print(xid.shape)\n",
    "# quantizer = RandomProjectionVectorQuantizer(16, 8, 6, 3, time_first=True, dist_fn=\"l2\")\n",
    "# x = torch.rand(2, 10, 16)\n",
    "# xid = quantizer(x)\n",
    "# print(xid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "tensor([[[0., 1., 2.],\n",
      "         [0., 1., 2.],\n",
      "         [0., 1., 2.],\n",
      "         [0., 1., 2.]],\n",
      "\n",
      "        [[0., 1., 2.],\n",
      "         [0., 1., 2.],\n",
      "         [0., 1., 2.],\n",
      "         [0., 1., 2.]]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.zeros(2, 4, 3)\n",
    "t2 = torch.arange(3, device=xid.device).unsqueeze(0).unsqueeze(0)\n",
    "print(t1)\n",
    "print(t1+t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLMLoss(nn.Module):\n",
    "    def __init__(self, combine_time_steps: int = 1, mask_threshold: float = 0.8,):\n",
    "        super().__init__()\n",
    "        self.nll_loss = nn.NLLLoss()\n",
    "        self.combine_time_steps = combine_time_steps\n",
    "        self.mask_threshold = mask_threshold\n",
    "\n",
    "    def forward(self, spec_masks, decoder_outputs, targets, decoder_lengths=None, target_lengths=None, masks=None):\n",
    "\n",
    "        if masks is None:\n",
    "            masks = spec_masks\n",
    "\n",
    "        # B,D,T -> B,T,D\n",
    "        masks = masks.transpose(1, 2)\n",
    "\n",
    "        masks = masks.reshape(masks.shape[0], masks.shape[1] // self.combine_time_steps, -1)\n",
    "        masks = masks.mean(-1) > self.mask_threshold\n",
    "\n",
    "        out_masked_only = decoder_outputs[masks]\n",
    "        targets = F.pad(targets, (0, masks.shape[-1] - targets.shape[-1]))\n",
    "        targets_masked_only = targets[masks]\n",
    "\n",
    "        loss = self.nll_loss(out_masked_only, targets_masked_only)\n",
    "        loss = torch.mean(loss)\n",
    "\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.arange(12).reshape(2, 6)\n",
    "m1 = torch.tensor([[0, 1, 1, 0, 1, 0], [1, 1, 0, 1, 0, 1]]).bool()\n",
    "t2 = t1[m1]\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def process_audio_file_pathlib(audio_file, manifest_file, data_dir=None):\n",
    "    audio_file = Path(audio_file)\n",
    "\n",
    "    if (len(str(audio_file)) < 255) and not audio_file.is_absolute() and not audio_file.is_file():\n",
    "        # If audio_file is not available and the path is not absolute, the full path is assumed\n",
    "        # to be relative to the manifest file parent directory or data directory.\n",
    "\n",
    "        # resolve the data directory\n",
    "        if data_dir is None:\n",
    "            data_dir = Path(manifest_file).parent.as_posix()\n",
    "\n",
    "        # assume audio_file path is relative to data_dir\n",
    "        audio_file_path = Path(data_dir, audio_file)\n",
    "        return audio_file_path.as_posix()\n",
    "    return audio_file.as_posix()\n",
    "\n",
    "def process_audio_file_os(audio_file, manifest_file, data_dir=None):\n",
    "    \n",
    "    if (len(str(audio_file)) < 255) and not os.path.isabs(audio_file) and not os.path.exists(audio_file):\n",
    "        # If audio_file is not available and the path is not absolute, the full path is assumed\n",
    "        # to be relative to the manifest file parent directory or data directory.\n",
    "\n",
    "        # resolve the data directory\n",
    "        if data_dir is None:\n",
    "            data_dir = os.path.dirname(manifest_file)\n",
    "            \n",
    "        # assume audio_file path is relative to data_dir\n",
    "        audio_file_path = os.path.join(data_dir, audio_file)\n",
    "        return audio_file_path\n",
    "    return audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_pathlib(num=50000):\n",
    "    for _ in range(num):\n",
    "        process_audio_file_pathlib(\"audios/test.wav\", \"/a/b/c/d/test.json\")\n",
    "\n",
    "def test_os_lib(num=50000):\n",
    "    for _ in range(num):\n",
    "        process_audio_file_os(\"audios/test.wav\", \"/a/b/c/d/test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.96 s ± 24 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test_pathlib(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.64 s ± 9.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test_os_lib(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_pathlib2(num=50000):\n",
    "    for _ in range(num):\n",
    "        process_audio_file_pathlib(\"/a/audios/test.wav\", \"/a/b/c/d/test.json\")\n",
    "\n",
    "def test_os_lib2(num=50000):\n",
    "    for _ in range(num):\n",
    "        process_audio_file_os(\"/a/audios/test.wav\", \"/a/b/c/d/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95 s ± 11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test_pathlib2(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 ms ± 1.78 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test_os_lib2(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "input_manifest = 'tarred_audio_manifest.json'\n",
    "\n",
    "def load_manifest(filepath):\n",
    "    data = []\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def write_manifest(filepath, data):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for d in data:\n",
    "            f.write(json.dumps(d) + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifests = load_manifest(input_manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(manifests)\n",
    "new_manifests = manifests[:400]\n",
    "write_manifest('tarred_audio_manifest_400.json', new_manifests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
