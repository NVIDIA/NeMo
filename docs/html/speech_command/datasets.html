

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Datasets &mdash; nemo 0.10.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Models" href="models.html" />
    <link rel="prev" title="Tutorial" href="tutorial.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.10.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Fast Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/intro.html">Speech Recognition</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="intro.html">Speech Commands</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#google-speech-commands-dataset">Google Speech Commands Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataset">Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="models.html">Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nlp/intro.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tts/intro.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">NeMo API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chinese/intro.html">中文支持</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="intro.html">Speech Commands</a> &raquo;</li>
        
      <li>Datasets</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/speech_command/datasets.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="datasets">
<h1>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h1>
<div class="section" id="google-speech-commands-dataset">
<span id="googlespeechcommands-dataset"></span><h2>Google Speech Commands Dataset<a class="headerlink" href="#google-speech-commands-dataset" title="Permalink to this headline">¶</a></h2>
<p>The ability to recognize spoken commands with high accuracy can be useful in a variety of contexts.
To this end, Google released the Speech Commands dataset (see <a class="bibtex reference internal" href="#speech-recognition-dataset-warden2018speech" id="id1">[SPEECH-RECOGNITION-DATASET1]</a>,
which contains short audio clips of a fixed number of command words such as “stop”, “go”, “up”, “down”, etc spoken by a large number of speakers.
To promote the use of the set, Google also hosted a Kaggle competition, in which the winning team attained a multi-class accuracy of 91%.</p>
<p>We experimented with applying NeMo’s ASR classification models on mel spectrogram of the audio clips and found that they worked surprisingly well.
Adding data augmentation further improved the results.</p>
</div>
<div class="section" id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h2>
<p>Google released two versions of the dataset with the first version containing 65k samples over 30 classes and the second containing 110k samples over 35 classes.
We refer to these datasets as v1 and v2, and currently we have metrics for v1 version in order to compare to the different metrics used by other papers.</p>
<p>Run the script <cite>process_speech_commands_data.py</cite> to process Google Speech Commands dataset in order to generate files in the supported format of  <cite>nemo_asr</cite>,
which can be found in the <cite>scripts</cite> sub-directory of the nemo base directory. You should set the data folder of Speech Commands using <cite>–data_root</cite> and the version of the dataset using <cite>–data_version</cite> as an int.</p>
<p>You can further rebalance the train set by passing the <cite>–rebalance</cite> flag.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python process_speech_commands_data.py --data_root<span class="o">=</span>&lt;data directory&gt; --data_version<span class="o">=</span>&lt;<span class="m">1</span> or <span class="m">2</span>&gt; <span class="o">{</span>--rebalance<span class="o">}</span>
</pre></div>
</div>
<p>Then, you should have <cite>train_manifest.json</cite>, <cite>validation_manifest.json</cite> and <cite>test_manifest.json</cite>
in the directory <cite>{data_root}/google_speech_recognition_v{1/2}</cite>.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-speech_command/datasets-0"><dl class="citation">
<dt class="bibtex label" id="speech-recognition-dataset-warden2018speech"><span class="brackets"><a class="fn-backref" href="#id1">SPEECH-RECOGNITION-DATASET1</a></span></dt>
<dd><p>Pete Warden. Speech commands: a dataset for limited-vocabulary speech recognition. <em>arXiv preprint arXiv:1804.03209</em>, 2018.</p>
</dd>
</dl>
</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="models.html" class="btn btn-neutral float-right" title="Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="tutorial.html" class="btn btn-neutral float-left" title="Tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2020, NVIDIA

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>