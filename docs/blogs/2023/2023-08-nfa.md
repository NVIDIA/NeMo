---
title: Introducing NeMo Forced Aligner
author: [Elena Rastorgueva]
author_gh_user: [erastorgueva-nv]
read_time: 2 minutes
publish_date: 08/14/2023

# DO NOT CHANGE BELOW
template: blog.html
---

# Introducing NeMo Forced Aligner

Today we introduce [NeMo Forced Aligner](https://github.com/NVIDIA/NeMo/tree/main/tools/nemo_forced_aligner): a [NeMo](https://github.com/NVIDIA/NeMo/tree/main)-based tool for forced alignment.

NFA allows you to obtain token-level, word-level and segment-level timestamps for words spoken in an audio file. NFA produces timestamp information in a variety of output file formats, including subtitle files, which you can use to create videos such as the one below[^butter_betty_bought]:

<figure markdown>
  ![type:video](https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/asset-post-2023-08-forced-alignment-butter_betty_bought_words_aligned.mp4)
  <figcaption>Video with words highlighted according to word alignment timestamps obtained with NFA</figcaption>
</figure>

Ways to get started:

* [Try out](https://huggingface.co/spaces/erastorgueva-nv/NeMo-Forced-Aligner) our HuggingFace Space demo to quickly try out NFA in various languages.
* [Follow along](https://colab.research.google.com/github/NVIDIA/NeMo/blob/main/tutorials/tools/NeMo_Forced_Aligner_Tutorial.ipynb) with our step-by-step NFA "how-to" tutorial.
* [Learn more](./2023-08-forced-alignment.md) about how forced alignment works in this explainer tutorial.


You can also download [NFA](https://github.com/NVIDIA/NeMo/tree/main/tools/nemo_forced_aligner) from the [NeMo](https://github.com/NVIDIA/NeMo/tree/main) repository.

You can use NFA timestamps to:

* Split audio files into shorter segments
* Generate token- or word-level subtitles, like in our [HuggingFace Space](https://huggingface.co/spaces/erastorgueva-nv/NeMo-Forced-Aligner)
* Train token/word duration components of text-to-speech or speaker diarization models

NFA alignment timestamps can be based on reference text that you provide, or reference text obtained from speech-to-text transcription from a NeMo model. NFA works on audio in 14+ languages: it will work any of the 14 (and counting) languages for which there is an open-sourced NeMo speech-to-text [model checkpoint](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/results.html#speech-recognition-languages), or you can train your own ASR model for a new language.

<figure markdown>
  ![NFA pipeline](https://github.com/NVIDIA/NeMo/releases/download/v1.20.0/nfa_forced_alignment_pipeline.png)
  <figcaption>The NFA forced alignment pipeline</figcaption>
</figure>


[^butter_betty_bought]: This video is of an excerpt from 'The Jingle Book' by Carolyn Wells. The audio is a reading of a poem called "The Butter Betty Bought". The audio is taken from a [LibriVox recording](https://www.archive.org/download/jingle_book_blb_librivox/jinglebook_03_wells.mp3) of the [book](https://librivox.org/the-jingle-book-by-carolyn-wells/). We used NeMo Forced Aligner to generate the subtitle files for the video. The text was adapted from [Project Gutenberg](https://www.gutenberg.org/cache/epub/24560/pg24560.txt). Both the original audio and the text are in the public domain.
