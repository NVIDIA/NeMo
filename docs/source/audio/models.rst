Models
=======
This section provides a brief overview of models that NeMo's audio collection currently supports.

* **Model Recipes** can be accessed through `examples/audio <https://github.com/NVIDIA/NeMo/tree/stable/examples/audio>`_.
* **Configuration Files** can be found in the directory of `examples/audio/conf <https://github.com/NVIDIA/NeMo/tree/stable/examples/audio/conf>`_. For detailed information about configuration files and how they
  should be structured, please refer to the section :doc:`./configs`.
* **Pretrained Model Checkpoints** are available for any users for immediately synthesizing speech or fine-tuning models on
  your custom datasets. Please follow the section :doc:`./checkpoints` for instructions on how to use those pretrained models.


Encoder-Mask-Decoder Model
~~~~~~~~~~~~~~~~~~~~~~~~~~
Encoder-Mask-Decoder model is a general model consisting of an encoder, a mask estimator, a mask processor and a decoder. The encoder processes the input audio signal and produces a latent representation. The mask estimator estimates the mask from the latent representation. The mask processor processes the mask and the latent representation to produce a processed latent representation. The decoder processes the processed latent representation to produce the output audio signal. The model can be used for various tasks such as speech enhancement or speech separation.
The encoder and decoder can be learned or fixed, such as the `short-time Fourier transform (STFT) <https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/audio/modules/transforms.py#L34>`_ and `inverse STFT <https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/audio/modules/transforms.py#L306>`_ modules, respectively.
The mask estimator can be a neural model, such as `multi-channel mask estimator <https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/audio/modules/masking.py#L202>`_ :cite:`audio-models-jukic2023flexible` or a non-neural model, such as `guided source separation (GSS) <https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/audio/modules/masking.py#L451>`_ :cite:`audio-models-ito2016directional`.
The mask processor can be either simple masking, or a parametric multichannel Wiener filter :cite:`audio-models-jukic2023flexible`.


Predictive Model
~~~~~~~~~~~~~~~~
Predictive model is similar to the encoder-mask-decoder model, but the mask estimator and mask processor are replaced by a neural estimator. The predictive model estimates the latent representation of the target output signal from the input audio signal :cite:`audio-models-richter2023sgmse,audio-models-jukic2024sb`. The model can be used for various tasks such as speech enhancement or speech separation.


Score-Based Generative Model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Score-based generative model is a diffusion-based generative model that estimates the score function of the data distribution :cite:`audio-models-welker2022speech,audio-models-richter2023sgmse`. The model consists of an encoder and decoder, a neural score estimator, a stochastic differential equation (SDE) model and a sampler.


Schrödinger Bridge Model
~~~~~~~~~~~~~~~~~~~~~~~~
Schrödinger bridge model is a generative model using a data-to-data process to transform the input (degraded) audio signal into the target (clean) audio signal :cite:`audio-models-jukic2024sb`. The model consists of an encoder and decoder, a neural estimator, noise schedule and a sampler.


Flow Matching Model
~~~~~~~~~~~~~~~~~~~
Flow matching model is a generative model using a noise-to-data process to transform the input (degraded) audio signal into the target (clean) audio signal :cite:`audio-models-ku2024generative`. The model consists of an encoder and decoder, a neural estimator, a flow model and a sampler.


References
----------

.. bibliography:: audio_all.bib
    :style: plain
    :labelprefix: AUDIO-
    :keyprefix: audio-models-