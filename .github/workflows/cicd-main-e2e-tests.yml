name: NeMo E2E Tests
on:
  workflow_call:
    inputs:
      test_to_run:
        required: true
        type: string

jobs:
  # L2: Community llava multimodal Checkpoints tests
  L2_Community_vita_Checkpoints_tests_Llama3:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_Community_vita_Checkpoints_tests_Llama3

  L2_Speech_to_Text_EMA:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speech_to_Text_EMA

  L2_Speech_to_Text_AED:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_Speech_to_Text_AED

  # L2: Speaker dev run
  L2_Speaker_dev_run_Speaker_Recognition:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_Speaker_dev_run_Speaker_Recognition

  L2_Speaker_dev_run_Speaker_Diarization:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_Speaker_dev_run_Speaker_Diarization

  L2_Speaker_dev_run_EndtoEnd_Speaker_Diarization_Sortformer:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_Speaker_dev_run_EndtoEnd_Speaker_Diarization_Sortformer

  L2_Speaker_dev_run_EndtoEnd_Diarizer_Inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speaker_dev_run_EndtoEnd_Diarizer_Inference

  L2_Speaker_dev_run_Speech_to_Label:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_Speaker_dev_run_Speech_to_Label

  L2_Speaker_dev_run_Speaker_Diarization_with_ASR_Inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speaker_dev_run_Speaker_Diarization_with_ASR_Inference

  L2_Speaker_dev_run_Clustering_Diarizer_Inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speaker_dev_run_Clustering_Diarizer_Inference

  L2_Speaker_dev_run_Neural_Diarizer_Inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speaker_dev_run_Neural_Diarizer_Inference

  L2_Speaker_dev_run_Multispeaker_ASR_Data_Simulation:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speaker_dev_run_Multispeaker_ASR_Data_Simulation

  # L2: ASR Multi-dataloader dev run
  L2_ASR_Multi-dataloader_dev_run_Speech_to_Text_multi-dataloader:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_ASR_Multi-dataloader_dev_run_Speech_to_Text_multi-dataloader

  L2_ASR_Multi-dataloader_dev_run_Speech_to_Label_multi-dataloader:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_ASR_Multi-dataloader_dev_run_Speech_to_Label_multi-dataloader

  # L2: ASR Adapters
  L2_ASR_Adapters_Linear_Adapters:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_ASR_Adapters_Linear_Adapters

  L2_ASR_Adapters_RelPos_MHA_Adapters:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_ASR_Adapters_RelPos_MHA_Adapters

  # L2: OOMptimizer
  L2_Speech_Estimate_Duration_Bins:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speech_Estimate_Duration_Bins

  # L2: OOMptimizer
  L2_Speech_Batch_Size_OOMptimizer:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speech_Batch_Size_OOMptimizer

  # L2: OOMptimizer Canary (has a different batch schema)
  Optional_L2_Speech_Batch_Size_OOMptimizer_Canary:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: Optional_L2_Speech_Batch_Size_OOMptimizer_Canary
      IS_OPTIONAL: true

  # L2: Speech Transcription
  L2_Speech_Transcription_Speech_to_Text_Transcribe:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speech_Transcription_Speech_to_Text_Transcribe

  # L2: Speech Transcription
  L2_Speech_Transcription_Canary_Transcribe_Full_Manifest:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speech_Transcription_Canary_Transcribe_Full_Manifest

  L2_Speech_Transcription_Canary_Transcribe_With_Prompt:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speech_Transcription_Canary_Transcribe_With_Prompt

  L2_Speech_Transcription_Canary_Transcribe_Audio_Dir:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Speech_Transcription_Canary_Transcribe_Audio_Dir
      IS_OPTIONAL: true

  # L2: Longform without TimeStamps from Audio Dir
  L2_Longform_Speech_Transcription_Canary_Chunked_Infer_from_Audio_Dir:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Longform_Speech_Transcription_Canary_Chunked_Infer_from_Audio_Dir

  # L2: Longform with TimeStamps from Audio Dir
  L2_Longform_Speech_Transcription_with_TimeStamps_Canary_Chunked_Infer_from_Audio_Dir:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Longform_Speech_Transcription_with_TimeStamps_Canary_Chunked_Infer_from_Audio_Dir

  # L2: Longform with TimeStamps from manifest
  L2_Longform_Speech_Transcription_with_TimeStamps_Canary_Chunked_Infer_from_Manifest:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Longform_Speech_Transcription_with_TimeStamps_Canary_Chunked_Infer_from_Manifest

  # L2: Segmentation Tool
  L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Eng_CitriNet_with_wav:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Eng_CitriNet_with_wav

  Optional_L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Ru_QN_with_mp3:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Ru_QN_with_mp3
      IS_OPTIONAL: true

  # L2: G2P Models
  L2_G2P_Models_G2P_Conformer_training_evaluation_and_inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_G2P_Models_G2P_Conformer_training_evaluation_and_inference

    # TODO: pleasefixme @redoctopus
    # - name: ByT5G2P training, evaluation and inference
    #   run: |
    #     cd examples/tts/g2p && \
    #         TIME=`date +"%Y-%m-%d-%T"` && OUTPUT_DIR_T5=output_byt5_${TIME} && \
    #         python g2p_train_and_evaluate.py \
    #             train_manifest=/home/TestData/g2p/g2p.json \
    #             validation_manifest=/home/TestData/g2p/g2p.json \
    #             model.test_ds.manifest_filepath=/home/TestData/g2p/g2p.json \
    #             trainer.max_epochs=1 \
    #             model.max_source_len=64 \
    #             trainer.devices=1 \
    #             do_training=True \
    #             do_testing=True \
    #             exp_manager.exp_dir=${OUTPUT_DIR_T5} \
    #             +exp_manager.use_datetime_version=False\
    #             +exp_manager.version=test && \
    #         python g2p_inference.py \
    #             pretrained_model=${OUTPUT_DIR_T5}/T5G2P/test/checkpoints/T5G2P.nemo \
    #             manifest_filepath=/home/TestData/g2p/g2p.json \
    #             phoneme_field=text
    #   }
    # }
    # - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
    # if: "failure()"

  L2_G2P_Models_HeteronymClassificationModel_training_evaluation_and_inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_G2P_Models_HeteronymClassificationModel_training_evaluation_and_inference

  # TODO: remove +model.optim.capturable=True when Pytorch fix: https://github.com/pytorch/pytorch/pull/81858
  # is in the release container
  # L2: NMT Attention is All You Need Training
  L2_NMT_Attention_is_All_You_Need_Training_NMT_Training_Post-LN:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NMT_Attention_is_All_You_Need_Training_NMT_Training_Post-LN

  L2_NMT_Attention_is_All_You_Need_Training_NMT_Training_Pre-LN:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NMT_Attention_is_All_You_Need_Training_NMT_Training_Pre-LN

  L2_NMT_Attention_is_All_You_Need_Training_NMT_Multi-Validation:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NMT_Attention_is_All_You_Need_Training_NMT_Multi-Validation

  # L2: NMT Attention is All You Need Inference
  L2_NMT_Attention_is_All_You_Need_Inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NMT_Attention_is_All_You_Need_Inference

  # L2: NMT Attention is All You Need Finetuning
  L2_NMT_Attention_is_All_You_Need_Finetuning:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NMT_Attention_is_All_You_Need_Finetuning

  # L2: NMT Tarred Dataset Creation
  L2_NMT_Tarred_Dataset_Creation_Auto_Tarred_Dataset_Creation:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NMT_Tarred_Dataset_Creation_Auto_Tarred_Dataset_Creation

  L2_NMT_Tarred_Dataset_Creation_Script_Tarred_Dataset_Creation:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NMT_Tarred_Dataset_Creation_Script_Tarred_Dataset_Creation

  L2_VLM_HF_Transformer_PEFT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_VLM_HF_Transformer_PEFT

  L2_VLM_HF_Transformer_PEFT_FSDP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_VLM_HF_Transformer_PEFT_FSDP2

  L2_VLM_HF_Transformer_PEFT_4bit:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_VLM_HF_Transformer_PEFT_4bit

  L2_VLM_HF_Transformer_SFT_FSDP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_VLM_HF_Transformer_SFT_FSDP2

  L2_HF_Transformer_PEFT_notebook:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PEFT_notebook

  L2_HF_Transformer_PEFT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_PEFT

  L2_HF_Transformer_PEFT_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_PEFT_nemorun

  L2_HF_Transformer_PEFT_2gpu:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PEFT_2gpu

  L2_HF_Transformer_PEFT_2gpu_FSDP2_liger:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PEFT_2gpu_FSDP2_liger

  L2_HF_Transformer_PEFT_2gpu_FSDP2_fp8:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: azure-gpu-vm-runner1-h100
      SCRIPT: L2_HF_Transformer_PEFT_2gpu_FSDP2_fp8
      IS_OPTIONAL: true

  L2_HF_Transformer_PEFT_2gpu_FSDP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PEFT_2gpu_FSDP2

  L2_HF_Transformer_PEFT_2gpu_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PEFT_2gpu_nemorun

  L2_HF_Transformer_SFT_2gpu:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_2gpu

  L2_HF_Transformer_SFT_2gpu_FSDP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_2gpu_FSDP2

  L2_HF_Transformer_SFT_2gpu_FSDP2_fp8:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: azure-gpu-vm-runner1-h100
      SCRIPT: L2_HF_Transformer_SFT_2gpu_FSDP2_fp8
      IS_OPTIONAL: true

  L2_HF_Transformer_SFT_2gpu_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_2gpu_nemorun

  L2_HF_Transformer_SFT_2gpu_nemorun_fsdp2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_2gpu_nemorun_fsdp2

  L2_HF_Transformer_SFT_FSDP2_2gpu:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_FSDP2_2gpu

  L2_HF_Transformer_PT_2gpu:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PT_2gpu

  L2_HF_Transformer_PT_2gpu_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_PT_2gpu_nemorun

  L2_HF_Transformer_PT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_PT

  L2_HF_Transformer_PT_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_PT_nemorun

  L2_HF_Transformer_SFT_notebook:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SFT_notebook

  L2_HF_Transformer_SFT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_SFT

  L2_HF_Transformer_SFT_nemorun:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_SFT_nemorun

  L2_HF_Transformer_SFT_TE_Acceleration:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_SFT_TE_Acceleration
      IS_OPTIONAL: true

  L2_HF_Transformer_PT_TE_Acceleration:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_HF_Transformer_PT_TE_Acceleration

  # L2: SpeechLM tests
  L2_HF_Transformer_SpeechLM_SFT_2gpu:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_HF_Transformer_SpeechLM_SFT_2gpu

  # L2: TTS Fast dev runs 1
  L2_TTS_Fast_dev_runs_1_Tacotron_2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_TTS_Fast_dev_runs_1_Tacotron_2

  L2_TTS_Fast_dev_runs_1_WaveGlow:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_TTS_Fast_dev_runs_1_WaveGlow

  L2_TTS_Fast_dev_runs_1_FastPitch:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_TTS_Fast_dev_runs_1_FastPitch

  # OPTIONAL_L2_TTS_Fast_dev_runs_1_RADTTS:
  #
  #   runs-on: self-hosted-azure
  #   timeout-minutes: 10
  #   container:
  #     image: nemoci.azurecr.io/nemo_container:${{ github.run_id }}
  #     options:
  #       # --user 0:128
  #       --device=/dev/nvidia0
  #       --gpus all
  #       --shm-size=8g
  #       --env TRANSFORMERS_OFFLINE=0
  #       --env HYDRA_FULL_ERROR=1
  #       --volume /mnt/datadrive/TestData:/home/TestData
  #   steps:
  #       - name: Checkout repository
  #         uses: actions/checkout@v4
  #       - run: |
  #           python examples/tts/radtts.py \
  #           train_dataset=/home/TestData/an4_dataset/an4_train.json \
  #           validation_datasets=/home/TestData/an4_dataset/an4_val.json \
  #           sup_data_path=/home/TestData/an4_dataset/radtts_beta_priors \
  #           trainer.devices="[0]" \
  #           +trainer.limit_train_batches=1 \
  #           +trainer.limit_val_batches=1 \
  #           trainer.max_epochs=1 \
  #           trainer.strategy=auto \
  #           model.pitch_mean=212.35873413085938 \
  #           model.pitch_std=68.52806091308594 \
  #           model.train_ds.dataloader_params.batch_size=4 \
  #           model.train_ds.dataloader_params.num_workers=0 \
  #           model.validation_ds.dataloader_params.batch_size=4 \
  #           model.validation_ds.dataloader_params.num_workers=0 \
  #           export_dir=/home/TestData/radtts_test \
  #           model.optim.lr=0.0001 \
  #           model.modelConfig.decoder_use_partial_padding=True \
  #           ~trainer.check_val_every_n_epoch \
  #           ~model.text_normalizer \
  #           ~model.text_normalizer_call_kwargs
  #       #- uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
  #       #  if: "failure()"

  L2_TTS_Fast_dev_runs_1_Hifigan:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_TTS_Fast_dev_runs_1_Hifigan

  # L2: NeRF
  # L2_NeRF_DreamFusion:
  #
  #   runs-on: self-hosted-azure
  #   container:
  #     image: nemoci.azurecr.io/nemo_container:${{ github.run_id }}
  #     options:
  #       # --user 0:128
  #       --device=/dev/nvidia0
  #       --gpus all
  #       --shm-size=8g
  #       --env TRANSFORMERS_OFFLINE=0
  #       --env HYDRA_FULL_ERROR=1
  #       --volume /mnt/datadrive/TestData:/home/TestData
  #   steps:
  #       - name: Checkout repository
  #         uses: actions/checkout@v4
  #       - run: |
  #           python examples/multimodal/text_to_image/nerf/main.py \
  #           trainer.num_nodes=1 \
  #           trainer.devices="[0]" \
  #           trainer.max_steps=1000 \
  #           model.prompt="a DSLR photo of a delicious hamburger" \
  #           exp_manager.exp_dir=examples/multimodal/text_to_image/nerf/dreamfusion_results
  #
  #       - uses: "NVIDIA/NeMo/.github/actions/cancel-workflow@main"
  #         if: "failure()"

  Speech_Checkpoints_tests:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      TIMEOUT: 20
      SCRIPT: Speech_Checkpoints_tests
      AFTER_SCRIPT: |
        rm -f examples/asr/evaluation_transcripts.json

  L2_Stable_Diffusion_Training:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_Stable_Diffusion_Training

  L2_NeMo_2_GPT_Pretraining_no_transformer_engine:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_Pretraining_no_transformer_engine

  L2_NeMo_2_llama3_pretraining_recipe:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_llama3_pretraining_recipe

  L2_NeMo_2_llama3_fault_tolerance_plugin:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_llama3_fault_tolerance_plugin

  L2_NeMo_2_llama3_straggler_detection:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_llama3_straggler_detection

  L2_NeMo_2_GPT_DDP_Param_Parity_check:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_DDP_Param_Parity_check

  L2_NeMo_2_Hyena_Conversion_from_HF:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Hyena_Conversion_from_HF

  L2_NeMo_2_Hyena_DDP_Pretraining_Test:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure # Assume runner has 2 GPUs
      SCRIPT: L2_NeMo_2_Hyena_DDP_Pretraining_Test

  Optional_L2_NeMo_2_SSM_Pretraining:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_SSM_Pretraining
      IS_OPTIONAL: true

  Optional_L2_NeMo_2_SSM_Finetuning:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_SSM_Finetuning
      IS_OPTIONAL: true

  L2_NeMo_2_HF_MODEL_IMPORT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_HF_MODEL_IMPORT

  L2_NeMo_2_jit_callback:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_jit_callback

  OPTIONAL_L2_NeMo_2_T5_Pretraining:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_T5_Pretraining
      IS_OPTIONAL: true

  L2_NeMo_2_T5_MockData_Pretraining:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_T5_MockData_Pretraining

  L2_NeMo_2_T5_Finetuning:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_T5_Finetuning

  L2_NeMo_2_T5_Squad:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_T5_Squad

  L2_NeMo_2_T5_LoRA:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_T5_LoRA

  L2_NeMo_2_BERT_Pretraining_Megatron:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_BERT_Pretraining_Megatron

  L2_NeMo_2_BERT_Pretraining_HuggingFace:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_BERT_Pretraining_HuggingFace

  L2_NeMo_2_NEVA_MOCK_PRETRAIN_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_PRETRAIN_TP2

  L2_NeMo_2_NEVA_MOCK_PRETRAIN_PP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_PRETRAIN_PP2

  L2_NeMo_2_NEVA_MOCK_PRETRAIN_CP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_PRETRAIN_CP2

  L2_NeMo_2_NEVA_MOCK_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_FINETUNE_TP2

  L2_NeMo_2_NEVA_ENERGON_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_ENERGON_FINETUNE_TP2

  L2_NeMo_2_NEVA_MOCK_FINETUNE_PP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_FINETUNE_PP2

  L2_NeMo_2_NEVA_MOCK_FINETUNE_CP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_MOCK_FINETUNE_CP2

  L2_NeMo_2_NEVA_PRELOADED_FINETUNE_PP2_SEQPACK_PAD:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_PRELOADED_FINETUNE_PP2_SEQPACK_PAD

  L2_NeMo_2_NEVA_PRELOADED_FINETUNE_PP2_SEQPACK_TRUNC:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-2-h100
      SCRIPT: L2_NeMo_2_NEVA_PRELOADED_FINETUNE_PP2_SEQPACK_TRUNC

  OPTIONAL_L2_NeMo_2_NEVA_LOAD_GENERATE:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_NEVA_LOAD_GENERATE
      IS_OPTIONAL: true

  L2_NeMo_2_QWEN2VL_MOCK_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    if: contains(fromJSON(needs.pre-flight.outputs.test_to_run), 'L2_NeMo_2_QWEN2VL_MOCK_FINETUNE_TP2')
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_QWEN2VL_MOCK_FINETUNE_TP2

  L2_NeMo_2_QWEN2VL_PRELOADED_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    if: contains(fromJSON(needs.pre-flight.outputs.test_to_run), 'L2_NeMo_2_QWEN2VL_PRELOADED_FINETUNE_TP2')
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_QWEN2VL_PRELOADED_FINETUNE_TP2

  L2_NeMo_2_QWEN2VL_ENERGON_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    if: contains(fromJSON(needs.pre-flight.outputs.test_to_run), 'L2_NeMo_2_QWEN2VL_ENERGON_FINETUNE_TP2')
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_QWEN2VL_ENERGON_FINETUNE_TP2

  L2_NeMo_2_LLAVA_IMPORT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_LLAVA_IMPORT

  Optional_L2_NEMO_2_MLLAMA_Inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NEMO_2_MLLAMA_Inference
      IS_OPTIONAL: true

  Optional_L2_NeMo_2_MLLAMA_MOCK_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_MLLAMA_MOCK_FINETUNE_TP2
      IS_OPTIONAL: true

  L2_NeMo_2_MLLAMA_PRELOADED_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_MLLAMA_PRELOADED_FINETUNE_TP2

  L2_NeMo_2_MLLAMA_ENERGON_FINETUNE_TP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_MLLAMA_ENERGON_FINETUNE_TP2

  L2_NeMo_2_MLLAMA_IMPORT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_MLLAMA_IMPORT

  L2_NeMo_2_Mixtral_Pretraining:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mixtral_Pretraining

  L2_NeMo_2_GPT_SFT_TP1PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_SFT_TP1PP1_MBS1

  L2_NeMo_2_GPT_SFT_TP1PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_SFT_TP1PP1_MBS2

  L2_NeMo_2_GPT_SFT_TP1PP2_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_SFT_TP1PP2_MBS2

  L2_NeMo_2_GPT_SFT_TP2PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_SFT_TP2PP1_MBS2

  L2_NeMo_2_GPT_SFT_TP1PP1_MBS1_PACKED:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_SFT_TP1PP1_MBS1_PACKED

  L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1

  L2_NeMo_2_GPT_LoRA_TP1PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS2

  L2_NeMo_2_GPT_LoRA_TP1PP2_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP1PP2_MBS2

  L2_NeMo_2_GPT_LoRA_TP2PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP2PP1_MBS2

  L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1_PACKED:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1_PACKED

  L2_NeMo_2_GPT_DoRA_TP1PP1_MBS1_PACKED:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_DoRA_TP1PP1_MBS1_PACKED

  L2_NeMo_2_GPT_CLoRA_TP1PP1_MBS1_PACKED:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_CLoRA_TP1PP1_MBS1_PACKED

  L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1_Chat:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_GPT_LoRA_TP1PP1_MBS1_Chat

  L2_NeMo_2_Mixtral_LoRA_EP2PP1_MBS2_exclude:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mixtral_LoRA_EP2PP1_MBS2_exclude

  L2_NeMo_2_Mixtral_LoRA_EP2PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mixtral_LoRA_EP2PP1_MBS2

  L2_NeMo_2_Mixtral_LoRA_TP1PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mixtral_LoRA_TP1PP1_MBS1

  L2_NeMo_2_Mixtral_LoRA_TP2PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mixtral_LoRA_TP2PP1_MBS1

  L2_NeMo_2_Mistral_LoRA_TP1PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mistral_LoRA_TP1PP1_MBS1

  L2_NeMo_2_Mistral_LoRA_TP1PP1_MBS1_exclude:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mistral_LoRA_TP1PP1_MBS1_exclude

  L2_NeMo_2_Mistral_LoRA_TP2PP1_MBS1:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Mistral_LoRA_TP2PP1_MBS1

  L2_NEMO_2_LoRA_MERGE:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NEMO_2_LoRA_MERGE

  L2_NEMO_2_LoRA_Export:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NEMO_2_LoRA_Export

  L2_NEMO_2_LoRA_Inference:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NEMO_2_LoRA_Inference

  L2_NeMo_2_NeMo_Mcore_Mixtral_bitexact:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_NeMo_Mcore_Mixtral_bitexact

  L2_NeMo_2_Automodel_PTQ_trtllm:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Automodel_PTQ_trtllm

  L2_NeMo_2_Automodel_PTQ_hf:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Automodel_PTQ_hf

  L2_NeMo_2_PTQ_Llama2_FP8_trtllm:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_PTQ_Llama2_FP8_trtllm

  L2_NeMo_2_PTQ_Llama2_FP8_nemo:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_PTQ_Llama2_FP8_nemo

  L2_NeMo_2_PTQ_Unified_Export:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_PTQ_Unified_Export

  L2_NeMo_2_Distill_Llama3_TP1PP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Distill_Llama3_TP1PP2

  L2_NeMo_2_Prune_Llama_TP1PP2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Prune_Llama_TP1PP2

  L2_NeMo_2_LLAVA_NEXT_MOCK_TRAINING:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_LLAVA_NEXT_MOCK_TRAINING

  L2_NeMo_2_LLAVA_NEXT_HF_CONVERSION:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_LLAVA_NEXT_HF_CONVERSION

  L2_NeMo_2_LLAVA_NEXT_ENERGON_TRAIN:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_LLAVA_NEXT_ENERGON_TRAIN

  L2_NeMo_2_LLAVA_NEXT_ENERGON_PACKED_TRAIN:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_LLAVA_NEXT_ENERGON_PACKED_TRAIN

  L2_NeMo_2_CLIP_PRETRAIN:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_CLIP_PRETRAIN

  L2_NeMo_2_CLIP_INFER:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_CLIP_INFER

  Optional_L2_NeMo_2_EVAL:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: Optional_L2_NeMo_2_EVAL
      IS_OPTIONAL: true

  L2_NeMo_2_Auto_Configurator_llama_TP1_PP1_MBS124:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_Auto_Configurator_llama_TP1_PP1_MBS124

  L2_NeMo_2_Auto_Configurator_bert_TP1_PP1_MBS124:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_Auto_Configurator_bert_TP1_PP1_MBS124

  L2_NeMo_2_Auto_Configurator_t5_TP1_PP1_MBS124:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure-gpus-1
      SCRIPT: L2_NeMo_2_Auto_Configurator_t5_TP1_PP1_MBS124

  L2_SpeechLM_LoRA_TP1PP1_MBS2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_SpeechLM_LoRA_TP1PP1_MBS2

  L2_NeMo_2_Conversion_Test_Baichuan2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Baichuan2

  L2_NeMo_2_Conversion_Test_ChatGLM:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_ChatGLM

  L2_NeMo_2_Conversion_Test_DeepSeek:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_DeepSeek

  L2_NeMo_2_Conversion_Test_Gemma:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Gemma

  L2_NeMo_2_Conversion_Test_Gemma2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Gemma2

  L2_NeMo_2_Conversion_Test_Mistral:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Mistral

  L2_NeMo_2_Conversion_Test_Llama:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Llama

  L2_NeMo_2_Conversion_Test_Llama_Embedding:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Llama_Embedding

  L2_NeMo_2_Conversion_Test_Nemotron:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Nemotron

  L2_NeMo_2_Conversion_Test_Phi3Mini:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Phi3Mini

  L2_NeMo_2_Conversion_Test_Qwen2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Qwen2

  L2_NeMo_2_Conversion_Test_Starcoder:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Starcoder

  L2_NeMo_2_Conversion_Test_Starcoder2:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_Starcoder2

  L2_NeMo_2_Conversion_Test_BERT:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_BERT

  L2_NeMo_2_Conversion_Test_T5:
    uses: ./.github/workflows/_test_template.yml
    with:
      RUNNER: self-hosted-azure
      SCRIPT: L2_NeMo_2_Conversion_Test_T5
