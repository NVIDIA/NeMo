{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14eb898-0f8e-4783-a70e-ab54b4de910d",
   "metadata": {},
   "source": [
    "# Tutorial: NeMo & Lhotse Data Loading\n",
    "\n",
    "![image](https://raw.githubusercontent.com/lhotse-speech/lhotse/master/docs/logo.png)\n",
    "\n",
    "In this tutorial we introduce the integration of NeMo with Lhotse, a library for speech data preparation and loading. Lhotse adds new capabilities to NeMo, allowing to move certain operations such as bucketing or dataset blending to dataloading runtime, rather than dataset preparation. This allows a greater flexibility in trying out various dataset setups without the need to prepare different data variants ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57eada3f-d3df-4038-b927-c666ec2b8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import nemo\n",
    "import lhotse\n",
    "from lhotse import CutSet\n",
    "from lhotse.recipes import (\n",
    "    download_librispeech, \n",
    "    download_yesno, \n",
    "    prepare_librispeech, \n",
    "    prepare_yesno,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd2b7ad-be34-4518-aa74-44e8253c0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_root = str(Path(nemo.__path__[0]).parent)\n",
    "root_dir = Path(\"data\")\n",
    "root_dir.mkdir(parents=True, exist_ok=True)\n",
    "num_jobs = os.cpu_count() - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6709798-78ec-477e-86da-8110f307f6f5",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Quick Lhotse Primer\n",
    "\n",
    "[Lhotse](https://github.com/lhotse-speech/lhotse) is a toolkit for speech data handling that originated as a part of the next-generation Kaldi framework. Next-gen Kaldi includes other tools, such as [k2](https://github.com/k2-fsa/k2), which is also [integrated into NeMo](https://github.com/NVIDIA/NeMo/blob/main/examples/asr/experimental/k2/speech_to_text_bpe.py).\n",
    "\n",
    "Lhotse represents speech data as python objects, and provides efficient sampling and dataloading mechanisms. The core Lhotse concepts leveraged in NeMo integration are:\n",
    "- Representation for individual examples: [Recording](https://lhotse.readthedocs.io/en/latest/corpus.html#recording-manifest), [SupervisionSegment](https://lhotse.readthedocs.io/en/latest/corpus.html#supervision-manifest), and [Cut](https://lhotse.readthedocs.io/en/latest/cuts.html#cuts).\n",
    "- Representation for a dataset and/or mini-batch: [CutSet](https://lhotse.readthedocs.io/en/latest/api.html#lhotse.cut.CutSet).\n",
    "- Samplers (stratified and non-stratified): [DynamicCutSampler](https://lhotse.readthedocs.io/en/latest/datasets.html#lhotse.dataset.sampling.DynamicCutSampler) and [DynamicBucketingSampler](https://lhotse.readthedocs.io/en/latest/datasets.html#lhotse.dataset.sampling.DynamicBucketingSampler).\n",
    "- A specific method of blending multiple datasets together, based on a probabilistic multiplexer: [CutSet.mux](https://lhotse.readthedocs.io/en/latest/api.html?highlight=mux#lhotse.cut.CutSet.mux).\n",
    "\n",
    "### How is Lhotse integrated into NeMo?\n",
    "\n",
    "Like NeMo, Lhotse leverages JSON Lines (JSONL) format to keep metadata in manifests. Unlike NeMo, Lhotse's manifests are mapped into Python objects. Most data represented by NeMo manifests are a special case supported by Lhotse and can be adapted on-the-fly to be directly read as a Lhotse `CutSet`. This conversion is enabled by [LazyNeMoIterator](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/common/data/lhotse/nemo_adapters.py#L33) and [LazyTarredNeMoIterator](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/common/data/lhotse/nemo_adapters.py#L131) classes inside NeMo.\n",
    "\n",
    "Building a `DataLoader` with Lhotse relies heavily on `CutSampler` to sample a mini-batch on metadata level as a `CutSet`, which is then passed to a map-style PyTorch dataset that converts the `CutSet` to a tuple/dict of tensors. This is covered in more detail in Lhotse tutorials:\n",
    "- Introductory tutorial [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lhotse-speech/lhotse/blob/master/examples/00-basic-workflow.ipynb)\n",
    "- Tutorial on Lhotse Shar format (\"tarred\" data format in Lhotse): [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lhotse-speech/lhotse/blob/master/examples/04-lhotse-shar.ipynb)\n",
    "\n",
    "The dataloader is being constructed in NeMo from a dataset configuration using function [get_lhotse_dataloader_from_config](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/common/data/lhotse/dataloader.py#L103).\n",
    "\n",
    "### Getting mini LibriSpeech\n",
    "\n",
    "For the sake of the tutorial, we'll be using very small datasets to keep things quick. The first example is mini LibriSpeech, a 5h train set and 2h dev set collection that was released alongside the popular LibriSpeech dataset. Lhotse provides a download function that fetches and unpacks the archive with data, and a prepare function that creates Lhotse manifests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f4033f-ec05-4ead-9675-72dc3d36a772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bc7e6bf889431da3d92f7f1ea48f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading LibriSpeech parts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b040891901d9489a9e0d8be7ff12163e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dataset parts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Distributing tasks: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Distributing tasks: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/1089 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "libri_root = download_librispeech(root_dir, dataset_parts=\"mini_librispeech\")\n",
    "\n",
    "libri = prepare_librispeech(\n",
    "    libri_root, output_dir=root_dir, num_jobs=num_jobs\n",
    ")\n",
    "\n",
    "for split in (\"train-clean-5\", \"dev-clean-2\"):\n",
    "    (\n",
    "        CutSet\n",
    "        .from_manifests(**libri[split])\n",
    "        .to_file(f\"data/librispeech_cuts_{split}.jsonl.gz\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33922226-01ba-4e21-b148-bf520e7946af",
   "metadata": {},
   "source": [
    "# Training NeMo models with Lhotse \n",
    "\n",
    "For quick illustration, we'll fine-tune a small NeMo model `nvidia/stt_en_conformer_ctc_small` for 100 steps, running a validation every 50 steps. When training from scratch, you'd simply use a different NeMo script, while keeping the same dataloading options (perhaps tuning the batch size settings to fit your model choice).\n",
    "\n",
    "**Technical note.** We train using existing NeMo `speech_to_text_finetune.py` script to illustrate real-world usage patterns of NeMo. If you're unfamiliar with running bash commands from a Jupyter notebook, starting the line with an exclamation mark `!` runs a single command, and starting a cell with `%%bash -s {var}` runs the whole cell in bash, and passes `var` as argument `$1` (subsequent -s args will be passed as `$2`, `$3`, and so on). \n",
    "\n",
    "**Common arguments.** Let's briefly discuss the CLI arguments we provide to the fine-tuning script.\n",
    "- Most of the options are in `model.train_ds` and `model.validation_ds` namespaces:\n",
    "  - `use_lhotse=true` enables Lhotse dataloading backend\n",
    "  - Batch size is dynamic and controlled via `batch_duration`, `use_bucketing`, `num_buckets`, and `quadratic_duration`. [Please refer to **NeMo documentation** for details](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/datasets.html#enabling-lhotse-via-configuration).\n",
    "  - We set `batch_size=null` explicitly (the base config has some value that would have otherwise limited our dynamic batch size).\n",
    "  - Although we don't enable dynamic batch size for validation in this example for brevity, it does also work (including with bucketing).\n",
    "- `trainer.use_distributed_sampler=false` is required by Lhotse (it has its own distributed sampling handling).\n",
    "- In `trainer` namespace, `max_steps` controls the total number of steps in training; `val_check_interval` is the number of steps between validation runs.\n",
    "- The `+` notation is used to append a value to a config (i.e., requires when these are not present in the YAML config file). [See **Hydra override syntax** for details](https://hydra.cc/docs/1.1/advanced/override_grammar/basic/#basic-override-syntax).\n",
    "\n",
    "**Model inference.** We skip inference in this tutorial for brevity. [Please refer to **NeMo ASR inference documentation** to learn more](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/intro.html).\n",
    "\n",
    "## I. Training using Lhotse CutSet\n",
    "\n",
    "Let's start with training from our existing Lhotse manifests for mini LibriSpeech. Highlights for relevant CLI arguments:\n",
    "- The manifest path is provided via `cuts_path` so the trainer knows to read this as a Lhotse manifest.\n",
    "- We have to set `manifest_filepath=null` explicitly as older NeMo configs expect some value to be provided there regardless. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fecdcb5d-047b-44ec-94c9-20e83c37142c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 09:59:09 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2024-02-26 09:59:11 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 09:59:11 speech_to_text_finetune:190] Hydra config: name: finetune_from_cutset\n",
      "    init_from_nemo_model: null\n",
      "    model:\n",
      "      sample_rate: 16000\n",
      "      compute_eval_loss: false\n",
      "      log_prediction: true\n",
      "      rnnt_reduction: mean_volume\n",
      "      skip_nan_grad: false\n",
      "      train_ds:\n",
      "        manifest_filepath: null\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: null\n",
      "        shuffle: true\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        max_duration: 20\n",
      "        min_duration: 0.1\n",
      "        is_tarred: false\n",
      "        tarred_audio_filepaths: null\n",
      "        shuffle_n: 2048\n",
      "        bucketing_strategy: fully_randomized\n",
      "        bucketing_batch_size: null\n",
      "        use_lhotse: true\n",
      "        cuts_path: data/librispeech_cuts_train-clean-5.jsonl.gz\n",
      "        batch_duration: 300\n",
      "        use_bucketing: true\n",
      "        num_buckets: 30\n",
      "        quadratic_duration: 15\n",
      "      validation_ds:\n",
      "        manifest_filepath: null\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 64\n",
      "        shuffle: false\n",
      "        use_start_end_token: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        use_lhotse: true\n",
      "        cuts_path: data/librispeech_cuts_dev-clean-2.jsonl.gz\n",
      "      test_ds:\n",
      "        manifest_filepath: null\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: false\n",
      "        use_start_end_token: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "      char_labels:\n",
      "        update_labels: false\n",
      "        labels: null\n",
      "      tokenizer:\n",
      "        update_tokenizer: false\n",
      "        dir: null\n",
      "        type: bpe\n",
      "      spec_augment:\n",
      "        _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
      "        freq_masks: 2\n",
      "        time_masks: 10\n",
      "        freq_width: 27\n",
      "        time_width: 0.05\n",
      "      optim:\n",
      "        name: adamw\n",
      "        lr: 0.0001\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        weight_decay: 0.001\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 5000\n",
      "          warmup_ratio: null\n",
      "          min_lr: 5.0e-06\n",
      "    trainer:\n",
      "      devices: -1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 50\n",
      "      max_steps: 100\n",
      "      val_check_interval: 50\n",
      "      accelerator: auto\n",
      "      strategy: ddp\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 0.0\n",
      "      precision: 32\n",
      "      log_every_n_steps: 10\n",
      "      enable_progress_bar: true\n",
      "      num_sanity_val_steps: 0\n",
      "      check_val_every_n_epoch: 1\n",
      "      sync_batchnorm: true\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "      benchmark: false\n",
      "      use_distributed_sampler: false\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        monitor: val_wer\n",
      "        mode: min\n",
      "        save_top_k: 5\n",
      "        always_save_nemo: true\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        name: null\n",
      "        project: null\n",
      "    init_from_pretrained_model: nvidia/stt_en_conformer_ctc_small\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 09:59:11 exp_manager:396] Experiments will be logged at /home/pzelasko/code/canary/nemo_experiments/finetune_from_cutset/2024-02-26_09-59-11\n",
      "[NeMo I 2024-02-26 09:59:11 exp_manager:856] TensorboardLogger has been set up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 09:59:11 exp_manager:966] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 100. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 09:59:11 speech_to_text_finetune:99] Sleeping for at least 60 seconds to wait for model download to finish.\n",
      "[NeMo I 2024-02-26 10:00:11 mixins:172] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:00:12 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/NeMo_ASR_SET/English/v2.0/train/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/NeMo_ASR_SET/English/v2.0/train/audio__OP_0..4095_CL_.tar\n",
      "    \n",
      "[NeMo W 2024-02-26 10:00:12 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n",
      "[NeMo W 2024-02-26 10:00:12 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:00:12 features:289] PADDING: 0\n",
      "[NeMo I 2024-02-26 10:00:12 save_restore_connector:263] Model EncDecCTCModelBPE was successfully restored from /home/pzelasko/.cache/huggingface/hub/models--nvidia--stt_en_conformer_ctc_small/snapshots/f879b51de584983383de815ce87d25469b2abbf3/stt_en_conformer_ctc_small.nemo.\n",
      "[NeMo I 2024-02-26 10:00:12 speech_to_text_finetune:131] Reusing the vocabulary from the pre-trained model.\n",
      "We will be using a Lhotse DataLoader.\n",
      "Creating a Lhotse DynamicBucketingSampler (max_batch_duration=300.0 max_batch_size=None)\n",
      "We will be using a Lhotse DataLoader.\n",
      "Creating a Lhotse DynamicCutSampler (bucketing is disabled, (max_batch_duration=None max_batch_size=64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:00:12 modelPT:612] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:00:12 modelPT:723] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.0001\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:00:12 lr_scheduler:895] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:00:13 modelPT:723] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.0001\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2024-02-26 10:00:13 lr_scheduler:915] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f77c01db850>\" \n",
      "    will be used during training (effective maximum steps = 100) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 5000\n",
      "    warmup_ratio: null\n",
      "    min_lr: 5.0e-06\n",
      "    max_steps: 100\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConformerEncoder                  | 13.0 M\n",
      "2 | decoder           | ConvASRDecoder                    | 181 K \n",
      "3 | loss              | CTCLoss                           | 0     \n",
      "4 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "5 | wer               | WER                               | 0     \n",
      "6 | spec_augment      | SpectrogramAugmentation           | 0     \n",
      "------------------------------------------------------------------------\n",
      "13.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.2 M    Total params\n",
      "52.616    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 9it [00:02,  3.58it/s, v_num=9-11, train_step_timing in s=0.151][NeMo I 2024-02-26 10:00:17 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:17 wer:319] reference:his line rang suddenly jack she cried you got a bite he pulled missed the strike and wound in the minnow was all right so he tossed it back again that isn't your name he said\n",
      "[NeMo I 2024-02-26 10:00:17 wer:320] predicted:ng suddenly youtll the strike andound thener so hes again isn't said\n",
      "Epoch 0: : 19it [00:03,  4.78it/s, v_num=9-11, train_step_timing in s=0.144][NeMo I 2024-02-26 10:00:19 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:19 wer:319] reference:the giant's heavy eyes lifted quickly but he spoke to the girl you go on home\n",
      "[NeMo I 2024-02-26 10:00:19 wer:320] predicted:the giant's heavy eyes lifted quickly but he spoke to the girl you go on home\n",
      "Epoch 0: : 29it [00:05,  5.43it/s, v_num=9-11, train_step_timing in s=0.113][NeMo I 2024-02-26 10:00:20 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:20 wer:319] reference:in your work with the club men with your old acquaintances what sort of reception do they give you how do you approach them what do they say rollin was relieved when rachel spoke he answered quickly oh it depends on the man\n",
      "[NeMo I 2024-02-26 10:00:20 wer:320] predicted:the within theception do they give you do you do they wasck\n",
      "Epoch 0: : 39it [00:06,  5.88it/s, v_num=9-11, train_step_timing in s=0.161][NeMo I 2024-02-26 10:00:21 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:21 wer:319] reference:held a disconcerting bead on carling's forehead please don't do that said jimmie dale softly it's rather a good make that safe i dare say it would take me half an hour to open it\n",
      "[NeMo I 2024-02-26 10:00:21 wer:320] predicted:ld atertingehead't that saidy softly'sther a's safe i dare it me half an hour to\n",
      "Epoch 0: : 49it [00:08,  6.11it/s, v_num=9-11, train_step_timing in s=0.126][NeMo I 2024-02-26 10:00:23 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:23 wer:319] reference:a pair of pince nez sat crookedly on his nose and two fat volumes under his arm completed the picture fisher who was an observer of some discernment noticed under the overcoat a creased blue suit large black boots\n",
      "[NeMo I 2024-02-26 10:00:23 wer:320] predicted:ir ofedly on his nose and twotlumes on thectureisher wasserverver ofcericed thecoat black boots\n",
      "Epoch 0: : 50it [00:08,  6.14it/s, v_num=9-11, train_step_timing in s=0.118]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]\u001b[A[NeMo I 2024-02-26 10:00:24 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:24 wer:319] reference:on the last saturday in april the new york times published an account of the strike complications which were delaying alexander's new jersey bridge and stated that the engineer himself was in town and at his office on west tenth street\n",
      "[NeMo I 2024-02-26 10:00:24 wer:320] predicted:the lastturday in april the timesblished account of the strikelications werelaying alexander's jerseydge and stated that thengineer town and onstth street\n",
      "\n",
      "Validation DataLoader 0: : 1it [00:00,  2.12it/s]\u001b[A[NeMo I 2024-02-26 10:00:24 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:24 wer:319] reference:she slid to the floor beside him as if she were too tired to sit up any longer\n",
      "[NeMo I 2024-02-26 10:00:24 wer:320] predicted:sheli theloor beside him as if she were too tired to sit any longer\n",
      "\n",
      "Validation DataLoader 0: : 2it [00:00,  2.48it/s]\u001b[A[NeMo I 2024-02-26 10:00:25 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:25 wer:319] reference:and she got up and put her head into the oven\n",
      "[NeMo I 2024-02-26 10:00:25 wer:320] predicted:and she and put her head into theven\n",
      "\n",
      "Validation DataLoader 0: : 3it [00:01,  2.31it/s]\u001b[A[NeMo I 2024-02-26 10:00:25 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:25 wer:319] reference:ah he did not depend upon emotional excitement to keep up his belief no declamations no anger no visions of blood red flags waving or metaphorical lurid suns of vengeance rising above the horizon of a doomed society not he\n",
      "[NeMo I 2024-02-26 10:00:25 wer:320] predicted:he depend upon emotional excitement to keep his belieflamationsngersions of blooddgsving metaphoricald sons ofngeance rising above therizon of a doom\n",
      "\n",
      "Validation DataLoader 0: : 4it [00:01,  2.43it/s]\u001b[A[NeMo I 2024-02-26 10:00:26 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:26 wer:319] reference:he gets a red face poring over them\n",
      "[NeMo I 2024-02-26 10:00:26 wer:320] predicted:he gets a red faceuring them\n",
      "\n",
      "Validation DataLoader 0: : 5it [00:02,  2.42it/s]\u001b[A[NeMo I 2024-02-26 10:00:26 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:26 wer:319] reference:his eyes wandered ceaselessly over the blank horizon\n",
      "[NeMo I 2024-02-26 10:00:26 wer:320] predicted:yesed the blindrizon\n",
      "\n",
      "Validation DataLoader 0: : 6it [00:02,  2.57it/s]\u001b[A[NeMo I 2024-02-26 10:00:26 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:26 wer:319] reference:in flesh was raimented how he was killed and buried from the dead how he arose to life with victory and reigned in heaven how all of us shall be glorious like him whose hearts to his are wed how they who die for love of reason give hypocrites tyrants sophists all who sell their neighbours ill for holiness to hell how the dead saint condemns the bad who live how all he does becomes a law for men how he at last to judge shall come again\n",
      "[NeMo I 2024-02-26 10:00:26 wer:320] predicted:fleshmented helled andri from thead how he arose to life victory andigin and heaven of glorious whose hearts to his are who die for ofyppocritesyrantsphs who sell their neighboursll for holiness toll theadintdemns thed who hes a law for men he todge again\n",
      "\n",
      "Validation DataLoader 0: : 7it [00:02,  2.38it/s]\u001b[A[NeMo I 2024-02-26 10:00:27 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:27 wer:319] reference:that's funny remarked betsy thoughtfully\n",
      "[NeMo I 2024-02-26 10:00:27 wer:320] predicted:'snymark for\n",
      "\n",
      "Validation DataLoader 0: : 8it [00:03,  2.46it/s]\u001b[A[NeMo I 2024-02-26 10:00:27 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:27 wer:319] reference:at the usual hour mister dorriforth and his ward were summoned to tea he entered with a countenance which evinced the remains of anger his eye gave testimony of his absent thoughts and though he took up a pamphlet affecting to read it was plain to discern that he scarcely knew he held it in his hand\n",
      "[NeMo I 2024-02-26 10:00:27 wer:320] predicted:at theual hour mr dorifor and his ward were summoned toa he entered with a countenance whichvince thes of anger hisye gave testimony of absent thoughts though he tookmphlet effecting to was plain toc that hearcely he held it in his\n",
      "\n",
      "Validation DataLoader 0: : 9it [00:03,  2.51it/s]\u001b[A[NeMo I 2024-02-26 10:00:28 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:28 wer:319] reference:only a little food will be required\n",
      "[NeMo I 2024-02-26 10:00:28 wer:320] predicted:only a little food will be required\n",
      "\n",
      "Validation DataLoader 0: : 10it [00:04,  2.44it/s]\u001b[A[NeMo I 2024-02-26 10:00:28 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:28 wer:319] reference:tom says thanks and looks at hilda and she blushes really\n",
      "[NeMo I 2024-02-26 10:00:28 wer:320] predicted:s thanks and atll blushes\n",
      "\n",
      "Validation DataLoader 0: : 11it [00:04,  2.55it/s]\u001b[A[NeMo I 2024-02-26 10:00:28 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:28 wer:319] reference:for these read fibi and vinos that we may conform to english pronunciation\n",
      "[NeMo I 2024-02-26 10:00:28 wer:320] predicted:for thisb andnus that we mayorm to englishnunciation\n",
      "\n",
      "Validation DataLoader 0: : 12it [00:04,  2.63it/s]\u001b[A[NeMo I 2024-02-26 10:00:28 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:28 wer:319] reference:he would make a famous scoundrel\n",
      "[NeMo I 2024-02-26 10:00:28 wer:320] predicted:wouldmous\n",
      "\n",
      "Validation DataLoader 0: : 13it [00:04,  2.64it/s]\u001b[A[NeMo I 2024-02-26 10:00:29 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:29 wer:319] reference:by and by a short figure smoking a cheroot came up out of the dark and proved to be doctor macklewain who had been prevented from attending the dinner by reason of an accident to a constable at norfolk bay which had claimed his professional attention\n",
      "[NeMo I 2024-02-26 10:00:29 wer:320] predicted:and by a short figure smoking aroot up out of therk and proved toctorckelne who had beenvented fromtending the dinner by ofident totable atrfolk bay hadlaimed hisfessionaltention\n",
      "\n",
      "Validation DataLoader 0: : 14it [00:05,  2.71it/s]\u001b[A[NeMo I 2024-02-26 10:00:29 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:29 wer:319] reference:a snake of his size in fighting trim would be more than any boy could handle\n",
      "[NeMo I 2024-02-26 10:00:29 wer:320] predicted:a snake of its andightingm be than thele\n",
      "\n",
      "Validation DataLoader 0: : 15it [00:05,  2.69it/s]\u001b[A[NeMo I 2024-02-26 10:00:30 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:30 wer:319] reference:who is touching me and untrussing me\n",
      "[NeMo I 2024-02-26 10:00:30 wer:320] predicted:whouching me andruing\n",
      "\n",
      "Validation DataLoader 0: : 16it [00:06,  2.65it/s]\u001b[A[NeMo I 2024-02-26 10:00:30 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:30 wer:319] reference:some are wonderfully wrought pretty little homes for birdikins\n",
      "[NeMo I 2024-02-26 10:00:30 wer:320] predicted:some arefullyugh littles forrdkins\n",
      "\n",
      "Validation DataLoader 0: : 17it [00:06,  2.61it/s]\u001b[A[NeMo I 2024-02-26 10:00:30 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:30 wer:319] reference:he was that child's stay and she was his prop\n",
      "[NeMo I 2024-02-26 10:00:30 wer:320] predicted:he sheud\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:00:30 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('global_step', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:00:30 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:00:30 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('val_wer', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 50it [00:15,  3.22it/s, v_num=9-11, train_step_timing in s=0.118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_wer' reached 0.53526 (best 0.53526), saving model to '/home/pzelasko/code/canary/nemo_experiments/finetune_from_cutset/2024-02-26_09-59-11/checkpoints/finetune_from_cutset--val_wer=0.5353-epoch=0.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \u001b[A[NeMo I 2024-02-26 10:00:31 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_cutset/2024-02-26_09-59-11/checkpoints/finetune_from_cutset.nemo\n",
      "[NeMo I 2024-02-26 10:00:32 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_cutset/2024-02-26_09-59-11/checkpoints/finetune_from_cutset.nemo\n",
      "Epoch 0: : 59it [00:18,  3.16it/s, v_num=9-11, train_step_timing in s=0.0971][NeMo I 2024-02-26 10:00:33 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:33 wer:319] reference:and enjoyed municipal liberty under the suzerainty of the empire justinian displayed in his day of adversity a degree of capacity which astonished his contemporaries he fled from cherson and took refuge with the khan of the khazars\n",
      "[NeMo I 2024-02-26 10:00:33 wer:320] predicted:and enjoynipalberty under they of thempirepyed in his dayversity agacitytonishedtempories heson andfuge the of thesars\n",
      "Epoch 0: : 69it [00:19,  3.46it/s, v_num=9-11, train_step_timing in s=0.149][NeMo I 2024-02-26 10:00:35 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:35 wer:319] reference:his room was really a dressing room attached to her own bedroom communicating with it by a door which was usually kept open during the night both dressing room and bedroom were entered by other doors giving on the passage\n",
      "[NeMo I 2024-02-26 10:00:35 wer:320] predicted:was aressing roomached to herdroating it by door usuallyept the anddrotered byors on theage\n",
      "Epoch 0: : 79it [00:21,  3.72it/s, v_num=9-11, train_step_timing in s=0.141][NeMo I 2024-02-26 10:00:36 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:36 wer:319] reference:what are you doing with that dagger the boy's breast heaved and his dirty fingers clenched tight around the whittled stick don't you talk to me that a way he said with an ominous shake of his head i'll gut ye the fisherman threw back his head\n",
      "[NeMo I 2024-02-26 10:00:36 wer:320] predicted:do youinggger thes breasad andury fingerslenched around thed stick' an in ake of head theishman threw back his\n",
      "Epoch 0: : 89it [00:22,  3.97it/s, v_num=9-11, train_step_timing in s=0.099] [NeMo I 2024-02-26 10:00:37 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:37 wer:319] reference:so trigger said they might have two thirds of what everybody wants and you might have one third right here on the table how many of the later raiders did you catch all of them said the commissioner around forty\n",
      "[NeMo I 2024-02-26 10:00:37 wer:320] predicted:soer they might two everybodys you have third here on the of the did youtch of them said theerty\n",
      "Epoch 0: : 99it [00:23,  4.16it/s, v_num=9-11, train_step_timing in s=0.149][NeMo I 2024-02-26 10:00:38 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:38 wer:319] reference:but you are not alone in this world there are other beings of whom you must think you must not be egoists all dropped their heads with a gloomy air\n",
      "[NeMo I 2024-02-26 10:00:38 wer:320] predicted:are al in the they you must musts with theloomy\n",
      "Epoch 0: : 100it [00:23,  4.17it/s, v_num=9-11, train_step_timing in s=0.152]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]\u001b[A[NeMo I 2024-02-26 10:00:40 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:40 wer:319] reference:on the last saturday in april the new york times published an account of the strike complications which were delaying alexander's new jersey bridge and stated that the engineer himself was in town and at his office on west tenth street\n",
      "[NeMo I 2024-02-26 10:00:40 wer:320] predicted:on the lastturday in april the new timesblished account of the strikelications werelaying alexander's jerseydge and stated that thengineer in town and onstth street\n",
      "\n",
      "Validation DataLoader 0: : 1it [00:00,  4.15it/s]\u001b[A[NeMo I 2024-02-26 10:00:40 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:40 wer:319] reference:she slid to the floor beside him as if she were too tired to sit up any longer\n",
      "[NeMo I 2024-02-26 10:00:40 wer:320] predicted:sheli theloor beside him as if she were too tired to sit any longer\n",
      "\n",
      "Validation DataLoader 0: : 2it [00:00,  4.02it/s]\u001b[A[NeMo I 2024-02-26 10:00:40 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:40 wer:319] reference:and she got up and put her head into the oven\n",
      "[NeMo I 2024-02-26 10:00:40 wer:320] predicted:and she and put her head into theven\n",
      "\n",
      "Validation DataLoader 0: : 3it [00:00,  3.07it/s]\u001b[A[NeMo I 2024-02-26 10:00:41 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:41 wer:319] reference:ah he did not depend upon emotional excitement to keep up his belief no declamations no anger no visions of blood red flags waving or metaphorical lurid suns of vengeance rising above the horizon of a doomed society not he\n",
      "[NeMo I 2024-02-26 10:00:41 wer:320] predicted:he did not depend upon emotional excitement to keep his belieflamations no angersions of blooddgsving metaphoricald sons ofngeance rising above therizon of a doom\n",
      "\n",
      "Validation DataLoader 0: : 4it [00:01,  3.19it/s]\u001b[A[NeMo I 2024-02-26 10:00:41 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:41 wer:319] reference:he gets a red face poring over them\n",
      "[NeMo I 2024-02-26 10:00:41 wer:320] predicted:he gets a red face pouring them\n",
      "\n",
      "Validation DataLoader 0: : 5it [00:01,  2.99it/s]\u001b[A[NeMo I 2024-02-26 10:00:41 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:41 wer:319] reference:his eyes wandered ceaselessly over the blank horizon\n",
      "[NeMo I 2024-02-26 10:00:41 wer:320] predicted:yesed the blindrizon\n",
      "\n",
      "Validation DataLoader 0: : 6it [00:01,  3.09it/s]\u001b[A[NeMo I 2024-02-26 10:00:42 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:42 wer:319] reference:in flesh was raimented how he was killed and buried from the dead how he arose to life with victory and reigned in heaven how all of us shall be glorious like him whose hearts to his are wed how they who die for love of reason give hypocrites tyrants sophists all who sell their neighbours ill for holiness to hell how the dead saint condemns the bad who live how all he does becomes a law for men how he at last to judge shall come again\n",
      "[NeMo I 2024-02-26 10:00:42 wer:320] predicted:fleshmented helled andri from thead how he arose to life victory and reig and heaven of glorious like whose hearts to his are they who die for ofyppocritesyrantsphs wholl their neighbours ill for holiness toll theadintdemns the bad who hes a law for men he at todge shall again\n",
      "\n",
      "Validation DataLoader 0: : 7it [00:02,  2.75it/s]\u001b[A[NeMo I 2024-02-26 10:00:42 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:42 wer:319] reference:that's funny remarked betsy thoughtfully\n",
      "[NeMo I 2024-02-26 10:00:42 wer:320] predicted:'snymark for\n",
      "\n",
      "Validation DataLoader 0: : 8it [00:02,  2.81it/s]\u001b[A[NeMo I 2024-02-26 10:00:42 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:42 wer:319] reference:at the usual hour mister dorriforth and his ward were summoned to tea he entered with a countenance which evinced the remains of anger his eye gave testimony of his absent thoughts and though he took up a pamphlet affecting to read it was plain to discern that he scarcely knew he held it in his hand\n",
      "[NeMo I 2024-02-26 10:00:42 wer:320] predicted:at theual hour mr dorifor and his ward were summoned to tea he entered with a countenance whichvince thes of anger hisye gave testimony of absent thoughts though he tookmphlet effecting to it was plain tocer that hearcely he held it in his\n",
      "\n",
      "Validation DataLoader 0: : 9it [00:03,  2.83it/s]\u001b[A[NeMo I 2024-02-26 10:00:43 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:43 wer:319] reference:only a little food will be required\n",
      "[NeMo I 2024-02-26 10:00:43 wer:320] predicted:only a little food will be required\n",
      "\n",
      "Validation DataLoader 0: : 10it [00:03,  2.70it/s]\u001b[A[NeMo I 2024-02-26 10:00:43 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:43 wer:319] reference:tom says thanks and looks at hilda and she blushes really\n",
      "[NeMo I 2024-02-26 10:00:43 wer:320] predicted:mp says thanks ands at hilda she blushes\n",
      "\n",
      "Validation DataLoader 0: : 11it [00:03,  2.79it/s]\u001b[A[NeMo I 2024-02-26 10:00:43 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:43 wer:319] reference:for these read fibi and vinos that we may conform to english pronunciation\n",
      "[NeMo I 2024-02-26 10:00:44 wer:320] predicted:for thesedb andnus that we mayorm to englishnunciation\n",
      "\n",
      "Validation DataLoader 0: : 12it [00:04,  2.86it/s]\u001b[A[NeMo I 2024-02-26 10:00:44 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:44 wer:319] reference:he would make a famous scoundrel\n",
      "[NeMo I 2024-02-26 10:00:44 wer:320] predicted:he would makemous\n",
      "\n",
      "Validation DataLoader 0: : 13it [00:04,  2.85it/s]\u001b[A[NeMo I 2024-02-26 10:00:44 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:44 wer:319] reference:by and by a short figure smoking a cheroot came up out of the dark and proved to be doctor macklewain who had been prevented from attending the dinner by reason of an accident to a constable at norfolk bay which had claimed his professional attention\n",
      "[NeMo I 2024-02-26 10:00:44 wer:320] predicted:and by a short figure smoking aroot up out of therk and proved toctorckel wayne who had beenvented fromtending the dinner by ofident to a constable atrfolk bay hadlaimed hisfessionaltention\n",
      "\n",
      "Validation DataLoader 0: : 14it [00:04,  2.92it/s]\u001b[A[NeMo I 2024-02-26 10:00:45 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:45 wer:319] reference:a snake of his size in fighting trim would be more than any boy could handle\n",
      "[NeMo I 2024-02-26 10:00:45 wer:320] predicted:a snake of itsize andightingm be more than the couldle\n",
      "\n",
      "Validation DataLoader 0: : 15it [00:05,  2.88it/s]\u001b[A[NeMo I 2024-02-26 10:00:45 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:45 wer:319] reference:who is touching me and untrussing me\n",
      "[NeMo I 2024-02-26 10:00:45 wer:320] predicted:touching me andruing me\n",
      "\n",
      "Validation DataLoader 0: : 16it [00:05,  2.82it/s]\u001b[A[NeMo I 2024-02-26 10:00:45 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:45 wer:319] reference:some are wonderfully wrought pretty little homes for birdikins\n",
      "[NeMo I 2024-02-26 10:00:45 wer:320] predicted:some arefullyught littles forrdkins\n",
      "\n",
      "Validation DataLoader 0: : 17it [00:06,  2.76it/s]\u001b[A[NeMo I 2024-02-26 10:00:46 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:00:46 wer:319] reference:he was that child's stay and she was his prop\n",
      "[NeMo I 2024-02-26 10:00:46 wer:320] predicted:he and sheud\n",
      "\n",
      "Epoch 0: : 100it [00:30,  3.23it/s, v_num=9-11, train_step_timing in s=0.152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 100: 'val_wer' reached 0.47179 (best 0.47179), saving model to '/home/pzelasko/code/canary/nemo_experiments/finetune_from_cutset/2024-02-26_09-59-11/checkpoints/finetune_from_cutset--val_wer=0.4718-epoch=0.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \u001b[A[NeMo I 2024-02-26 10:00:46 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_cutset/2024-02-26_09-59-11/checkpoints/finetune_from_cutset.nemo\n",
      "[NeMo I 2024-02-26 10:00:47 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_cutset/2024-02-26_09-59-11/checkpoints/finetune_from_cutset.nemo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 100it [00:32,  3.05it/s, v_num=9-11, train_step_timing in s=0.152]\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {nemo_root}\n",
    "python $1/examples/asr/speech_to_text_finetune.py \\\n",
    "    +init_from_pretrained_model=\"nvidia/stt_en_conformer_ctc_small\" \\\n",
    "    name=\"finetune_from_cutset\" \\\n",
    "    +model.train_ds.use_lhotse=true \\\n",
    "    model.train_ds.manifest_filepath=null \\\n",
    "    +model.train_ds.cuts_path=data/librispeech_cuts_train-clean-5.jsonl.gz \\\n",
    "    model.train_ds.batch_size=null \\\n",
    "    +model.train_ds.batch_duration=300 \\\n",
    "    +model.train_ds.use_bucketing=true \\\n",
    "    +model.train_ds.num_buckets=30 \\\n",
    "    +model.train_ds.quadratic_duration=15 \\\n",
    "    +model.validation_ds.use_lhotse=true \\\n",
    "    model.validation_ds.manifest_filepath=null \\\n",
    "    +model.validation_ds.cuts_path=data/librispeech_cuts_dev-clean-2.jsonl.gz \\\n",
    "    model.validation_ds.batch_size=64 \\\n",
    "    +trainer.use_distributed_sampler=false \\\n",
    "    trainer.max_steps=100 \\\n",
    "    ++trainer.val_check_interval=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7772c3e1-163d-4b34-a1c0-9efd117b7ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " finetune_from_cutset.nemo\n",
      "'finetune_from_cutset--val_wer=0.4718-epoch=0.ckpt'\n",
      "'finetune_from_cutset--val_wer=0.4718-epoch=0-last.ckpt'\n",
      "'finetune_from_cutset--val_wer=0.5353-epoch=0.ckpt'\n"
     ]
    }
   ],
   "source": [
    "!ls nemo_experiments/finetune_from_cutset/*/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4860e2-631a-4522-bf0f-4471cfc46545",
   "metadata": {},
   "source": [
    "## II. Training using NeMo manifest\n",
    "\n",
    "Training from NeMo manifest format is done in a similar way. Highlights:\n",
    "- We'll convert Lhotse CutSet manifests to NeMo manifests for this exercise. If you have existing data in NeMo format, just use it as-is.\n",
    "- We can now use `manifest_filepath` argument directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4929a59c-1375-4397-b2fb-07ccc03f6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in (\"train-clean-5\", \"dev-clean-2\"):\n",
    "    lhotse.serialization.save_to_jsonl(\n",
    "        (\n",
    "            {\n",
    "                \"audio_filepath\": cut.recording.sources[0].source,\n",
    "                \"duration\": cut.duration,\n",
    "                \"text\": cut.supervisions[0].text,\n",
    "                \"lang\": cut.supervisions[0].language,\n",
    "                \"sampling_rate\": cut.sampling_rate,\n",
    "            }\n",
    "            for cut in CutSet.from_file(f\"data/librispeech_cuts_{split}.jsonl.gz\")\n",
    "        ),\n",
    "        f\"data/nemo_{split}.json\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "822dc33c-98a2-4c39-bc04-b274a7422e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:00:54 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2024-02-26 10:00:55 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:00:55 speech_to_text_finetune:190] Hydra config: name: finetune_from_nemo_json\n",
      "    init_from_nemo_model: null\n",
      "    model:\n",
      "      sample_rate: 16000\n",
      "      compute_eval_loss: false\n",
      "      log_prediction: true\n",
      "      rnnt_reduction: mean_volume\n",
      "      skip_nan_grad: false\n",
      "      train_ds:\n",
      "        manifest_filepath: data/nemo_train-clean-5.json\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: null\n",
      "        shuffle: true\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        max_duration: 20\n",
      "        min_duration: 0.1\n",
      "        is_tarred: false\n",
      "        tarred_audio_filepaths: null\n",
      "        shuffle_n: 2048\n",
      "        bucketing_strategy: fully_randomized\n",
      "        bucketing_batch_size: null\n",
      "        use_lhotse: true\n",
      "        batch_duration: 300\n",
      "        use_bucketing: true\n",
      "        num_buckets: 30\n",
      "        quadratic_duration: 15\n",
      "      validation_ds:\n",
      "        manifest_filepath: data/nemo_dev-clean-2.json\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 64\n",
      "        shuffle: false\n",
      "        use_start_end_token: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        use_lhotse: true\n",
      "      test_ds:\n",
      "        manifest_filepath: null\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: false\n",
      "        use_start_end_token: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "      char_labels:\n",
      "        update_labels: false\n",
      "        labels: null\n",
      "      tokenizer:\n",
      "        update_tokenizer: false\n",
      "        dir: null\n",
      "        type: bpe\n",
      "      spec_augment:\n",
      "        _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
      "        freq_masks: 2\n",
      "        time_masks: 10\n",
      "        freq_width: 27\n",
      "        time_width: 0.05\n",
      "      optim:\n",
      "        name: adamw\n",
      "        lr: 0.0001\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        weight_decay: 0.001\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 5000\n",
      "          warmup_ratio: null\n",
      "          min_lr: 5.0e-06\n",
      "    trainer:\n",
      "      devices: -1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 50\n",
      "      max_steps: 100\n",
      "      val_check_interval: 50\n",
      "      accelerator: auto\n",
      "      strategy: ddp\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 0.0\n",
      "      precision: 32\n",
      "      log_every_n_steps: 10\n",
      "      enable_progress_bar: true\n",
      "      num_sanity_val_steps: 0\n",
      "      check_val_every_n_epoch: 1\n",
      "      sync_batchnorm: true\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "      benchmark: false\n",
      "      use_distributed_sampler: false\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        monitor: val_wer\n",
      "        mode: min\n",
      "        save_top_k: 5\n",
      "        always_save_nemo: true\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        name: null\n",
      "        project: null\n",
      "    init_from_pretrained_model: nvidia/stt_en_conformer_ctc_small\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:00:55 exp_manager:396] Experiments will be logged at /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_json/2024-02-26_10-00-55\n",
      "[NeMo I 2024-02-26 10:00:55 exp_manager:856] TensorboardLogger has been set up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:00:55 exp_manager:966] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 100. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:00:55 speech_to_text_finetune:99] Sleeping for at least 60 seconds to wait for model download to finish.\n",
      "[NeMo I 2024-02-26 10:01:56 mixins:172] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:01:56 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/NeMo_ASR_SET/English/v2.0/train/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/NeMo_ASR_SET/English/v2.0/train/audio__OP_0..4095_CL_.tar\n",
      "    \n",
      "[NeMo W 2024-02-26 10:01:56 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n",
      "[NeMo W 2024-02-26 10:01:56 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:01:56 features:289] PADDING: 0\n",
      "[NeMo I 2024-02-26 10:01:56 save_restore_connector:263] Model EncDecCTCModelBPE was successfully restored from /home/pzelasko/.cache/huggingface/hub/models--nvidia--stt_en_conformer_ctc_small/snapshots/f879b51de584983383de815ce87d25469b2abbf3/stt_en_conformer_ctc_small.nemo.\n",
      "[NeMo I 2024-02-26 10:01:56 speech_to_text_finetune:131] Reusing the vocabulary from the pre-trained model.\n",
      "We will be using a Lhotse DataLoader.\n",
      "Initializing Lhotse CutSet from a single NeMo manifest (tarred): 'data/nemo_train-clean-5.json'\n",
      "Creating a Lhotse DynamicBucketingSampler (max_batch_duration=300.0 max_batch_size=None)\n",
      "We will be using a Lhotse DataLoader.\n",
      "Initializing Lhotse CutSet from a single NeMo manifest (tarred): 'data/nemo_dev-clean-2.json'\n",
      "Creating a Lhotse DynamicCutSampler (bucketing is disabled, (max_batch_duration=None max_batch_size=64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:01:57 modelPT:612] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:01:57 modelPT:723] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.0001\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:01:57 lr_scheduler:895] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:01:58 modelPT:723] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.0001\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2024-02-26 10:01:58 lr_scheduler:915] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f49e013a890>\" \n",
      "    will be used during training (effective maximum steps = 100) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 5000\n",
      "    warmup_ratio: null\n",
      "    min_lr: 5.0e-06\n",
      "    max_steps: 100\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConformerEncoder                  | 13.0 M\n",
      "2 | decoder           | ConvASRDecoder                    | 181 K \n",
      "3 | loss              | CTCLoss                           | 0     \n",
      "4 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "5 | wer               | WER                               | 0     \n",
      "6 | spec_augment      | SpectrogramAugmentation           | 0     \n",
      "------------------------------------------------------------------------\n",
      "13.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.2 M    Total params\n",
      "52.616    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 9it [00:02,  3.52it/s, v_num=0-55, train_step_timing in s=0.163][NeMo I 2024-02-26 10:02:01 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:01 wer:319] reference:his line rang suddenly jack she cried you got a bite he pulled missed the strike and wound in the minnow was all right so he tossed it back again that isn't your name he said\n",
      "[NeMo I 2024-02-26 10:02:01 wer:320] predicted:his line rang suddenlyck sheried herake and in the mi was he back again that he\n",
      "Epoch 0: : 19it [00:03,  4.82it/s, v_num=0-55, train_step_timing in s=0.140][NeMo I 2024-02-26 10:02:03 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:03 wer:319] reference:the giant's heavy eyes lifted quickly but he spoke to the girl you go on home\n",
      "[NeMo I 2024-02-26 10:02:03 wer:320] predicted:the giant's heavy eyes lifted quickly but he spoke to the girl you go on home\n",
      "Epoch 0: : 29it [00:05,  5.41it/s, v_num=0-55, train_step_timing in s=0.158][NeMo I 2024-02-26 10:02:04 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:04 wer:319] reference:in your work with the club men with your old acquaintances what sort of reception do they give you how do you approach them what do they say rollin was relieved when rachel spoke he answered quickly oh it depends on the man\n",
      "[NeMo I 2024-02-26 10:02:04 wer:320] predicted:yourlub yourquaintances what sort ofception do you you them they roland wasckly\n",
      "Epoch 0: : 39it [00:06,  5.91it/s, v_num=0-55, train_step_timing in s=0.137][NeMo I 2024-02-26 10:02:05 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:05 wer:319] reference:held a disconcerting bead on carling's forehead please don't do that said jimmie dale softly it's rather a good make that safe i dare say it would take me half an hour to open it\n",
      "[NeMo I 2024-02-26 10:02:05 wer:320] predicted:lderehead't do that saidjeftly'sther good that's dare it me an to it\n",
      "Epoch 0: : 49it [00:07,  6.24it/s, v_num=0-55, train_step_timing in s=0.0838][NeMo I 2024-02-26 10:02:07 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:07 wer:319] reference:a pair of pince nez sat crookedly on his nose and two fat volumes under his arm completed the picture fisher who was an observer of some discernment noticed under the overcoat a creased blue suit large black boots\n",
      "[NeMo I 2024-02-26 10:02:07 wer:320] predicted:air oftckedly on his twotlumes under hisd thectureish who was an observer of someeranted thecoat aedlueit large blackots\n",
      "Epoch 0: : 50it [00:07,  6.28it/s, v_num=0-55, train_step_timing in s=0.109] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]\u001b[A[NeMo I 2024-02-26 10:02:08 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:08 wer:319] reference:on the last saturday in april the new york times published an account of the strike complications which were delaying alexander's new jersey bridge and stated that the engineer himself was in town and at his office on west tenth street\n",
      "[NeMo I 2024-02-26 10:02:08 wer:320] predicted:the lastturday in april the timesblished account of the strikelications werelaying alexander's jerseydge and stated that thengineer town and onstth street\n",
      "\n",
      "Validation DataLoader 0: : 1it [00:00,  1.97it/s]\u001b[A[NeMo I 2024-02-26 10:02:08 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:08 wer:319] reference:she slid to the floor beside him as if she were too tired to sit up any longer\n",
      "[NeMo I 2024-02-26 10:02:08 wer:320] predicted:sheli theloor beside him as if she were too tired to sit any longer\n",
      "\n",
      "Validation DataLoader 0: : 2it [00:00,  2.23it/s]\u001b[A[NeMo I 2024-02-26 10:02:09 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:09 wer:319] reference:and she got up and put her head into the oven\n",
      "[NeMo I 2024-02-26 10:02:09 wer:320] predicted:and she and put her head into theven\n",
      "\n",
      "Validation DataLoader 0: : 3it [00:01,  2.14it/s]\u001b[A[NeMo I 2024-02-26 10:02:09 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:09 wer:319] reference:ah he did not depend upon emotional excitement to keep up his belief no declamations no anger no visions of blood red flags waving or metaphorical lurid suns of vengeance rising above the horizon of a doomed society not he\n",
      "[NeMo I 2024-02-26 10:02:09 wer:320] predicted:he depend upon emotional excitement to keep his belieflamationsngersions of blooddgsving metaphoricald sons ofngeance rising above therizon of a doom\n",
      "\n",
      "Validation DataLoader 0: : 4it [00:01,  2.23it/s]\u001b[A[NeMo I 2024-02-26 10:02:10 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:10 wer:319] reference:he gets a red face poring over them\n",
      "[NeMo I 2024-02-26 10:02:10 wer:320] predicted:he gets a red faceuring them\n",
      "\n",
      "Validation DataLoader 0: : 5it [00:02,  2.25it/s]\u001b[A[NeMo I 2024-02-26 10:02:10 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:10 wer:319] reference:his eyes wandered ceaselessly over the blank horizon\n",
      "[NeMo I 2024-02-26 10:02:10 wer:320] predicted:yesed the blindrizon\n",
      "\n",
      "Validation DataLoader 0: : 6it [00:02,  2.41it/s]\u001b[A[NeMo I 2024-02-26 10:02:11 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:11 wer:319] reference:in flesh was raimented how he was killed and buried from the dead how he arose to life with victory and reigned in heaven how all of us shall be glorious like him whose hearts to his are wed how they who die for love of reason give hypocrites tyrants sophists all who sell their neighbours ill for holiness to hell how the dead saint condemns the bad who live how all he does becomes a law for men how he at last to judge shall come again\n",
      "[NeMo I 2024-02-26 10:02:11 wer:320] predicted:fleshmented helled andri from thead how he arose to life victory andigin and heaven of glorious whose hearts to his are they who die for ofyppocritesyrantsphs who sell their neighboursll for holiness toll theadintdemns thed who hes a law for men he todge again\n",
      "\n",
      "Validation DataLoader 0: : 7it [00:03,  2.26it/s]\u001b[A[NeMo I 2024-02-26 10:02:11 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:11 wer:319] reference:that's funny remarked betsy thoughtfully\n",
      "[NeMo I 2024-02-26 10:02:11 wer:320] predicted:'snymark for\n",
      "\n",
      "Validation DataLoader 0: : 8it [00:03,  2.35it/s]\u001b[A[NeMo I 2024-02-26 10:02:11 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:11 wer:319] reference:at the usual hour mister dorriforth and his ward were summoned to tea he entered with a countenance which evinced the remains of anger his eye gave testimony of his absent thoughts and though he took up a pamphlet affecting to read it was plain to discern that he scarcely knew he held it in his hand\n",
      "[NeMo I 2024-02-26 10:02:11 wer:320] predicted:at theual hour mr dorifor and his ward were summoned toa he entered with a countenance whichvince thes of anger hisye gave testimony of absent thoughts though he tookmphlet effecting to was plain toc that hearcely he held it in his\n",
      "\n",
      "Validation DataLoader 0: : 9it [00:03,  2.40it/s]\u001b[A[NeMo I 2024-02-26 10:02:12 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:12 wer:319] reference:only a little food will be required\n",
      "[NeMo I 2024-02-26 10:02:12 wer:320] predicted:only a little food will be required\n",
      "\n",
      "Validation DataLoader 0: : 10it [00:04,  2.34it/s]\u001b[A[NeMo I 2024-02-26 10:02:12 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:12 wer:319] reference:tom says thanks and looks at hilda and she blushes really\n",
      "[NeMo I 2024-02-26 10:02:12 wer:320] predicted:s thanks and at hell blushes\n",
      "\n",
      "Validation DataLoader 0: : 11it [00:04,  2.45it/s]\u001b[A[NeMo I 2024-02-26 10:02:12 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:12 wer:319] reference:for these read fibi and vinos that we may conform to english pronunciation\n",
      "[NeMo I 2024-02-26 10:02:12 wer:320] predicted:for thisb andnus that we mayorm to englishnunciation\n",
      "\n",
      "Validation DataLoader 0: : 12it [00:04,  2.54it/s]\u001b[A[NeMo I 2024-02-26 10:02:13 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:13 wer:319] reference:he would make a famous scoundrel\n",
      "[NeMo I 2024-02-26 10:02:13 wer:320] predicted:wouldmous\n",
      "\n",
      "Validation DataLoader 0: : 13it [00:05,  2.55it/s]\u001b[A[NeMo I 2024-02-26 10:02:13 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:13 wer:319] reference:by and by a short figure smoking a cheroot came up out of the dark and proved to be doctor macklewain who had been prevented from attending the dinner by reason of an accident to a constable at norfolk bay which had claimed his professional attention\n",
      "[NeMo I 2024-02-26 10:02:13 wer:320] predicted:and by a short figure smoking aroot up out of therk and proved toctorckelne who had beenvented fromtending the dinner by ofident totable atrfolk bay hadlaimed hisfessionaltention\n",
      "\n",
      "Validation DataLoader 0: : 14it [00:05,  2.62it/s]\u001b[A[NeMo I 2024-02-26 10:02:13 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:13 wer:319] reference:a snake of his size in fighting trim would be more than any boy could handle\n",
      "[NeMo I 2024-02-26 10:02:13 wer:320] predicted:a snake of its andightingm be than the couldle\n",
      "\n",
      "Validation DataLoader 0: : 15it [00:05,  2.61it/s]\u001b[A[NeMo I 2024-02-26 10:02:14 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:14 wer:319] reference:who is touching me and untrussing me\n",
      "[NeMo I 2024-02-26 10:02:14 wer:320] predicted:whouching me andruing me\n",
      "\n",
      "Validation DataLoader 0: : 16it [00:06,  2.57it/s]\u001b[A[NeMo I 2024-02-26 10:02:14 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:14 wer:319] reference:some are wonderfully wrought pretty little homes for birdikins\n",
      "[NeMo I 2024-02-26 10:02:14 wer:320] predicted:some arefullyugh littles forrdkins\n",
      "\n",
      "Validation DataLoader 0: : 17it [00:06,  2.53it/s]\u001b[A[NeMo I 2024-02-26 10:02:14 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:14 wer:319] reference:he was that child's stay and she was his prop\n",
      "[NeMo I 2024-02-26 10:02:14 wer:320] predicted:he sheud\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:02:14 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('global_step', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:02:14 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:02:14 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('val_wer', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 50it [00:15,  3.21it/s, v_num=0-55, train_step_timing in s=0.109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_wer' reached 0.53069 (best 0.53069), saving model to '/home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_json/2024-02-26_10-00-55/checkpoints/finetune_from_nemo_json--val_wer=0.5307-epoch=0.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \u001b[A[NeMo I 2024-02-26 10:02:15 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_json/2024-02-26_10-00-55/checkpoints/finetune_from_nemo_json.nemo\n",
      "[NeMo I 2024-02-26 10:02:16 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_json/2024-02-26_10-00-55/checkpoints/finetune_from_nemo_json.nemo\n",
      "Epoch 0: : 59it [00:18,  3.16it/s, v_num=0-55, train_step_timing in s=0.147] [NeMo I 2024-02-26 10:02:18 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:18 wer:319] reference:and enjoyed municipal liberty under the suzerainty of the empire justinian displayed in his day of adversity a degree of capacity which astonished his contemporaries he fled from cherson and took refuge with the khan of the khazars\n",
      "[NeMo I 2024-02-26 10:02:18 wer:320] predicted:ed the wholeberty under the in of thempire just in his day ofdversity a degree of capacity whichmper he fled fromson andfuge the of thezars\n",
      "Epoch 0: : 69it [00:19,  3.46it/s, v_num=0-55, train_step_timing in s=0.137][NeMo I 2024-02-26 10:02:19 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:19 wer:319] reference:his room was really a dressing room attached to her own bedroom communicating with it by a door which was usually kept open during the night both dressing room and bedroom were entered by other doors giving on the passage\n",
      "[NeMo I 2024-02-26 10:02:19 wer:320] predicted:was a dressing roomtached to her bedcating it by door was kp in the nightressing room and bedro were entered byorsving theage\n",
      "Epoch 0: : 79it [00:21,  3.71it/s, v_num=0-55, train_step_timing in s=0.174] [NeMo I 2024-02-26 10:02:20 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:20 wer:319] reference:what are you doing with that dagger the boy's breast heaved and his dirty fingers clenched tight around the whittled stick don't you talk to me that a way he said with an ominous shake of his head i'll gut ye the fisherman threw back his head\n",
      "[NeMo I 2024-02-26 10:02:20 wer:320] predicted:are doing withgger the boys basad and his dirtyers clench around the stick me he said with an in hiske of headll theish threw his\n",
      "Epoch 0: : 89it [00:22,  3.95it/s, v_num=0-55, train_step_timing in s=0.0919][NeMo I 2024-02-26 10:02:21 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:21 wer:319] reference:so trigger said they might have two thirds of what everybody wants and you might have one third right here on the table how many of the later raiders did you catch all of them said the commissioner around forty\n",
      "[NeMo I 2024-02-26 10:02:21 wer:320] predicted:sogger said they might two thirds ofs and they might third right on theables did youtch the commissionerty\n",
      "Epoch 0: : 99it [00:23,  4.14it/s, v_num=0-55, train_step_timing in s=0.139][NeMo I 2024-02-26 10:02:23 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:23 wer:319] reference:but you are not alone in this world there are other beings of whom you must think you must not be egoists all dropped their heads with a gloomy air\n",
      "[NeMo I 2024-02-26 10:02:23 wer:320] predicted:notone the you you must e they\n",
      "Epoch 0: : 100it [00:24,  4.16it/s, v_num=0-55, train_step_timing in s=0.128]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]\u001b[A[NeMo I 2024-02-26 10:02:24 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:24 wer:319] reference:on the last saturday in april the new york times published an account of the strike complications which were delaying alexander's new jersey bridge and stated that the engineer himself was in town and at his office on west tenth street\n",
      "[NeMo I 2024-02-26 10:02:24 wer:320] predicted:on the lastturday in april the new timesblished account of the strikelications which werelaying alexander's jerseydge and stated that thengineer in town and onstth street\n",
      "\n",
      "Validation DataLoader 0: : 1it [00:00,  4.00it/s]\u001b[A[NeMo I 2024-02-26 10:02:24 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:24 wer:319] reference:she slid to the floor beside him as if she were too tired to sit up any longer\n",
      "[NeMo I 2024-02-26 10:02:24 wer:320] predicted:sheli theloor beside him as if she were too tired to sit any longer\n",
      "\n",
      "Validation DataLoader 0: : 2it [00:00,  3.94it/s]\u001b[A[NeMo I 2024-02-26 10:02:25 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:25 wer:319] reference:and she got up and put her head into the oven\n",
      "[NeMo I 2024-02-26 10:02:25 wer:320] predicted:and she and put her head into theven\n",
      "\n",
      "Validation DataLoader 0: : 3it [00:01,  2.97it/s]\u001b[A[NeMo I 2024-02-26 10:02:25 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:25 wer:319] reference:ah he did not depend upon emotional excitement to keep up his belief no declamations no anger no visions of blood red flags waving or metaphorical lurid suns of vengeance rising above the horizon of a doomed society not he\n",
      "[NeMo I 2024-02-26 10:02:25 wer:320] predicted:he did not depend upon emotional excitement to keep his belieflamations no angersions of blooddgsving metaphoricald sons ofngeance rising above therizon of a doom\n",
      "\n",
      "Validation DataLoader 0: : 4it [00:01,  3.09it/s]\u001b[A[NeMo I 2024-02-26 10:02:25 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:25 wer:319] reference:he gets a red face poring over them\n",
      "[NeMo I 2024-02-26 10:02:25 wer:320] predicted:he gets a red face pouring them\n",
      "\n",
      "Validation DataLoader 0: : 5it [00:01,  2.91it/s]\u001b[A[NeMo I 2024-02-26 10:02:26 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:26 wer:319] reference:his eyes wandered ceaselessly over the blank horizon\n",
      "[NeMo I 2024-02-26 10:02:26 wer:320] predicted:yesedly the blindrizon\n",
      "\n",
      "Validation DataLoader 0: : 6it [00:01,  3.02it/s]\u001b[A[NeMo I 2024-02-26 10:02:26 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:26 wer:319] reference:in flesh was raimented how he was killed and buried from the dead how he arose to life with victory and reigned in heaven how all of us shall be glorious like him whose hearts to his are wed how they who die for love of reason give hypocrites tyrants sophists all who sell their neighbours ill for holiness to hell how the dead saint condemns the bad who live how all he does becomes a law for men how he at last to judge shall come again\n",
      "[NeMo I 2024-02-26 10:02:26 wer:320] predicted:fleshmented helled andri from thead how he arose to life victory and reig and heaven of glorious like whose hearts to his ared they who die for ofyppocritesyrantsphs wholl their neighbours ill for holiness toll theadintdemns the bad who hes a law for men he at todge shall again\n",
      "\n",
      "Validation DataLoader 0: : 7it [00:02,  2.70it/s]\u001b[A[NeMo I 2024-02-26 10:02:26 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:26 wer:319] reference:that's funny remarked betsy thoughtfully\n",
      "[NeMo I 2024-02-26 10:02:26 wer:320] predicted:'snymark for\n",
      "\n",
      "Validation DataLoader 0: : 8it [00:02,  2.75it/s]\u001b[A[NeMo I 2024-02-26 10:02:27 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:27 wer:319] reference:at the usual hour mister dorriforth and his ward were summoned to tea he entered with a countenance which evinced the remains of anger his eye gave testimony of his absent thoughts and though he took up a pamphlet affecting to read it was plain to discern that he scarcely knew he held it in his hand\n",
      "[NeMo I 2024-02-26 10:02:27 wer:320] predicted:at theual hour mr dorifor and his ward were summoned to tea he entered with a countenance whichvince thes of anger hisye gave testimony of absent thoughts though he tookmphlet effecting to it was plain tocer that hearcely he held it in his\n",
      "\n",
      "Validation DataLoader 0: : 9it [00:03,  2.77it/s]\u001b[A[NeMo I 2024-02-26 10:02:27 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:27 wer:319] reference:only a little food will be required\n",
      "[NeMo I 2024-02-26 10:02:27 wer:320] predicted:only a little food will be required\n",
      "\n",
      "Validation DataLoader 0: : 10it [00:03,  2.66it/s]\u001b[A[NeMo I 2024-02-26 10:02:28 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:28 wer:319] reference:tom says thanks and looks at hilda and she blushes really\n",
      "[NeMo I 2024-02-26 10:02:28 wer:320] predicted:mps thanks ands at hilda she blushes\n",
      "\n",
      "Validation DataLoader 0: : 11it [00:03,  2.75it/s]\u001b[A[NeMo I 2024-02-26 10:02:28 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:28 wer:319] reference:for these read fibi and vinos that we may conform to english pronunciation\n",
      "[NeMo I 2024-02-26 10:02:28 wer:320] predicted:for thesedb andnus that we mayorm to englishnunciation\n",
      "\n",
      "Validation DataLoader 0: : 12it [00:04,  2.84it/s]\u001b[A[NeMo I 2024-02-26 10:02:28 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:28 wer:319] reference:he would make a famous scoundrel\n",
      "[NeMo I 2024-02-26 10:02:28 wer:320] predicted:he would makemous\n",
      "\n",
      "Validation DataLoader 0: : 13it [00:04,  2.83it/s]\u001b[A[NeMo I 2024-02-26 10:02:28 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:28 wer:319] reference:by and by a short figure smoking a cheroot came up out of the dark and proved to be doctor macklewain who had been prevented from attending the dinner by reason of an accident to a constable at norfolk bay which had claimed his professional attention\n",
      "[NeMo I 2024-02-26 10:02:28 wer:320] predicted:and by a short figure smoking aroot up out of therk and proved toctorckel wayne who had beenvented fromtending the dinner by ofident to a constable atrfolk bay hadlaimed hisfessionaltention\n",
      "\n",
      "Validation DataLoader 0: : 14it [00:04,  2.89it/s]\u001b[A[NeMo I 2024-02-26 10:02:29 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:29 wer:319] reference:a snake of his size in fighting trim would be more than any boy could handle\n",
      "[NeMo I 2024-02-26 10:02:29 wer:320] predicted:a snake of itsize andightingm be more than the couldle\n",
      "\n",
      "Validation DataLoader 0: : 15it [00:05,  2.86it/s]\u001b[A[NeMo I 2024-02-26 10:02:29 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:29 wer:319] reference:who is touching me and untrussing me\n",
      "[NeMo I 2024-02-26 10:02:29 wer:320] predicted:touching me andruing me\n",
      "\n",
      "Validation DataLoader 0: : 16it [00:05,  2.79it/s]\u001b[A[NeMo I 2024-02-26 10:02:30 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:30 wer:319] reference:some are wonderfully wrought pretty little homes for birdikins\n",
      "[NeMo I 2024-02-26 10:02:30 wer:320] predicted:some arefullyught littles forrdkins\n",
      "\n",
      "Validation DataLoader 0: : 17it [00:06,  2.74it/s]\u001b[A[NeMo I 2024-02-26 10:02:30 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:02:30 wer:319] reference:he was that child's stay and she was his prop\n",
      "[NeMo I 2024-02-26 10:02:30 wer:320] predicted:he and sheud\n",
      "\n",
      "Epoch 0: : 100it [00:31,  3.21it/s, v_num=0-55, train_step_timing in s=0.128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 100: 'val_wer' reached 0.46767 (best 0.46767), saving model to '/home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_json/2024-02-26_10-00-55/checkpoints/finetune_from_nemo_json--val_wer=0.4677-epoch=0.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \u001b[A[NeMo I 2024-02-26 10:02:30 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_json/2024-02-26_10-00-55/checkpoints/finetune_from_nemo_json.nemo\n",
      "[NeMo I 2024-02-26 10:02:31 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_json/2024-02-26_10-00-55/checkpoints/finetune_from_nemo_json.nemo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 100it [00:32,  3.04it/s, v_num=0-55, train_step_timing in s=0.128]\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {nemo_root}\n",
    "python $1/examples/asr/speech_to_text_finetune.py \\\n",
    "    +init_from_pretrained_model=\"nvidia/stt_en_conformer_ctc_small\" \\\n",
    "    name=\"finetune_from_nemo_json\" \\\n",
    "    +model.train_ds.use_lhotse=true \\\n",
    "    model.train_ds.manifest_filepath=data/nemo_train-clean-5.json \\\n",
    "    model.train_ds.batch_size=null \\\n",
    "    +model.train_ds.batch_duration=300 \\\n",
    "    +model.train_ds.use_bucketing=true \\\n",
    "    +model.train_ds.num_buckets=30 \\\n",
    "    +model.train_ds.quadratic_duration=15 \\\n",
    "    +model.validation_ds.use_lhotse=true \\\n",
    "    model.validation_ds.manifest_filepath=data/nemo_dev-clean-2.json \\\n",
    "    model.validation_ds.batch_size=64 \\\n",
    "    +trainer.use_distributed_sampler=false \\\n",
    "    trainer.max_steps=100 \\\n",
    "    ++trainer.val_check_interval=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccdff9bc-078f-4b88-85ec-18a9f7c86017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " finetune_from_nemo_json.nemo\n",
      "'finetune_from_nemo_json--val_wer=0.4677-epoch=0.ckpt'\n",
      "'finetune_from_nemo_json--val_wer=0.4677-epoch=0-last.ckpt'\n",
      "'finetune_from_nemo_json--val_wer=0.5307-epoch=0.ckpt'\n"
     ]
    }
   ],
   "source": [
    "!ls nemo_experiments/finetune_from_nemo_json/*/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa6cc48-159c-44e3-a666-6b42f5b1587d",
   "metadata": {},
   "source": [
    "## III. Training using NeMo tarred manifest\n",
    "\n",
    "Tarred manifest format is useful when dealing with I/O bottlenecks. Typical scenarios are compute grids with shared resources, magnetic disks, cloud storage such as AWS S3, GCS, Azure Blob Storage, etc. \n",
    "\n",
    "We'll cover NeMo native tarred format below. If you're interested in Lhotse Shar tarred format, these also work in NeMo -- [please visit the **relevant Lhotse Shar tutorial** for details](https://colab.research.google.com/github/lhotse-speech/lhotse/blob/master/examples/04-lhotse-shar.ipynb). \n",
    "\n",
    "Highlights:\n",
    "- First, let's convert data to NeMo tarred manifests using dedicated NeMo script `convert_to_tarred_audio_dataset.py`. We'll split the data into 32 shards here.\n",
    "- For training, we'll use `manifest_filepath` for sharded JSONL manifests, and `tarred_audio_filepaths` for sharded audio tar files. Note the NeMo-specific syntax of `_OP_0..31_CL_` which tells NeMo to expand it into a list of 32 items.\n",
    "- The only other modification is that we're adding `trainer.train_limit_batches` option which tells the trainer what's the size of a pseudo-epoch. In previous examples we could have measured training length in epochs, but chose not to. However, with tarred datasets, we completely discard the notion of an epoch -- the data iterator is infinite, so we use the count of steps for everything instead. This design prevents issues with hanging due to uneven dataloader lengths in distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e89de72-7edc-4356-9863-f9e6e1b9eb48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pzelasko/code/NeMo/scripts/speech_recognition/create_dali_tarred_dataset_index.py:71: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=None, config_name='index_config')\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new tarred dataset ...\n",
      "After filtering, manifest has 1519 files which amounts to 19118.674812500023 seconds of audio.\n",
      "Number of samples added : 1519\n",
      "Remainder: 15\n",
      "Shard 0 has entries 0 ~ 47\n",
      "Shard 0 contains 47 files\n",
      "Shard 1 has entries 47 ~ 94\n",
      "Shard 1 contains 47 files\n",
      "Shard 2 has entries 94 ~ 141\n",
      "Shard 2 contains 47 files\n",
      "Shard 3 has entries 141 ~ 188\n",
      "Shard 3 contains 47 files\n",
      "Shard 4 has entries 188 ~ 235\n",
      "Shard 4 contains 47 files\n",
      "Shard 5 has entries 235 ~ 282\n",
      "Shard 5 contains 47 files\n",
      "Shard 6 has entries 282 ~ 329\n",
      "Shard 6 contains 47 files\n",
      "Shard 7 has entries 329 ~ 376\n",
      "Shard 7 contains 47 files\n",
      "Shard 8 has entries 376 ~ 423\n",
      "Shard 8 contains 47 files\n",
      "Shard 9 has entries 423 ~ 470\n",
      "Shard 9 contains 47 files\n",
      "Shard 10 has entries 470 ~ 517\n",
      "Shard 10 contains 47 files\n",
      "Shard 11 has entries 517 ~ 564\n",
      "Shard 11 contains 47 files\n",
      "Shard 12 has entries 564 ~ 611\n",
      "Shard 12 contains 47 files\n",
      "Shard 13 has entries 611 ~ 658\n",
      "Shard 13 contains 47 files\n",
      "Shard 14 has entries 658 ~ 705\n",
      "Shard 14 contains 47 files\n",
      "Shard 15 has entries 705 ~ 752\n",
      "Shard 15 contains 47 files\n",
      "Shard 16 has entries 752 ~ 799\n",
      "Shard 16 contains 47 files\n",
      "Shard 17 has entries 799 ~ 846\n",
      "Shard 17 contains 47 files\n",
      "Shard 18 has entries 846 ~ 893\n",
      "Shard 18 contains 47 files\n",
      "Shard 19 has entries 893 ~ 940\n",
      "Shard 19 contains 47 files\n",
      "Shard 20 has entries 940 ~ 987\n",
      "Shard 20 contains 47 files\n",
      "Shard 21 has entries 987 ~ 1034\n",
      "Shard 21 contains 47 files\n",
      "Shard 22 has entries 1034 ~ 1081\n",
      "Shard 22 contains 47 files\n",
      "Shard 23 has entries 1081 ~ 1128\n",
      "Shard 23 contains 47 files\n",
      "Shard 24 has entries 1128 ~ 1175\n",
      "Shard 24 contains 47 files\n",
      "Shard 25 has entries 1175 ~ 1222\n",
      "Shard 25 contains 47 files\n",
      "Shard 26 has entries 1222 ~ 1269\n",
      "Shard 26 contains 47 files\n",
      "Shard 27 has entries 1269 ~ 1316\n",
      "Shard 27 contains 47 files\n",
      "Shard 28 has entries 1316 ~ 1363\n",
      "Shard 28 contains 47 files\n",
      "Shard 29 has entries 1363 ~ 1410\n",
      "Shard 29 contains 47 files\n",
      "Shard 30 has entries 1410 ~ 1457\n",
      "Shard 30 contains 47 files\n",
      "Shard 31 has entries 1457 ~ 1504\n",
      "Shard 31 contains 47 files\n",
      "Have 15 entries left over that will be discarded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.17278412062133794s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.046422481536865234s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=4)]: Done  27 out of  32 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  29 out of  32 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  32 out of  32 | elapsed:    0.4s finished\n",
      "[NeMo W 2024-02-26 10:02:38 manifest:225] Manifest file `./tarred/tarred_audio_manifest.json` seems to be part of a tarred dataset, skip checking for relative paths. If this is not intended, please avoid having `/sharded_manifests/` and `tarred_audio_manifest.json` in manifest_filepath.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in manifest : 1504\n",
      "Note: we estimated the optimal bucketing duration bins for 30 buckets. You can enable dynamic bucketing by setting the following options in your training script:\n",
      "  use_lhotse=true\n",
      "  use_bucketing=true\n",
      "  num_buckets=30\n",
      "  bucket_duration_bins=[6.435,8.76,10.155,11.185,12.005,12.435,12.71,13.085,13.31,13.56,13.785,13.95,14.13,14.285,14.47,14.6,14.715,14.855,14.985,15.135,15.24,15.355,15.445,15.53,15.66,15.79,15.92,16.1299375,16.43]\n",
      "  batch_duration=<tune-this-value>\n",
      "If you'd like to use a different number of buckets, re-estimate this option manually using scripts/speech_recognition/estimate_duration_bins.py\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {nemo_root}\n",
    "python $1/scripts/speech_recognition/convert_to_tarred_audio_dataset.py \\\n",
    "    --manifest_path data/nemo_train-clean-5.json \\\n",
    "    --num_shards 32 \\\n",
    "    --workers 4 \\\n",
    "    --max_duration 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf18615-df6a-45a3-9e7f-aba7749bc5c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:02:42 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2024-02-26 10:02:43 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:02:43 speech_to_text_finetune:190] Hydra config: name: finetune_from_nemo_tarred\n",
      "    init_from_nemo_model: null\n",
      "    model:\n",
      "      sample_rate: 16000\n",
      "      compute_eval_loss: false\n",
      "      log_prediction: true\n",
      "      rnnt_reduction: mean_volume\n",
      "      skip_nan_grad: false\n",
      "      train_ds:\n",
      "        manifest_filepath: tarred/sharded_manifests/manifest__OP_0..31_CL_.json\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: null\n",
      "        shuffle: true\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        max_duration: 20\n",
      "        min_duration: 0.1\n",
      "        is_tarred: false\n",
      "        tarred_audio_filepaths: tarred/audio__OP_0..31_CL_.tar\n",
      "        shuffle_n: 2048\n",
      "        bucketing_strategy: fully_randomized\n",
      "        bucketing_batch_size: null\n",
      "        use_lhotse: true\n",
      "        batch_duration: 300\n",
      "        use_bucketing: true\n",
      "        num_buckets: 30\n",
      "        quadratic_duration: 15\n",
      "      validation_ds:\n",
      "        manifest_filepath: data/nemo_dev-clean-2.json\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 64\n",
      "        shuffle: false\n",
      "        use_start_end_token: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        use_lhotse: true\n",
      "      test_ds:\n",
      "        manifest_filepath: null\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: false\n",
      "        use_start_end_token: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "      char_labels:\n",
      "        update_labels: false\n",
      "        labels: null\n",
      "      tokenizer:\n",
      "        update_tokenizer: false\n",
      "        dir: null\n",
      "        type: bpe\n",
      "      spec_augment:\n",
      "        _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
      "        freq_masks: 2\n",
      "        time_masks: 10\n",
      "        freq_width: 27\n",
      "        time_width: 0.05\n",
      "      optim:\n",
      "        name: adamw\n",
      "        lr: 0.0001\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        weight_decay: 0.001\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 5000\n",
      "          warmup_ratio: null\n",
      "          min_lr: 5.0e-06\n",
      "    trainer:\n",
      "      devices: -1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 50\n",
      "      max_steps: 100\n",
      "      val_check_interval: 50\n",
      "      accelerator: auto\n",
      "      strategy: ddp\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 0.0\n",
      "      precision: 32\n",
      "      log_every_n_steps: 10\n",
      "      enable_progress_bar: true\n",
      "      num_sanity_val_steps: 0\n",
      "      check_val_every_n_epoch: 1\n",
      "      sync_batchnorm: true\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "      benchmark: false\n",
      "      use_distributed_sampler: false\n",
      "      limit_train_batches: 50\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        monitor: val_wer\n",
      "        mode: min\n",
      "        save_top_k: 5\n",
      "        always_save_nemo: true\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        name: null\n",
      "        project: null\n",
      "    init_from_pretrained_model: nvidia/stt_en_conformer_ctc_small\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:02:43 exp_manager:396] Experiments will be logged at /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_tarred/2024-02-26_10-02-43\n",
      "[NeMo I 2024-02-26 10:02:43 exp_manager:856] TensorboardLogger has been set up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:02:43 exp_manager:966] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 100. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:02:43 speech_to_text_finetune:99] Sleeping for at least 60 seconds to wait for model download to finish.\n",
      "[NeMo I 2024-02-26 10:03:44 mixins:172] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:03:44 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/NeMo_ASR_SET/English/v2.0/train/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/NeMo_ASR_SET/English/v2.0/train/audio__OP_0..4095_CL_.tar\n",
      "    \n",
      "[NeMo W 2024-02-26 10:03:44 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n",
      "[NeMo W 2024-02-26 10:03:44 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:03:44 features:289] PADDING: 0\n",
      "[NeMo I 2024-02-26 10:03:45 save_restore_connector:263] Model EncDecCTCModelBPE was successfully restored from /home/pzelasko/.cache/huggingface/hub/models--nvidia--stt_en_conformer_ctc_small/snapshots/f879b51de584983383de815ce87d25469b2abbf3/stt_en_conformer_ctc_small.nemo.\n",
      "[NeMo I 2024-02-26 10:03:45 speech_to_text_finetune:131] Reusing the vocabulary from the pre-trained model.\n",
      "We will be using a Lhotse DataLoader.\n",
      "Initializing Lhotse CutSet from a single NeMo manifest (tarred): 'tarred/sharded_manifests/manifest__OP_0..31_CL_.json'\n",
      "Creating a Lhotse DynamicBucketingSampler (max_batch_duration=300.0 max_batch_size=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:03:45 ctc_models:372] Model Trainer was not set before constructing the dataset, incorrect number of training batches will be used. Please set the trainer and rebuild the dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using a Lhotse DataLoader.\n",
      "Initializing Lhotse CutSet from a single NeMo manifest (tarred): 'data/nemo_dev-clean-2.json'\n",
      "Creating a Lhotse DynamicCutSampler (bucketing is disabled, (max_batch_duration=None max_batch_size=64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:03:46 modelPT:612] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:03:46 modelPT:723] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.0001\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:03:46 lr_scheduler:895] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:03:46 modelPT:723] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.0001\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2024-02-26 10:03:46 lr_scheduler:915] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f995c13c520>\" \n",
      "    will be used during training (effective maximum steps = 100) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 5000\n",
      "    warmup_ratio: null\n",
      "    min_lr: 5.0e-06\n",
      "    max_steps: 100\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConformerEncoder                  | 13.0 M\n",
      "2 | decoder           | ConvASRDecoder                    | 181 K \n",
      "3 | loss              | CTCLoss                           | 0     \n",
      "4 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "5 | wer               | WER                               | 0     \n",
      "6 | spec_augment      | SpectrogramAugmentation           | 0     \n",
      "------------------------------------------------------------------------\n",
      "13.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.2 M    Total params\n",
      "52.616    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18%|        | 9/50 [00:02<00:09,  4.26it/s, v_num=2-43, train_step_timing in s=0.118][NeMo I 2024-02-26 10:03:50 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:50 wer:319] reference:our itching is really the itching for the infinite the immeasurable like the rider on his forward panting horse we let the reins fall before the infinite we modern men we semi barbarians\n",
      "[NeMo I 2024-02-26 10:03:50 wer:320] predicted:chingching for thefinite themmeasurable theder hiswarding theinsll before the infin barb\n",
      "Epoch 0:  38%|      | 19/50 [00:03<00:05,  5.22it/s, v_num=2-43, train_step_timing in s=0.227][NeMo I 2024-02-26 10:03:51 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:51 wer:319] reference:and he saw them in the sand where the first tiny brook tinkled across the path from a gloomy ravine there the little creature had taken a flying leap across it and beyond he could see the prints no more he little guessed that while he halted to let his horse drink\n",
      "[NeMo I 2024-02-26 10:03:51 wer:320] predicted:and saw in the sand a first tiny booknked across the aloomyvine the littleture a it andon he could thence no he that helted to his horse\n",
      "Epoch 0:  58%|    | 29/50 [00:04<00:03,  5.89it/s, v_num=2-43, train_step_timing in s=0.113][NeMo I 2024-02-26 10:03:53 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:53 wer:319] reference:kara was given to making friends of his servants up to a point in his more generous moments he would address his bodyguard as fred and on more occasions than one and for no apparent reason had tipped his servant over and above his salary\n",
      "[NeMo I 2024-02-26 10:03:53 wer:320] predicted:a was given to making friends of his servants to a in his generous he would address hisdy guard and on more occasions than for noent reason servant over and above hisary\n",
      "Epoch 0:  78%|  | 39/50 [00:06<00:01,  6.23it/s, v_num=2-43, train_step_timing in s=0.0845][NeMo I 2024-02-26 10:03:54 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:54 wer:319] reference:did frederick move forward the moment was intense the coroner seemed to share the universal excitement\n",
      "[NeMo I 2024-02-26 10:03:54 wer:320] predicted:didrederick move forward the mo was inse the corner seemed to share the universalitement\n",
      "Epoch 0:  98%|| 49/50 [00:07<00:00,  6.54it/s, v_num=2-43, train_step_timing in s=0.121][NeMo I 2024-02-26 10:03:55 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:55 wer:319] reference:no one would fight for justinian who was caught and brought before the rebel leader in company with his two odious ministers\n",
      "[NeMo I 2024-02-26 10:03:55 wer:320] predicted:no one would fight for justinian who was caught and before the rebel leader in company with his twodious ministers\n",
      "Epoch 0: 100%|| 50/50 [00:07<00:00,  6.56it/s, v_num=2-43, train_step_timing in s=0.135]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]\u001b[A[NeMo I 2024-02-26 10:03:57 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:57 wer:319] reference:on the last saturday in april the new york times published an account of the strike complications which were delaying alexander's new jersey bridge and stated that the engineer himself was in town and at his office on west tenth street\n",
      "[NeMo I 2024-02-26 10:03:57 wer:320] predicted:on the lastturday in april the new york timesblished account of the strikelications which werelaying alexander's new jerseydge and stated that thengineer was in town and at his office on westth street\n",
      "\n",
      "Validation DataLoader 0: : 1it [00:00,  2.03it/s]\u001b[A[NeMo I 2024-02-26 10:03:57 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:57 wer:319] reference:she slid to the floor beside him as if she were too tired to sit up any longer\n",
      "[NeMo I 2024-02-26 10:03:57 wer:320] predicted:shelid theloor beside him as if she were too tired to sit up any longer\n",
      "\n",
      "Validation DataLoader 0: : 2it [00:00,  2.30it/s]\u001b[A[NeMo I 2024-02-26 10:03:57 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:57 wer:319] reference:and she got up and put her head into the oven\n",
      "[NeMo I 2024-02-26 10:03:57 wer:320] predicted:and she got up and put her head into the oven\n",
      "\n",
      "Validation DataLoader 0: : 3it [00:01,  2.20it/s]\u001b[A[NeMo I 2024-02-26 10:03:58 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:58 wer:319] reference:ah he did not depend upon emotional excitement to keep up his belief no declamations no anger no visions of blood red flags waving or metaphorical lurid suns of vengeance rising above the horizon of a doomed society not he\n",
      "[NeMo I 2024-02-26 10:03:58 wer:320] predicted:he did not depend upon emotional excitement to keep his belieflamations no anger no visions of blooddgs waving or metaphorical lud sons of vengeance rising above therizon of a doom society he\n",
      "\n",
      "Validation DataLoader 0: : 4it [00:01,  2.33it/s]\u001b[A[NeMo I 2024-02-26 10:03:58 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:58 wer:319] reference:he gets a red face poring over them\n",
      "[NeMo I 2024-02-26 10:03:58 wer:320] predicted:he gets a red face pouring over them\n",
      "\n",
      "Validation DataLoader 0: : 5it [00:02,  2.33it/s]\u001b[A[NeMo I 2024-02-26 10:03:59 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:59 wer:319] reference:his eyes wandered ceaselessly over the blank horizon\n",
      "[NeMo I 2024-02-26 10:03:59 wer:320] predicted:his eyes wandered ceasously over the blind horizon\n",
      "\n",
      "Validation DataLoader 0: : 6it [00:02,  2.49it/s]\u001b[A[NeMo I 2024-02-26 10:03:59 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:59 wer:319] reference:in flesh was raimented how he was killed and buried from the dead how he arose to life with victory and reigned in heaven how all of us shall be glorious like him whose hearts to his are wed how they who die for love of reason give hypocrites tyrants sophists all who sell their neighbours ill for holiness to hell how the dead saint condemns the bad who live how all he does becomes a law for men how he at last to judge shall come again\n",
      "[NeMo I 2024-02-26 10:03:59 wer:320] predicted:and fleshmented how he was killed andried from thead how he arose to life with victory and reig and heaven of us shall glorious like him whosearts to his ared how they who die for of reasonypocritesyrantsphists all wholl their neighbours ill forliness to hell how the dead saintdemns the bad who live how all he becomes a law for men how he at last to judge shall come again\n",
      "\n",
      "Validation DataLoader 0: : 7it [00:03,  2.32it/s]\u001b[A[NeMo I 2024-02-26 10:03:59 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:03:59 wer:319] reference:that's funny remarked betsy thoughtfully\n",
      "[NeMo I 2024-02-26 10:03:59 wer:320] predicted:'s funnymark tod thought\n",
      "\n",
      "Validation DataLoader 0: : 8it [00:03,  2.40it/s]\u001b[A[NeMo I 2024-02-26 10:04:00 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:00 wer:319] reference:at the usual hour mister dorriforth and his ward were summoned to tea he entered with a countenance which evinced the remains of anger his eye gave testimony of his absent thoughts and though he took up a pamphlet affecting to read it was plain to discern that he scarcely knew he held it in his hand\n",
      "[NeMo I 2024-02-26 10:04:00 wer:320] predicted:at the usual hour mr doriforth and his ward were summoned to tea he entered with a countenance which evince the remains of anger hisye gave testimony of absent thoughts and though he tookmphlet effecting to it was plain tocer that he scarcely knew he held it in his hand\n",
      "\n",
      "Validation DataLoader 0: : 9it [00:03,  2.46it/s]\u001b[A[NeMo I 2024-02-26 10:04:00 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:00 wer:319] reference:only a little food will be required\n",
      "[NeMo I 2024-02-26 10:04:00 wer:320] predicted:only a little food will be required\n",
      "\n",
      "Validation DataLoader 0: : 10it [00:04,  2.39it/s]\u001b[A[NeMo I 2024-02-26 10:04:01 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:01 wer:319] reference:tom says thanks and looks at hilda and she blushes really\n",
      "[NeMo I 2024-02-26 10:04:01 wer:320] predicted:mp says thanks and looks at hilda and she blushes really\n",
      "\n",
      "Validation DataLoader 0: : 11it [00:04,  2.49it/s]\u001b[A[NeMo I 2024-02-26 10:04:01 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:01 wer:319] reference:for these read fibi and vinos that we may conform to english pronunciation\n",
      "[NeMo I 2024-02-26 10:04:01 wer:320] predicted:for thesedb and venus that we mayorm to englishnunciation\n",
      "\n",
      "Validation DataLoader 0: : 12it [00:04,  2.58it/s]\u001b[A[NeMo I 2024-02-26 10:04:01 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:01 wer:319] reference:he would make a famous scoundrel\n",
      "[NeMo I 2024-02-26 10:04:01 wer:320] predicted:he would make amousoundrl\n",
      "\n",
      "Validation DataLoader 0: : 13it [00:05,  2.59it/s]\u001b[A[NeMo I 2024-02-26 10:04:01 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:01 wer:319] reference:by and by a short figure smoking a cheroot came up out of the dark and proved to be doctor macklewain who had been prevented from attending the dinner by reason of an accident to a constable at norfolk bay which had claimed his professional attention\n",
      "[NeMo I 2024-02-26 10:04:01 wer:320] predicted:and by a short figure smoking aroot came up out of the dark and proved to bector mack wayne who had been prevented fromtending the dinner by reason of accident to a constable at norfolk bay which had claimed his professional attention\n",
      "\n",
      "Validation DataLoader 0: : 14it [00:05,  2.66it/s]\u001b[A[NeMo I 2024-02-26 10:04:02 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:02 wer:319] reference:a snake of his size in fighting trim would be more than any boy could handle\n",
      "[NeMo I 2024-02-26 10:04:02 wer:320] predicted:a snake of its size and fightingm be more than the could handle\n",
      "\n",
      "Validation DataLoader 0: : 15it [00:05,  2.65it/s]\u001b[A[NeMo I 2024-02-26 10:04:02 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:02 wer:319] reference:who is touching me and untrussing me\n",
      "[NeMo I 2024-02-26 10:04:02 wer:320] predicted:who is touching me and un trustting me\n",
      "\n",
      "Validation DataLoader 0: : 16it [00:06,  2.60it/s]\u001b[A[NeMo I 2024-02-26 10:04:03 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:03 wer:319] reference:some are wonderfully wrought pretty little homes for birdikins\n",
      "[NeMo I 2024-02-26 10:04:03 wer:320] predicted:some are wonderfully wught pretty little homes forrdkins\n",
      "\n",
      "Validation DataLoader 0: : 17it [00:06,  2.57it/s]\u001b[A[NeMo I 2024-02-26 10:04:03 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:03 wer:319] reference:he was that child's stay and she was his prop\n",
      "[NeMo I 2024-02-26 10:04:03 wer:320] predicted:he wass she wasub\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:04:03 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('global_step', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:04:03 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:04:03 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('val_wer', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 50/50 [00:15<00:00,  3.31it/s, v_num=2-43, train_step_timing in s=0.135]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_wer' reached 0.24734 (best 0.24734), saving model to '/home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_tarred/2024-02-26_10-02-43/checkpoints/finetune_from_nemo_tarred--val_wer=0.2473-epoch=0.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \u001b[A[NeMo I 2024-02-26 10:04:03 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_tarred/2024-02-26_10-02-43/checkpoints/finetune_from_nemo_tarred.nemo\n",
      "[NeMo I 2024-02-26 10:04:04 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_tarred/2024-02-26_10-02-43/checkpoints/finetune_from_nemo_tarred.nemo\n",
      "Epoch 1:  18%|        | 9/50 [00:01<00:05,  7.66it/s, v_num=2-43, train_step_timing in s=0.102][NeMo I 2024-02-26 10:04:06 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:06 wer:319] reference:gave me the creeps too makes me surer than ever that he has an abominably deep purpose in using his wits to hang on here he suggests resources as hard to understand as anything that has happened in the old room you'll confess bobby he's had a good deal of influence over you an influence for evil\n",
      "[NeMo I 2024-02-26 10:04:06 wer:320] predicted:me the can than that he hasbom hist here hes re soources as hard to understand that happen in theess bo he had a goodal of influence an influ for\n",
      "Epoch 1:  38%|      | 19/50 [00:02<00:04,  7.41it/s, v_num=2-43, train_step_timing in s=0.115][NeMo I 2024-02-26 10:04:07 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:07 wer:319] reference:and put out the eyes of the patriarch who had crowned him then he set to work to hunt out meaner victims many prominent citizens of constantinople were sown up in sacks and drowned in the bosphorus soldiers were picked out by the dozen and beheaded\n",
      "[NeMo I 2024-02-26 10:04:07 wer:320] predicted:and out theyes of thetriar who him then hent outctims manyminents oflewn incksow in the bosphuslders anded\n",
      "Epoch 1:  58%|    | 29/50 [00:03<00:02,  8.08it/s, v_num=2-43, train_step_timing in s=0.107] [NeMo I 2024-02-26 10:04:09 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:09 wer:319] reference:entered the tap room they emerged thence a moment later\n",
      "[NeMo I 2024-02-26 10:04:09 wer:320] predicted:entered the tap room they emerged thence a moment later\n",
      "Epoch 1:  78%|  | 39/50 [00:04<00:01,  8.11it/s, v_num=2-43, train_step_timing in s=0.0988][NeMo I 2024-02-26 10:04:10 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:10 wer:319] reference:was the firm response then gentlemen continued frederick still without looking at amabel whose smile had acquired a mockery that drew the eyes of the jury toward her more than once during the following recital\n",
      "[NeMo I 2024-02-26 10:04:10 wer:320] predicted:thespon genlemen continuedredeckck theyes of the to theingal\n",
      "Epoch 1:  98%|| 49/50 [00:06<00:00,  8.14it/s, v_num=2-43, train_step_timing in s=0.121][NeMo I 2024-02-26 10:04:11 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:11 wer:319] reference:a purse of two hundred fifty dollars was made up to be given to the horse that could first reach wyandotte four miles distant the arrangement was carried out and brigham was entered as one of the contestants for the purse\n",
      "[NeMo I 2024-02-26 10:04:11 wer:320] predicted:a purse of hundred fifty dollars was up to ben to the that first reach mi the was carried andham wastered as of the contestants for the\n",
      "Epoch 1: 100%|| 50/50 [00:06<00:00,  8.13it/s, v_num=2-43, train_step_timing in s=0.131]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]\u001b[A[NeMo I 2024-02-26 10:04:12 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:12 wer:319] reference:on the last saturday in april the new york times published an account of the strike complications which were delaying alexander's new jersey bridge and stated that the engineer himself was in town and at his office on west tenth street\n",
      "[NeMo I 2024-02-26 10:04:12 wer:320] predicted:on the lastturday in april the new timesblished account of the strikelications which werelaying alexander's jerseydge and stated that thengineer in town and onstth street\n",
      "\n",
      "Validation DataLoader 0: : 1it [00:00,  4.20it/s]\u001b[A[NeMo I 2024-02-26 10:04:12 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:12 wer:319] reference:she slid to the floor beside him as if she were too tired to sit up any longer\n",
      "[NeMo I 2024-02-26 10:04:12 wer:320] predicted:sheli theloor beside him as if she were too tired to sit any longer\n",
      "\n",
      "Validation DataLoader 0: : 2it [00:00,  4.04it/s]\u001b[A[NeMo I 2024-02-26 10:04:13 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:13 wer:319] reference:and she got up and put her head into the oven\n",
      "[NeMo I 2024-02-26 10:04:13 wer:320] predicted:and she and put her head into theven\n",
      "\n",
      "Validation DataLoader 0: : 3it [00:00,  3.05it/s]\u001b[A[NeMo I 2024-02-26 10:04:13 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:13 wer:319] reference:ah he did not depend upon emotional excitement to keep up his belief no declamations no anger no visions of blood red flags waving or metaphorical lurid suns of vengeance rising above the horizon of a doomed society not he\n",
      "[NeMo I 2024-02-26 10:04:13 wer:320] predicted:he did not depend upon emotional excitement to keep his belieflamations no angersions of blooddgsving metaphorical lud sons ofngeance rising above therizon of a doom not he\n",
      "\n",
      "Validation DataLoader 0: : 4it [00:01,  3.12it/s]\u001b[A[NeMo I 2024-02-26 10:04:13 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:13 wer:319] reference:he gets a red face poring over them\n",
      "[NeMo I 2024-02-26 10:04:13 wer:320] predicted:he gets a red face pouring them\n",
      "\n",
      "Validation DataLoader 0: : 5it [00:01,  2.94it/s]\u001b[A[NeMo I 2024-02-26 10:04:14 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:14 wer:319] reference:his eyes wandered ceaselessly over the blank horizon\n",
      "[NeMo I 2024-02-26 10:04:14 wer:320] predicted:yesedly the blindrizon\n",
      "\n",
      "Validation DataLoader 0: : 6it [00:01,  3.05it/s]\u001b[A[NeMo I 2024-02-26 10:04:14 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:14 wer:319] reference:in flesh was raimented how he was killed and buried from the dead how he arose to life with victory and reigned in heaven how all of us shall be glorious like him whose hearts to his are wed how they who die for love of reason give hypocrites tyrants sophists all who sell their neighbours ill for holiness to hell how the dead saint condemns the bad who live how all he does becomes a law for men how he at last to judge shall come again\n",
      "[NeMo I 2024-02-26 10:04:14 wer:320] predicted:fleshmented helled andried from thead how he arose to life victory and reigin and heaven of glorious like whose hearts to his ared they who die for ofyppocritesyrantsphs wholl their neighbours ill for holiness to hell theadintdemns the bad who live hes a law for men how he at todge shall again\n",
      "\n",
      "Validation DataLoader 0: : 7it [00:02,  2.72it/s]\u001b[A[NeMo I 2024-02-26 10:04:15 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:15 wer:319] reference:that's funny remarked betsy thoughtfully\n",
      "[NeMo I 2024-02-26 10:04:15 wer:320] predicted:'s funnymark for\n",
      "\n",
      "Validation DataLoader 0: : 8it [00:02,  2.77it/s]\u001b[A[NeMo I 2024-02-26 10:04:15 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:15 wer:319] reference:at the usual hour mister dorriforth and his ward were summoned to tea he entered with a countenance which evinced the remains of anger his eye gave testimony of his absent thoughts and though he took up a pamphlet affecting to read it was plain to discern that he scarcely knew he held it in his hand\n",
      "[NeMo I 2024-02-26 10:04:15 wer:320] predicted:at theual hour mr dorifor and his ward were summoned to tea he entered with a countenance which evince thes of anger hisye gave testimony of absent thoughts though he tookmphlet effecting to it was plain toc that hearcely he held it in his\n",
      "\n",
      "Validation DataLoader 0: : 9it [00:03,  2.80it/s]\u001b[A[NeMo I 2024-02-26 10:04:15 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:15 wer:319] reference:only a little food will be required\n",
      "[NeMo I 2024-02-26 10:04:15 wer:320] predicted:only a little food will be required\n",
      "\n",
      "Validation DataLoader 0: : 10it [00:03,  2.68it/s]\u001b[A[NeMo I 2024-02-26 10:04:16 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:16 wer:319] reference:tom says thanks and looks at hilda and she blushes really\n",
      "[NeMo I 2024-02-26 10:04:16 wer:320] predicted:s thanks and at hell blushes\n",
      "\n",
      "Validation DataLoader 0: : 11it [00:03,  2.78it/s]\u001b[A[NeMo I 2024-02-26 10:04:16 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:16 wer:319] reference:for these read fibi and vinos that we may conform to english pronunciation\n",
      "[NeMo I 2024-02-26 10:04:16 wer:320] predicted:for thisb andnus that we mayorm to englishnunciation\n",
      "\n",
      "Validation DataLoader 0: : 12it [00:04,  2.86it/s]\u001b[A[NeMo I 2024-02-26 10:04:16 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:16 wer:319] reference:he would make a famous scoundrel\n",
      "[NeMo I 2024-02-26 10:04:16 wer:320] predicted:he would makemous\n",
      "\n",
      "Validation DataLoader 0: : 13it [00:04,  2.85it/s]\u001b[A[NeMo I 2024-02-26 10:04:17 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:17 wer:319] reference:by and by a short figure smoking a cheroot came up out of the dark and proved to be doctor macklewain who had been prevented from attending the dinner by reason of an accident to a constable at norfolk bay which had claimed his professional attention\n",
      "[NeMo I 2024-02-26 10:04:17 wer:320] predicted:and by a short figure smoking aroot up out of therk and proved toctor mackel wayne who had beenvented fromtending the dinner by ofident to a constable atrfolk bay hadlaimed hisfessionaltention\n",
      "\n",
      "Validation DataLoader 0: : 14it [00:04,  2.92it/s]\u001b[A[NeMo I 2024-02-26 10:04:17 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:17 wer:319] reference:a snake of his size in fighting trim would be more than any boy could handle\n",
      "[NeMo I 2024-02-26 10:04:17 wer:320] predicted:a snake of its size andightingm be more than the couldle\n",
      "\n",
      "Validation DataLoader 0: : 15it [00:05,  2.88it/s]\u001b[A[NeMo I 2024-02-26 10:04:17 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:17 wer:319] reference:who is touching me and untrussing me\n",
      "[NeMo I 2024-02-26 10:04:17 wer:320] predicted:touching me andruing me\n",
      "\n",
      "Validation DataLoader 0: : 16it [00:05,  2.82it/s]\u001b[A[NeMo I 2024-02-26 10:04:18 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:18 wer:319] reference:some are wonderfully wrought pretty little homes for birdikins\n",
      "[NeMo I 2024-02-26 10:04:18 wer:320] predicted:some arefullyught littles forrdkins\n",
      "\n",
      "Validation DataLoader 0: : 17it [00:06,  2.76it/s]\u001b[A[NeMo I 2024-02-26 10:04:18 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:04:18 wer:319] reference:he was that child's stay and she was his prop\n",
      "[NeMo I 2024-02-26 10:04:18 wer:320] predicted:hes sheud\n",
      "\n",
      "Epoch 1: 100%|| 50/50 [00:13<00:00,  3.82it/s, v_num=2-43, train_step_timing in s=0.131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 100: 'val_wer' reached 0.44016 (best 0.24734), saving model to '/home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_tarred/2024-02-26_10-02-43/checkpoints/finetune_from_nemo_tarred--val_wer=0.4402-epoch=1.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  \u001b[A[NeMo I 2024-02-26 10:04:19 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_tarred/2024-02-26_10-02-43/checkpoints/finetune_from_nemo_tarred.nemo\n",
      "[NeMo I 2024-02-26 10:04:19 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_tarred/2024-02-26_10-02-43/checkpoints/finetune_from_nemo_tarred.nemo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|| 50/50 [00:14<00:00,  3.36it/s, v_num=2-43, train_step_timing in s=0.131]\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {nemo_root}\n",
    "python $1/examples/asr/speech_to_text_finetune.py \\\n",
    "    +init_from_pretrained_model=\"nvidia/stt_en_conformer_ctc_small\" \\\n",
    "    name=\"finetune_from_nemo_tarred\" \\\n",
    "    +model.train_ds.use_lhotse=true \\\n",
    "    model.train_ds.manifest_filepath=tarred/sharded_manifests/manifest__OP_0..31_CL_.json \\\n",
    "    model.train_ds.tarred_audio_filepaths=tarred/audio__OP_0..31_CL_.tar \\\n",
    "    model.train_ds.batch_size=null \\\n",
    "    +model.train_ds.batch_duration=300 \\\n",
    "    +model.train_ds.use_bucketing=true \\\n",
    "    +model.train_ds.num_buckets=30 \\\n",
    "    +model.train_ds.quadratic_duration=15 \\\n",
    "    +model.validation_ds.use_lhotse=true \\\n",
    "    model.validation_ds.manifest_filepath=data/nemo_dev-clean-2.json \\\n",
    "    model.validation_ds.batch_size=64 \\\n",
    "    +trainer.use_distributed_sampler=false \\\n",
    "    trainer.max_steps=100 \\\n",
    "    +trainer.limit_train_batches=50 \\\n",
    "    ++trainer.val_check_interval=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71abb816-7908-4b33-a0e7-e60965636b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " finetune_from_nemo_tarred.nemo\n",
      "'finetune_from_nemo_tarred--val_wer=0.2473-epoch=0.ckpt'\n",
      "'finetune_from_nemo_tarred--val_wer=0.4402-epoch=1.ckpt'\n",
      "'finetune_from_nemo_tarred--val_wer=0.4402-epoch=1-last.ckpt'\n"
     ]
    }
   ],
   "source": [
    "!ls nemo_experiments/finetune_from_nemo_tarred/*/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d97bb-e6ed-4ea9-9df0-5baeb1bd38c6",
   "metadata": {},
   "source": [
    "## IV. Dynamically mixing multiple NeMo tarred datasets\n",
    "\n",
    "Let's introduce another feature of NeMo+Lhotse dataloading: mixing multiple datasets together. \n",
    "\n",
    "Lhotse supports a special type of data mixing that we call **weighted stochastic multiplexing**. It means that when we iterate multiple independent data sources, at each step we'll sample one source to pick the next item from according to the source weights. When the weight is not provided, we count the number of elements in each source before starting dataloading and use those as \"natural\" weights (this can be time-expensive, so it's best to precompute and provide those explicitly). This sampling strategy ensures that each mini-batch consists of a roughly constant blend of data from multiple sources throughout the training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce9b4c-df69-4849-af16-5aefbb800997",
   "metadata": {},
   "source": [
    "### Fetch another dataset (yesno)\n",
    "\n",
    "For these experiments, we download another small dataset called `yesno`. It's a bunch of recordings where a single person says either \"yes\" or \"no\" in Hebrew, with transcriptions in English (so it's technically a speech translation task). We convert the data to NeMo tarred format, same as previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51688267-c5c6-4a8d-bd99-7684320d11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yesno_root = download_yesno(root_dir)\n",
    "\n",
    "yesno = prepare_yesno(yesno_root, output_dir=root_dir)\n",
    "\n",
    "for split in (\"train\", \"test\"):\n",
    "    cuts = CutSet.from_manifests(**yesno[split])\n",
    "    cuts.to_file(f\"data/yesno_cuts_{split}.jsonl.gz\")\n",
    "    lhotse.serialization.save_to_jsonl(\n",
    "        (\n",
    "            {\n",
    "                \"audio_filepath\": cut.recording.sources[0].source,\n",
    "                \"duration\": cut.duration,\n",
    "                \"text\": cut.supervisions[0].text,\n",
    "                \"lang\": cut.supervisions[0].language,\n",
    "                \"sampling_rate\": cut.sampling_rate,\n",
    "            }\n",
    "            for cut in cuts\n",
    "        ),\n",
    "        f\"data/yesno_{split}.json\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cc78d14-f769-4535-8da2-02b1c1a2466a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pzelasko/code/NeMo/scripts/speech_recognition/create_dali_tarred_dataset_index.py:71: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=None, config_name='index_config')\n",
      "[NeMo W 2024-02-26 10:04:26 manifest:225] Manifest file `yesno_tarred/tarred_audio_manifest.json` seems to be part of a tarred dataset, skip checking for relative paths. If this is not intended, please avoid having `/sharded_manifests/` and `tarred_audio_manifest.json` in manifest_filepath.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new tarred dataset ...\n",
      "After filtering, manifest has 30 files which amounts to 181.39000000000001 seconds of audio.\n",
      "Number of samples added : 30\n",
      "Remainder: 0\n",
      "Shard 0 has entries 0 ~ 30\n",
      "Shard 0 contains 30 files\n",
      "Have 0 entries left over that will be discarded.\n",
      "Total number of entries in manifest : 30\n",
      "Note: we estimated the optimal bucketing duration bins for 30 buckets. You can enable dynamic bucketing by setting the following options in your training script:\n",
      "  use_lhotse=true\n",
      "  use_bucketing=true\n",
      "  num_buckets=30\n",
      "  bucket_duration_bins=[5.58,5.71,5.87,5.92,5.98,6.02,6.05,6.08,6.11,6.16,6.18,6.18,6.22,6.22,6.23,6.24,6.32,6.35,6.4,6.58,6.6,6.74]\n",
      "  batch_duration=<tune-this-value>\n",
      "If you'd like to use a different number of buckets, re-estimate this option manually using scripts/speech_recognition/estimate_duration_bins.py\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {nemo_root}\n",
    "python $1/scripts/speech_recognition/convert_to_tarred_audio_dataset.py \\\n",
    "    --manifest_path data/yesno_train.json \\\n",
    "    --num_shards 1 \\\n",
    "    --workers 1 \\\n",
    "    --max_duration 30 \\\n",
    "    --target_dir yesno_tarred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dddc26-8f97-4d78-b2ac-9b5218d7da4b",
   "metadata": {},
   "source": [
    "### [optional] Maximum efficiency: precomputing bucket duration bins\n",
    "\n",
    "We'll use a NeMo script `estimate_duration_bins.py` to precompute the optimal bucketing settings for our data blend. The result will be passed to the training script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "002e5f4c-9378-4009-bdf5-fec8d8b0624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash -s {nemo_root}\n",
    "# python $1/scripts/speech_recognition/estimate_duration_bins.py \\\n",
    "#     --buckets 30 \\\n",
    "#     '[[tarred/sharded_manifests/manifest__OP_0..31_CL_.json,0.8],[yesno_tarred/tarred_audio_manifest.json,0.2]]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909254b-fde8-46bd-9b05-c21da9396a3a",
   "metadata": {},
   "source": [
    "### Training with NeMo tarred manifests from two separate datasets\n",
    "\n",
    "The training command is similar to the examples above. Highlights:\n",
    "- Note that `manifest_filepath` and `tarred_audio_filepaths` now use a special list syntax for providing multiple data sources. Both lists need to have the same order of datasets.\n",
    "- The list in `manifest_filepath` is additionally specifying the weight for each dataset. The weights can be greater than one, and will be automatically re-normalized later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1522cc88-187d-43fd-b299-95cbf6dac391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:04:29 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2024-02-26 10:04:31 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:04:31 speech_to_text_finetune:190] Hydra config: name: finetune_from_nemo_multidataset\n",
      "    init_from_nemo_model: null\n",
      "    model:\n",
      "      sample_rate: 16000\n",
      "      compute_eval_loss: false\n",
      "      log_prediction: true\n",
      "      rnnt_reduction: mean_volume\n",
      "      skip_nan_grad: false\n",
      "      train_ds:\n",
      "        manifest_filepath:\n",
      "        - - tarred/sharded_manifests/manifest__OP_0..31_CL_.json\n",
      "          - 0.8\n",
      "        - - yesno_tarred/tarred_audio_manifest.json\n",
      "          - 0.2\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: null\n",
      "        shuffle: true\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        max_duration: 20\n",
      "        min_duration: 0.1\n",
      "        is_tarred: false\n",
      "        tarred_audio_filepaths:\n",
      "        - - tarred/audio__OP_0..31_CL_.tar\n",
      "        - - yesno_tarred/audio_0.tar\n",
      "        shuffle_n: 2048\n",
      "        bucketing_strategy: fully_randomized\n",
      "        bucketing_batch_size: null\n",
      "        use_lhotse: true\n",
      "        batch_duration: 300\n",
      "        use_bucketing: true\n",
      "        num_buckets: 30\n",
      "        quadratic_duration: 15\n",
      "      validation_ds:\n",
      "        manifest_filepath:\n",
      "        - data/nemo_dev-clean-2.json\n",
      "        - data/yesno_test.json\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 64\n",
      "        shuffle: false\n",
      "        use_start_end_token: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        use_lhotse: true\n",
      "      test_ds:\n",
      "        manifest_filepath: null\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: false\n",
      "        use_start_end_token: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "      char_labels:\n",
      "        update_labels: false\n",
      "        labels: null\n",
      "      tokenizer:\n",
      "        update_tokenizer: false\n",
      "        dir: null\n",
      "        type: bpe\n",
      "      spec_augment:\n",
      "        _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
      "        freq_masks: 2\n",
      "        time_masks: 10\n",
      "        freq_width: 27\n",
      "        time_width: 0.05\n",
      "      optim:\n",
      "        name: adamw\n",
      "        lr: 0.0001\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        weight_decay: 0.001\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 5000\n",
      "          warmup_ratio: null\n",
      "          min_lr: 5.0e-06\n",
      "    trainer:\n",
      "      devices: -1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 50\n",
      "      max_steps: 100\n",
      "      val_check_interval: 50\n",
      "      accelerator: auto\n",
      "      strategy: ddp\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 0.0\n",
      "      precision: 32\n",
      "      log_every_n_steps: 10\n",
      "      enable_progress_bar: true\n",
      "      num_sanity_val_steps: 0\n",
      "      check_val_every_n_epoch: 1\n",
      "      sync_batchnorm: true\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "      benchmark: false\n",
      "      use_distributed_sampler: false\n",
      "      limit_train_batches: 50\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        monitor: val_wer\n",
      "        mode: min\n",
      "        save_top_k: 5\n",
      "        always_save_nemo: true\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        name: null\n",
      "        project: null\n",
      "    init_from_pretrained_model: nvidia/stt_en_conformer_ctc_small\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:04:31 exp_manager:396] Experiments will be logged at /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_multidataset/2024-02-26_10-04-31\n",
      "[NeMo I 2024-02-26 10:04:31 exp_manager:856] TensorboardLogger has been set up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:04:31 exp_manager:966] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 100. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:04:31 speech_to_text_finetune:99] Sleeping for at least 60 seconds to wait for model download to finish.\n",
      "[NeMo I 2024-02-26 10:05:32 mixins:172] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:05:32 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/NeMo_ASR_SET/English/v2.0/train/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/NeMo_ASR_SET/English/v2.0/train/audio__OP_0..4095_CL_.tar\n",
      "    \n",
      "[NeMo W 2024-02-26 10:05:32 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n",
      "[NeMo W 2024-02-26 10:05:32 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:05:32 features:289] PADDING: 0\n",
      "[NeMo I 2024-02-26 10:05:33 save_restore_connector:263] Model EncDecCTCModelBPE was successfully restored from /home/pzelasko/.cache/huggingface/hub/models--nvidia--stt_en_conformer_ctc_small/snapshots/f879b51de584983383de815ce87d25469b2abbf3/stt_en_conformer_ctc_small.nemo.\n",
      "[NeMo I 2024-02-26 10:05:33 speech_to_text_finetune:131] Reusing the vocabulary from the pre-trained model.\n",
      "We will be using a Lhotse DataLoader.\n",
      "Initializing Lhotse CutSet from multiple tarred NeMo manifest sources with a weighted multiplexer. We found the following sources and weights: \n",
      "- manifest_path='tarred/sharded_manifests/manifest__OP_0..31_CL_.json' weight=0.8\n",
      "- manifest_path='yesno_tarred/tarred_audio_manifest.json' weight=0.2\n",
      "Creating a Lhotse DynamicBucketingSampler (max_batch_duration=300.0 max_batch_size=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:05:36 ctc_models:372] Model Trainer was not set before constructing the dataset, incorrect number of training batches will be used. Please set the trainer and rebuild the dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using a Lhotse DataLoader.\n",
      "Initializing Lhotse CutSet from a single NeMo manifest (tarred): 'data/nemo_dev-clean-2.json'\n",
      "Creating a Lhotse DynamicCutSampler (bucketing is disabled, (max_batch_duration=None max_batch_size=64)\n",
      "We will be using a Lhotse DataLoader.\n",
      "Initializing Lhotse CutSet from a single NeMo manifest (tarred): 'data/yesno_test.json'\n",
      "Creating a Lhotse DynamicCutSampler (bucketing is disabled, (max_batch_duration=None max_batch_size=64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:05:36 modelPT:612] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:05:36 modelPT:723] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.0001\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:05:36 lr_scheduler:895] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-02-26 10:05:37 modelPT:723] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.0001\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2024-02-26 10:05:37 lr_scheduler:915] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7efe042dcd00>\" \n",
      "    will be used during training (effective maximum steps = 100) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 5000\n",
      "    warmup_ratio: null\n",
      "    min_lr: 5.0e-06\n",
      "    max_steps: 100\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConformerEncoder                  | 13.0 M\n",
      "2 | decoder           | ConvASRDecoder                    | 181 K \n",
      "3 | loss              | CTCLoss                           | 0     \n",
      "4 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "5 | wer               | WER                               | 0     \n",
      "6 | spec_augment      | SpectrogramAugmentation           | 0     \n",
      "------------------------------------------------------------------------\n",
      "13.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.2 M    Total params\n",
      "52.616    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18%|        | 9/50 [00:10<00:49,  1.20s/it, v_num=4-31, train_step_timing in s=0.126][NeMo I 2024-02-26 10:05:49 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:49 wer:319] reference:mere chance and yet to jane it seemed so like him to have taken up his position precisely at the right spot on that long platform an enthusiastic lady patient had once said of deryck brand with more accuracy of definition than of grammar\n",
      "[NeMo I 2024-02-26 10:05:49 wer:320] predicted:tone it so like him take his positioncisely at the right spot on thatatformthusiastic ladytient had ofricknd with moreuracy ofinition than grammar\n",
      "Epoch 0:  38%|      | 19/50 [00:12<00:19,  1.57it/s, v_num=4-31, train_step_timing in s=0.115][NeMo I 2024-02-26 10:05:51 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:51 wer:319] reference:look at morgan and rockefeller and all the men that make a pile they know just as much as jeff did about the countries where they make it it stands to reason did i say that jeff shaved in the same old way not quite\n",
      "[NeMo I 2024-02-26 10:05:51 wer:320] predicted:atrgan andfell and the men that a they as muchff about the where they make itss to reason i say thatff in the\n",
      "Epoch 0:  58%|    | 29/50 [00:13<00:09,  2.15it/s, v_num=4-31, train_step_timing in s=0.151][NeMo I 2024-02-26 10:05:52 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:52 wer:319] reference:she picketed her steed hung up her weapons and warmed herself comfortably by his fire the halt in that roving restless life was inexpressibly soothing and pleasant to her\n",
      "[NeMo I 2024-02-26 10:05:52 wer:320] predicted:shecked at heredngapons andmedselffortable hisre the whole thatvingless lifeexpress soothing andasant to her\n",
      "Epoch 0:  78%|  | 39/50 [00:14<00:04,  2.65it/s, v_num=4-31, train_step_timing in s=0.0841][NeMo I 2024-02-26 10:05:53 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:53 wer:319] reference:no yes yes yes yes yes yes yes\n",
      "[NeMo I 2024-02-26 10:05:53 wer:320] predicted:\n",
      "Epoch 0:  98%|| 49/50 [00:16<00:00,  3.05it/s, v_num=4-31, train_step_timing in s=0.124][NeMo I 2024-02-26 10:05:54 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:54 wer:319] reference:and had been constantly befriended by the good william why when your papa was a little boy she said he often told me that it was william who defended him against a tyrant at the school where they were\n",
      "[NeMo I 2024-02-26 10:05:54 wer:320] predicted:and the when youpa was a little boy she he and told that it wasended him against theyrant at the school they were\n",
      "Epoch 0: 100%|| 50/50 [00:16<00:00,  3.09it/s, v_num=4-31, train_step_timing in s=0.128]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]\u001b[A[NeMo I 2024-02-26 10:05:56 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:56 wer:319] reference:on the last saturday in april the new york times published an account of the strike complications which were delaying alexander's new jersey bridge and stated that the engineer himself was in town and at his office on west tenth street\n",
      "[NeMo I 2024-02-26 10:05:56 wer:320] predicted:the lastturday in april the timesblished account of the strikelications werelaying alexander's jerseydge and stated that thengineer town and onstth street\n",
      "\n",
      "Validation DataLoader 0: : 1it [00:00,  2.01it/s]\u001b[A[NeMo I 2024-02-26 10:05:56 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:56 wer:319] reference:she slid to the floor beside him as if she were too tired to sit up any longer\n",
      "[NeMo I 2024-02-26 10:05:56 wer:320] predicted:shelid theloor beside him as if she were too tired to sit any longer\n",
      "\n",
      "Validation DataLoader 0: : 2it [00:00,  2.39it/s]\u001b[A[NeMo I 2024-02-26 10:05:57 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:57 wer:319] reference:and she got up and put her head into the oven\n",
      "[NeMo I 2024-02-26 10:05:57 wer:320] predicted:and she and put her head into theven\n",
      "\n",
      "Validation DataLoader 0: : 3it [00:01,  2.11it/s]\u001b[A[NeMo I 2024-02-26 10:05:57 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:57 wer:319] reference:ah he did not depend upon emotional excitement to keep up his belief no declamations no anger no visions of blood red flags waving or metaphorical lurid suns of vengeance rising above the horizon of a doomed society not he\n",
      "[NeMo I 2024-02-26 10:05:57 wer:320] predicted:he depend upon emotional excitement to keep his belieflamationsngersions of blooddgsving metaphoricald sons ofngeance rising above therizon of a doom\n",
      "\n",
      "Validation DataLoader 0: : 4it [00:01,  2.36it/s]\u001b[A[NeMo I 2024-02-26 10:05:57 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:57 wer:319] reference:he gets a red face poring over them\n",
      "[NeMo I 2024-02-26 10:05:57 wer:320] predicted:he gets a red face pouring them\n",
      "\n",
      "Validation DataLoader 0: : 5it [00:02,  2.36it/s]\u001b[A[NeMo I 2024-02-26 10:05:58 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:58 wer:319] reference:his eyes wandered ceaselessly over the blank horizon\n",
      "[NeMo I 2024-02-26 10:05:58 wer:320] predicted:yesandedasously the blindrizon\n",
      "\n",
      "Validation DataLoader 0: : 6it [00:02,  2.52it/s]\u001b[A[NeMo I 2024-02-26 10:05:58 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:58 wer:319] reference:in flesh was raimented how he was killed and buried from the dead how he arose to life with victory and reigned in heaven how all of us shall be glorious like him whose hearts to his are wed how they who die for love of reason give hypocrites tyrants sophists all who sell their neighbours ill for holiness to hell how the dead saint condemns the bad who live how all he does becomes a law for men how he at last to judge shall come again\n",
      "[NeMo I 2024-02-26 10:05:58 wer:320] predicted:fleshmentd helled andri from thead how he arose to life victory and reig in heaven of glorious like whose hearts to his are they who die for ofyppocritesyrantsphs wholl their neighbours ill forliness toll theadintdemns the bad who hes a law for men he last todge again\n",
      "\n",
      "Validation DataLoader 0: : 7it [00:02,  2.34it/s]\u001b[A[NeMo I 2024-02-26 10:05:59 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:59 wer:319] reference:that's funny remarked betsy thoughtfully\n",
      "[NeMo I 2024-02-26 10:05:59 wer:320] predicted:'snymark to thought\n",
      "\n",
      "Validation DataLoader 0: : 8it [00:03,  2.43it/s]\u001b[A[NeMo I 2024-02-26 10:05:59 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:59 wer:319] reference:at the usual hour mister dorriforth and his ward were summoned to tea he entered with a countenance which evinced the remains of anger his eye gave testimony of his absent thoughts and though he took up a pamphlet affecting to read it was plain to discern that he scarcely knew he held it in his hand\n",
      "[NeMo I 2024-02-26 10:05:59 wer:320] predicted:at theual hour mr dorifor and his ward were summoned to tea he entered with a countenance which evince thes of anger hisye gave testimony of absent thoughts though he tookmphlet effecting to was plain tocer that hearcely he held it in his\n",
      "\n",
      "Validation DataLoader 0: : 9it [00:03,  2.48it/s]\u001b[A[NeMo I 2024-02-26 10:05:59 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:05:59 wer:319] reference:only a little food will be required\n",
      "[NeMo I 2024-02-26 10:05:59 wer:320] predicted:only a little food will be required\n",
      "\n",
      "Validation DataLoader 0: : 10it [00:04,  2.41it/s]\u001b[A[NeMo I 2024-02-26 10:06:00 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:00 wer:319] reference:tom says thanks and looks at hilda and she blushes really\n",
      "[NeMo I 2024-02-26 10:06:00 wer:320] predicted:mp sayss ands at hilda she blushes\n",
      "\n",
      "Validation DataLoader 0: : 11it [00:04,  2.52it/s]\u001b[A[NeMo I 2024-02-26 10:06:00 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:00 wer:319] reference:for these read fibi and vinos that we may conform to english pronunciation\n",
      "[NeMo I 2024-02-26 10:06:00 wer:320] predicted:for theseb andnus that we mayorm to englishnunciation\n",
      "\n",
      "Validation DataLoader 0: : 12it [00:04,  2.61it/s]\u001b[A[NeMo I 2024-02-26 10:06:00 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:00 wer:319] reference:he would make a famous scoundrel\n",
      "[NeMo I 2024-02-26 10:06:00 wer:320] predicted:he would make amousound\n",
      "\n",
      "Validation DataLoader 0: : 13it [00:04,  2.61it/s]\u001b[A[NeMo I 2024-02-26 10:06:00 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:00 wer:319] reference:by and by a short figure smoking a cheroot came up out of the dark and proved to be doctor macklewain who had been prevented from attending the dinner by reason of an accident to a constable at norfolk bay which had claimed his professional attention\n",
      "[NeMo I 2024-02-26 10:06:00 wer:320] predicted:and by a short figure smoking aroot up out of therk and proved toctorckne who had beenvented fromtending the dinner by ofident to constable atrfolk bay hadlaimed hisfessionaltention\n",
      "\n",
      "Validation DataLoader 0: : 14it [00:05,  2.68it/s]\u001b[A[NeMo I 2024-02-26 10:06:01 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:01 wer:319] reference:a snake of his size in fighting trim would be more than any boy could handle\n",
      "[NeMo I 2024-02-26 10:06:01 wer:320] predicted:a snake of its andightingm be more than the couldle\n",
      "\n",
      "Validation DataLoader 0: : 15it [00:05,  2.67it/s]\u001b[A[NeMo I 2024-02-26 10:06:01 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:01 wer:319] reference:who is touching me and untrussing me\n",
      "[NeMo I 2024-02-26 10:06:01 wer:320] predicted:is touching me andrustting me\n",
      "\n",
      "Validation DataLoader 0: : 16it [00:06,  2.62it/s]\u001b[A[NeMo I 2024-02-26 10:06:02 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:02 wer:319] reference:some are wonderfully wrought pretty little homes for birdikins\n",
      "[NeMo I 2024-02-26 10:06:02 wer:320] predicted:some arefullyught littles forrdkins\n",
      "\n",
      "Validation DataLoader 0: : 17it [00:06,  2.59it/s]\u001b[A[NeMo I 2024-02-26 10:06:02 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:02 wer:319] reference:he was that child's stay and she was his prop\n",
      "[NeMo I 2024-02-26 10:06:02 wer:320] predicted:hes sheud\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:06:02 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('global_step', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: : 18it [00:07,  2.57it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]     \u001b[A\n",
      "Validation DataLoader 1: : 0it [00:00, ?it/s]\u001b[A[NeMo I 2024-02-26 10:06:02 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:02 wer:319] reference:no no no yes no no no yes\n",
      "[NeMo I 2024-02-26 10:06:02 wer:320] predicted:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-02-26 10:06:02 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('nemo_dev_clean_2_val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:06:02 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:06:02 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('nemo_dev_clean_2_val_wer', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:06:02 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('val_wer', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:06:02 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('yesno_test_val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-02-26 10:06:02 nemo_logging:349] /home/pzelasko/miniconda3/envs/nemo-nota/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:433: PossibleUserWarning: It is recommended to use `self.log('yesno_test_val_wer', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 50/50 [00:24<00:00,  2.08it/s, v_num=4-31, train_step_timing in s=0.128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_wer' reached 0.49404 (best 0.49404), saving model to '/home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_multidataset/2024-02-26_10-04-31/checkpoints/finetune_from_nemo_multidataset--val_wer=0.4940-epoch=0.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 \u001b[A[NeMo I 2024-02-26 10:06:03 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_multidataset/2024-02-26_10-04-31/checkpoints/finetune_from_nemo_multidataset.nemo\n",
      "[NeMo I 2024-02-26 10:06:04 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_multidataset/2024-02-26_10-04-31/checkpoints/finetune_from_nemo_multidataset.nemo\n",
      "Epoch 1:  18%|        | 9/50 [00:01<00:05,  7.48it/s, v_num=4-31, train_step_timing in s=0.123][NeMo I 2024-02-26 10:06:06 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:06 wer:319] reference:that the woman had sold as many as two dozen eggs in a day to the summer visitors but what with reading about amalgamated asbestos and consolidated copper and all that the hens began to seem pretty small business and in any case the idea of two dozen eggs at a cent apiece almost makes one blush\n",
      "[NeMo I 2024-02-26 10:06:06 wer:320] predicted:the womanld as many as two dozenggs in a at the summer visits buting about algatedest consolidated copper and that the hes began tom pretty small business case the of two dozen eggs at aent of blush\n",
      "Epoch 1:  38%|      | 19/50 [00:02<00:03,  8.01it/s, v_num=4-31, train_step_timing in s=0.086] [NeMo I 2024-02-26 10:06:07 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:07 wer:319] reference:no yes no no no yes yes no\n",
      "[NeMo I 2024-02-26 10:06:07 wer:320] predicted:law can b law law can can law\n",
      "Epoch 1:  58%|    | 29/50 [00:03<00:02,  8.32it/s, v_num=4-31, train_step_timing in s=0.102][NeMo I 2024-02-26 10:06:08 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:08 wer:319] reference:he no longer sighed for freedom since he had seen and learned to love fairer than a fairy he added many other tender speeches to this declaration and the princess to whom such remarks were a new experience\n",
      "[NeMo I 2024-02-26 10:06:08 wer:320] predicted:heerdom he and toirer than ay added many other tendereeches to thelaration and the to suchmarks new\n",
      "Epoch 1:  78%|  | 39/50 [00:04<00:01,  8.60it/s, v_num=4-31, train_step_timing in s=0.117][NeMo I 2024-02-26 10:06:09 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:09 wer:319] reference:leaping so high that the harness seemed rattling from their backs he struck them and said go on now go on devils there was no further trouble he encouraged mother not to be afraid looking keenly at me\n",
      "[NeMo I 2024-02-26 10:06:09 wer:320] predicted:leaping so high that theing from their he struck and said now was furtherrouble hecouraged not to befraiding ken\n",
      "Epoch 1:  98%|| 49/50 [00:05<00:00,  8.58it/s, v_num=4-31, train_step_timing in s=0.0862][NeMo I 2024-02-26 10:06:10 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:10 wer:319] reference:his attitude towards me had given me great anxiety and sorrow he had changed towards me he had become very reserved and seemed mistrustful i saw much less of him than before\n",
      "[NeMo I 2024-02-26 10:06:10 wer:320] predicted:ude givenxiety sor hes he and saw much lesser than than before\n",
      "Epoch 1: 100%|| 50/50 [00:05<00:00,  8.56it/s, v_num=4-31, train_step_timing in s=0.129] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]\u001b[A[NeMo I 2024-02-26 10:06:11 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:11 wer:319] reference:on the last saturday in april the new york times published an account of the strike complications which were delaying alexander's new jersey bridge and stated that the engineer himself was in town and at his office on west tenth street\n",
      "[NeMo I 2024-02-26 10:06:11 wer:320] predicted:on the lastturday in april the new york timesblished account of the strikelications which werelaying alexander's new jerseydge and stated thatngineer in town and on westth street\n",
      "\n",
      "Validation DataLoader 0: : 1it [00:00,  3.91it/s]\u001b[A[NeMo I 2024-02-26 10:06:11 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:11 wer:319] reference:she slid to the floor beside him as if she were too tired to sit up any longer\n",
      "[NeMo I 2024-02-26 10:06:11 wer:320] predicted:shelid theloor beside him as if she were too tired to sit up any longer\n",
      "\n",
      "Validation DataLoader 0: : 2it [00:00,  3.90it/s]\u001b[A[NeMo I 2024-02-26 10:06:12 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:12 wer:319] reference:and she got up and put her head into the oven\n",
      "[NeMo I 2024-02-26 10:06:12 wer:320] predicted:and she got up and put her head into theven\n",
      "\n",
      "Validation DataLoader 0: : 3it [00:00,  3.03it/s]\u001b[A[NeMo I 2024-02-26 10:06:12 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:12 wer:319] reference:ah he did not depend upon emotional excitement to keep up his belief no declamations no anger no visions of blood red flags waving or metaphorical lurid suns of vengeance rising above the horizon of a doomed society not he\n",
      "[NeMo I 2024-02-26 10:06:12 wer:320] predicted:he did not depend upon emotional excitement to keep his belieflamations no anger nosions of blooddgsving or metaphorical lud sons ofngeance rising above therizon of a doom society not he\n",
      "\n",
      "Validation DataLoader 0: : 4it [00:01,  3.16it/s]\u001b[A[NeMo I 2024-02-26 10:06:13 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:13 wer:319] reference:he gets a red face poring over them\n",
      "[NeMo I 2024-02-26 10:06:13 wer:320] predicted:he gets a red face pouring them\n",
      "\n",
      "Validation DataLoader 0: : 5it [00:01,  2.96it/s]\u001b[A[NeMo I 2024-02-26 10:06:13 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:13 wer:319] reference:his eyes wandered ceaselessly over the blank horizon\n",
      "[NeMo I 2024-02-26 10:06:13 wer:320] predicted:hisyesanderedeasously the blindrizon\n",
      "\n",
      "Validation DataLoader 0: : 6it [00:01,  3.07it/s]\u001b[A[NeMo I 2024-02-26 10:06:13 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:13 wer:319] reference:in flesh was raimented how he was killed and buried from the dead how he arose to life with victory and reigned in heaven how all of us shall be glorious like him whose hearts to his are wed how they who die for love of reason give hypocrites tyrants sophists all who sell their neighbours ill for holiness to hell how the dead saint condemns the bad who live how all he does becomes a law for men how he at last to judge shall come again\n",
      "[NeMo I 2024-02-26 10:06:13 wer:320] predicted:fleshmented he killed andried from thead how he arose to life victory and reig in heaven of us glorious like whose hearts to his ared they who die for ofypocritesyrantsphists wholl their neighbours ill forliness to hell how thead saintdemns the bad who live he becomes a law for men how he at last todge shall again\n",
      "\n",
      "Validation DataLoader 0: : 7it [00:02,  2.74it/s]\u001b[A[NeMo I 2024-02-26 10:06:14 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:14 wer:319] reference:that's funny remarked betsy thoughtfully\n",
      "[NeMo I 2024-02-26 10:06:14 wer:320] predicted:'s funnymark tod thought\n",
      "\n",
      "Validation DataLoader 0: : 8it [00:02,  2.79it/s]\u001b[A[NeMo I 2024-02-26 10:06:14 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:14 wer:319] reference:at the usual hour mister dorriforth and his ward were summoned to tea he entered with a countenance which evinced the remains of anger his eye gave testimony of his absent thoughts and though he took up a pamphlet affecting to read it was plain to discern that he scarcely knew he held it in his hand\n",
      "[NeMo I 2024-02-26 10:06:14 wer:320] predicted:at theual hour mr dorifor and his ward were summoned to tea he entered with a countenance whichvince thes of anger hisye gave testimony of absent thoughts and though he tookmphlet effecting to it was plain tocer that hearcely he held it in his\n",
      "\n",
      "Validation DataLoader 0: : 9it [00:03,  2.82it/s]\u001b[A[NeMo I 2024-02-26 10:06:15 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:15 wer:319] reference:only a little food will be required\n",
      "[NeMo I 2024-02-26 10:06:15 wer:320] predicted:only a little food will be required\n",
      "\n",
      "Validation DataLoader 0: : 10it [00:03,  2.69it/s]\u001b[A[NeMo I 2024-02-26 10:06:15 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:15 wer:319] reference:tom says thanks and looks at hilda and she blushes really\n",
      "[NeMo I 2024-02-26 10:06:15 wer:320] predicted:oms thanks and looks at hilda and she blushes really\n",
      "\n",
      "Validation DataLoader 0: : 11it [00:03,  2.79it/s]\u001b[A[NeMo I 2024-02-26 10:06:15 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:15 wer:319] reference:for these read fibi and vinos that we may conform to english pronunciation\n",
      "[NeMo I 2024-02-26 10:06:15 wer:320] predicted:for thesedb andnus that we mayorm to englishnunciation\n",
      "\n",
      "Validation DataLoader 0: : 12it [00:04,  2.88it/s]\u001b[A[NeMo I 2024-02-26 10:06:15 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:15 wer:319] reference:he would make a famous scoundrel\n",
      "[NeMo I 2024-02-26 10:06:15 wer:320] predicted:he would make amous scoundrel\n",
      "\n",
      "Validation DataLoader 0: : 13it [00:04,  2.86it/s]\u001b[A[NeMo I 2024-02-26 10:06:16 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:16 wer:319] reference:by and by a short figure smoking a cheroot came up out of the dark and proved to be doctor macklewain who had been prevented from attending the dinner by reason of an accident to a constable at norfolk bay which had claimed his professional attention\n",
      "[NeMo I 2024-02-26 10:06:16 wer:320] predicted:and by a short figure smoking aroot up out of therk and proved to bector mackel wayne who had been prevented fromtending the dinner by reason ofident to a constable atrfolk bay which had claimed his professional attention\n",
      "\n",
      "Validation DataLoader 0: : 14it [00:04,  2.93it/s]\u001b[A[NeMo I 2024-02-26 10:06:16 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:16 wer:319] reference:a snake of his size in fighting trim would be more than any boy could handle\n",
      "[NeMo I 2024-02-26 10:06:16 wer:320] predicted:a snake of its size andightingm be more than the couldle\n",
      "\n",
      "Validation DataLoader 0: : 15it [00:05,  2.90it/s]\u001b[A[NeMo I 2024-02-26 10:06:17 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:17 wer:319] reference:who is touching me and untrussing me\n",
      "[NeMo I 2024-02-26 10:06:17 wer:320] predicted:who is touching me and trusting me\n",
      "\n",
      "Validation DataLoader 0: : 16it [00:05,  2.83it/s]\u001b[A[NeMo I 2024-02-26 10:06:17 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:17 wer:319] reference:some are wonderfully wrought pretty little homes for birdikins\n",
      "[NeMo I 2024-02-26 10:06:17 wer:320] predicted:some are wonderfullyught pretty little homes forrdins\n",
      "\n",
      "Validation DataLoader 0: : 17it [00:06,  2.77it/s]\u001b[A[NeMo I 2024-02-26 10:06:18 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:18 wer:319] reference:he was that child's stay and she was his prop\n",
      "[NeMo I 2024-02-26 10:06:18 wer:320] predicted:he wassday sheub\n",
      "\n",
      "Validation DataLoader 0: : 18it [00:06,  2.73it/s]\u001b[A\n",
      "Validation DataLoader 0: : 0it [00:00, ?it/s]     \u001b[A\n",
      "Validation DataLoader 1: : 0it [00:00, ?it/s]\u001b[A[NeMo I 2024-02-26 10:06:18 wer:318] \n",
      "    \n",
      "[NeMo I 2024-02-26 10:06:18 wer:319] reference:no no no yes no no no yes\n",
      "[NeMo I 2024-02-26 10:06:18 wer:320] predicted:\n",
      "\n",
      "Epoch 1: 100%|| 50/50 [00:13<00:00,  3.79it/s, v_num=4-31, train_step_timing in s=0.129]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 100: 'val_wer' reached 0.36061 (best 0.36061), saving model to '/home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_multidataset/2024-02-26_10-04-31/checkpoints/finetune_from_nemo_multidataset--val_wer=0.3606-epoch=1.ckpt' as top 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 \u001b[A[NeMo I 2024-02-26 10:06:18 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_multidataset/2024-02-26_10-04-31/checkpoints/finetune_from_nemo_multidataset.nemo\n",
      "[NeMo I 2024-02-26 10:06:19 nemo_model_checkpoint:223] New .nemo model saved to: /home/pzelasko/code/canary/nemo_experiments/finetune_from_nemo_multidataset/2024-02-26_10-04-31/checkpoints/finetune_from_nemo_multidataset.nemo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|| 50/50 [00:14<00:00,  3.35it/s, v_num=4-31, train_step_timing in s=0.129]\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {nemo_root}\n",
    "python $1/examples/asr/speech_to_text_finetune.py \\\n",
    "    +init_from_pretrained_model=\"nvidia/stt_en_conformer_ctc_small\" \\\n",
    "    name=\"finetune_from_nemo_multidataset\" \\\n",
    "    +model.train_ds.use_lhotse=true \\\n",
    "    model.train_ds.manifest_filepath=[[tarred/sharded_manifests/manifest__OP_0..31_CL_.json,0.8],[yesno_tarred/tarred_audio_manifest.json,0.2]] \\\n",
    "    model.train_ds.tarred_audio_filepaths=[[tarred/audio__OP_0..31_CL_.tar],[yesno_tarred/audio_0.tar]] \\\n",
    "    model.train_ds.batch_size=null \\\n",
    "    +model.train_ds.batch_duration=300 \\\n",
    "    +model.train_ds.use_bucketing=true \\\n",
    "    +model.train_ds.num_buckets=30 \\\n",
    "    +model.train_ds.quadratic_duration=15 \\\n",
    "    +model.validation_ds.use_lhotse=true \\\n",
    "    model.validation_ds.manifest_filepath=[data/nemo_dev-clean-2.json,data/yesno_test.json] \\\n",
    "    model.validation_ds.batch_size=64 \\\n",
    "    +trainer.use_distributed_sampler=false \\\n",
    "    trainer.max_steps=100 \\\n",
    "    +trainer.limit_train_batches=50 \\\n",
    "    ++trainer.val_check_interval=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "178b0d83-69fe-4f52-91e3-ca67a9be61d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " finetune_from_nemo_multidataset.nemo\n",
      "'finetune_from_nemo_multidataset--val_wer=0.3606-epoch=1.ckpt'\n",
      "'finetune_from_nemo_multidataset--val_wer=0.3606-epoch=1-last.ckpt'\n",
      "'finetune_from_nemo_multidataset--val_wer=0.4940-epoch=0.ckpt'\n"
     ]
    }
   ],
   "source": [
    "!ls nemo_experiments/finetune_from_nemo_multidataset/*/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5817f02-8532-4a03-83b7-8c7863e26049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
