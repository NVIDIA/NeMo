PYTHONPATH=./ CUDA_VISIBLE_DEVICES=0 HYDRA_FULL_ERROR=1 NEMO_ENABLE_COLORING=1 python examples/multimodal/speech_llm/modular_audio_gpt_train.py \
    --config-path=conf/salm \
    --config-name=modular_audio_t5_s2st_config \
    name=debug \
    model.language_model_path=/workspace/model/megatronnmt_any_en_500m.nemo \
    model.pretrained_audio_model=/workspace/model/stt_multilingual_fastconformer_hybrid_large_pc_blend_eu.nemo \
    exp_manager.exp_dir=/workspace/Experiments/s2st/ \
    trainer.devices=1 \
    trainer.max_steps=180000 \
    trainer.log_every_n_steps=100 \
    trainer.val_check_interval=1000 \
    trainer.limit_val_batches=20 \
    trainer.precision=bf16 \
    trainer.gradient_clip_val=1.0 \
    model.resume_from_checkpoint=null \
    +model.freeze_llm=False \
    model.freeze_audio_encoder=True \
    model.freeze_modality_adapter=False \
    model.global_batch_size=16 \
    model.micro_batch_size=16 \
    model.megatron_amp_O2=False \
    model.save_nemo_on_validation_end=False \
    model.hidden_dropout=0.1 \
    model.attention_dropout=0.1 \
    model.ffn_dropout=0.1 \
    +model.label_smoothing=0.05 \
model.perception.modality_adapter.n_layers=1 \
    model.perception.modality_adapter.subsampling_factor=1 \
    model.perception.modality_adapter.reduction_factor=1 \
    model.perception.modality_adapter.subsampling_conv_channels=512 \
    model.perception.modality_adapter.d_model=512 \
    model.perception.modality_adapter._target_=nemo.collections.multimodal.speech_llm.modules.modality_adapters.IdentityConnectors \
    model.perception.use_multi_layer_feat=false \
    +model.perception.add_sep=true \
    +model.perception.is_canary=True \
    model.perception.spec_augment.freq_masks=2 \
    model.perception.spec_augment.time_masks=10 \
    model.perception.spec_augment.freq_width=27 \
    model.perception.spec_augment.time_width=0.05 \
    model.perception.modality_adapter.reduction=striding \
    model.data.train_ds.use_lhotse=true \
    model.data.train_ds.batch_duration=40 \
    model.data.train_ds.quadratic_duration=20 \
    model.data.train_ds.duration_bins=[3.155,3.76,4.27,4.74,5.1935,5.64,6.096,6.588,7.14,7.81,8.28,8.664,9.072,9.57,10.14,10.7335,11.3735,12.09,12.78,13.41,14.01,14.62,15.253375,15.96875,16.71,17.45,18.1335,18.7735,19.4,20.0] \
    +model.data.train_ds.use_bucketing=false \
    +model.data.train_ds.seed=trng \
    model.data.train_ds.text_field=answer \
    +model.data.train_ds.lang_field=target_lang \
    model.data.train_ds.buffer_size=30000 \
    model.data.train_ds.shuffle_buffer_size=30000 model.data.train_ds.num_workers=0 \
    model.data.train_ds.add_bos=True model.data.train_ds.pin_memory=true model.data.train_ds.max_duration=40 \
    +model.data.train_ds.convert_canary_prompt_to_text=true \
    +model.data.train_ds.canary_tokens_augment_ratio=0.1 \
    model.data.train_ds.max_open_streams=null \
    model.data.train_ds.max_seq_length=2000 \
    ++model.data.validation_ds.use_lhotse=true \
    ++model.data.validation_ds.use_bucketing=false \
    ++model.data.validation_ds.batch_size=4 \
    ++model.data.validation_ds.text_field=answer \
    ++model.data.validation_ds.lang_field=target_lang \
    ++model.data.validation_ds.pin_memory=true \
    ++model.data.validation_ds.num_workers=0 \
    ~model.data.validation_ds.log_every_n_steps \
    ++model.data.validation_ds.max_seq_length=2000 \
    ++model.data.validation_ds.write_predictions_to_file=True \
    ++model.data.validation_ds.output_file_path_prefix=test \
    ++model.data.validation_ds.canary_tokens_augment_ratio=0.0 \
    ++model.data.validation_ds.convert_canary_prompt_to_text=true \
    ++model.data.validation_ds.max_open_streams=null \
    ++model.data.validation_ds.output_dir=/workspace/Results/s2st \
    model.lora_tuning.q_adapter_dim=1 \
    model.lora_tuning.kv_adapter_dim=2 \
    model.lora_tuning.kqv_adapter_dim=4 \
    model.optim.lr=1e-4 \
    model.optim.betas=[0.9,0.98] \
    model.optim.weight_decay=0 \
    model.optim.sched.name=CosineAnnealing \
    model.optim.sched.warmup_steps=2500 \
    model.optim.sched.min_lr=1e-6 \
    +model.use_flash_attention=True \
    +model.audio_prompt_first=False
    # ++model.data.validation_ds.is_tarred=false \
    # ++model.data.validation_ds.tarred_audio_filepaths=null \
    # +model.data.validation_ds.manifest_filepath=[/workspace/data/ASR/MMLPC/en/val_test/mcv11/mcv11_dev_clean_pcstrip_en_2k.json] \
    # +trainer.ckpt_path="/workspace/model/megatron_audio_gpt_peft_tuning--validation_bleu\=53.280-step\=88099-epoch\=4-last.ckpt"